/mnt/vision_retrieval/chenyanzhe/anaconda3/envs/fashion/lib/python3.10/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
=> world size: 8
=> rank: 1
=> dist_url: tcp://127.0.0.1:29500
=> local_rank: 1
=> world size: 8
=> rank: 0
=> dist_url: tcp://127.0.0.1:29500
=> local_rank: 0
=> world size:=> world size:  88

=> rank:=> rank:  34

=> dist_url:=> dist_url:  tcp://127.0.0.1:29500tcp://127.0.0.1:29500

=> local_rank:=> local_rank:  34

=> world size: 8
=> rank: 2
=> dist_url: tcp://127.0.0.1:29500
=> local_rank: 2
=> world size: 8
=> rank: 7
=> dist_url: tcp://127.0.0.1:29500
=> local_rank: 7
=> world size: 8
=> rank: 5
=> dist_url: tcp://127.0.0.1:29500
=> local_rank: 5
=> world size: 8
=> rank: 6
=> dist_url: tcp://127.0.0.1:29500
=> local_rank: 6
CLIP model loaded successfully
CLIP model loaded successfully
CLIP model loaded successfully
CLIP model loaded successfully
CLIP model loaded successfully
CLIP model loaded successfullyCLIP model loaded successfully

CLIP model loaded successfully
Prompt learner loader successfully
Prompt learner loader successfully
Prompt learner loader successfully
Prompt learner loader successfully
Prompt learner loader successfully
Prompt learner loader successfully
Prompt learner loader successfullyPrompt learner loader successfully

Begin to train
Begin to train
Begin to train
Begin to train
Begin to train
Begin to train
Begin to train
Begin to train
/mnt/vision_retrieval/chenyanzhe/anaconda3/envs/fashion/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/mnt/vision_retrieval/chenyanzhe/anaconda3/envs/fashion/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/mnt/vision_retrieval/chenyanzhe/anaconda3/envs/fashion/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/mnt/vision_retrieval/chenyanzhe/anaconda3/envs/fashion/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/mnt/vision_retrieval/chenyanzhe/anaconda3/envs/fashion/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/mnt/vision_retrieval/chenyanzhe/anaconda3/envs/fashion/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/mnt/vision_retrieval/chenyanzhe/anaconda3/envs/fashion/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Train Epoch: [0][0/8]	Loss 7.7622 (7.7622)	LossFusion 7.7622 (7.7622)	/mnt/vision_retrieval/chenyanzhe/anaconda3/envs/fashion/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "

Train Epoch: [0][0/8]	Loss 7.7622 (7.7622)	LossFusion 7.7622 (7.7622)	
Train Epoch: [0][0/8]	Loss 7.7622 (7.7622)	LossFusion 7.7622 (7.7622)	Train Epoch: [0][0/8]	Loss 7.7622 (7.7622)	LossFusion 7.7622 (7.7622)	
Train Epoch: [0][0/8]	Loss 7.7622 (7.7622)	LossFusion 7.7622 (7.7622)	

Train Epoch: [0][0/8]	Loss 7.7622 (7.7622)	LossFusion 7.7622 (7.7622)	
Train Epoch: [0][0/8]	Loss 7.7622 (7.7622)	LossFusion 7.7622 (7.7622)	
Train Epoch: [0][0/8]	Loss 7.7622 (7.7622)	LossFusion 7.7622 (7.7622)	
Train Epoch: [0][7/8]	Loss 3.5828 (6.1018)	LossFusion 3.5828 (6.1018)	
Train Epoch: [0][7/8]	Loss 3.5828 (6.1018)	LossFusion 3.5828 (6.1018)	
Train Epoch: [0][7/8]	Loss 3.5828 (6.1018)	LossFusion 3.5828 (6.1018)	
Train Epoch: [0][7/8]	Loss 3.5828 (6.1018)	LossFusion 3.5828 (6.1018)	
Train Epoch: [0][7/8]	Loss 3.5828 (6.1018)	LossFusion 3.5828 (6.1018)	
Train Epoch: [0][7/8]	Loss 3.5828 (6.1018)	LossFusion 3.5828 (6.1018)	
Train Epoch: [0][7/8]	Loss 3.5828 (6.1018)	LossFusion 3.5828 (6.1018)	
Train Epoch: [0][7/8]	Loss 3.5828 (6.1018)	LossFusion 3.5828 (6.1018)	
R@10:  44.5201575756073     R@50:  72.45882749557495
Best Mean Now:  58.48949 ******************************
R@10:  44.5201575756073     R@50:  72.45882749557495
Best Mean Now:  58.48949 ******************************
R@10:  44.5201575756073     R@50:  72.45882749557495
Best Mean Now:  58.48949 ******************************
R@10:  44.5201575756073     R@50:  72.45882749557495
Best Mean Now:  58.48949 ******************************
R@10:  44.5201575756073     R@50:  72.45882749557495
Best Mean Now:  58.48949 ******************************
R@10:  44.5201575756073     R@50:  72.45882749557495
Best Mean Now:  58.48949 ******************************
R@10:  44.5201575756073     R@50:  72.45882749557495
Best Mean Now:  58.48949 ******************************
R@10:  44.5201575756073     R@50:  72.45882749557495
Best Mean Now:  58.48949 ******************************
Train Epoch: [1][0/8]	Loss 4.2216 (4.2216)	LossFusion 4.2216 (4.2216)	
Train Epoch: [1][0/8]	Loss 4.2216 (4.2216)	LossFusion 4.2216 (4.2216)	
Train Epoch: [1][0/8]	Loss 4.2216 (4.2216)	LossFusion 4.2216 (4.2216)	
Train Epoch: [1][0/8]	Loss 4.2216 (4.2216)	LossFusion 4.2216 (4.2216)	
Train Epoch: [1][0/8]	Loss 4.2216 (4.2216)	LossFusion 4.2216 (4.2216)	
Train Epoch: [1][0/8]	Loss 4.2216 (4.2216)	LossFusion 4.2216 (4.2216)	
Train Epoch: [1][0/8]	Loss 4.2216 (4.2216)	LossFusion 4.2216 (4.2216)	
Train Epoch: [1][0/8]	Loss 4.2216 (4.2216)	LossFusion 4.2216 (4.2216)	
Train Epoch: [1][7/8]	Loss 2.3499 (3.1941)	LossFusion 2.3499 (3.1941)	
Train Epoch: [1][7/8]	Loss 2.3499 (3.1941)	LossFusion 2.3499 (3.1941)	
Train Epoch: [1][7/8]	Loss 2.3499 (3.1941)	LossFusion 2.3499 (3.1941)	
Train Epoch: [1][7/8]	Loss 2.3499 (3.1941)	LossFusion 2.3499 (3.1941)	
Train Epoch: [1][7/8]	Loss 2.3499 (3.1941)	LossFusion 2.3499 (3.1941)	
Train Epoch: [1][7/8]	Loss 2.3499 (3.1941)	LossFusion 2.3499 (3.1941)	
Train Epoch: [1][7/8]	Loss 2.3499 (3.1941)	LossFusion 2.3499 (3.1941)	
Train Epoch: [1][7/8]	Loss 2.3499 (3.1941)	LossFusion 2.3499 (3.1941)	
R@10:  51.73196792602539     R@50:  78.25099229812622
Best Mean Now:  64.99148 ******************************
R@10:  51.73196792602539     R@50:  78.25099229812622
Best Mean Now:  64.99148 ******************************
R@10:  51.73196792602539     R@50:  78.25099229812622
Best Mean Now:  64.99148 ******************************
R@10:  51.73196792602539     R@50:  78.25099229812622
Best Mean Now:  64.99148 ******************************
R@10:  51.73196792602539     R@50:  78.25099229812622
Best Mean Now:  64.99148 ******************************
R@10:  51.73196792602539     R@50:  78.25099229812622
Best Mean Now:  64.99148 ******************************
R@10:  51.73196792602539     R@50:  78.25099229812622
Best Mean Now:  64.99148 ******************************
R@10:  51.73196792602539     R@50:  78.25099229812622
Best Mean Now:  64.99148 ******************************
Train Epoch: [2][0/8]	Loss 2.8761 (2.8761)	LossFusion 2.8761 (2.8761)	
Train Epoch: [2][0/8]	Loss 2.8761 (2.8761)	LossFusion 2.8761 (2.8761)	
Train Epoch: [2][0/8]	Loss 2.8761 (2.8761)	LossFusion 2.8761 (2.8761)	
Train Epoch: [2][0/8]	Loss 2.8761 (2.8761)	LossFusion 2.8761 (2.8761)	
Train Epoch: [2][0/8]	Loss 2.8761 (2.8761)	LossFusion 2.8761 (2.8761)	
Train Epoch: [2][0/8]	Loss 2.8761 (2.8761)	LossFusion 2.8761 (2.8761)	
Train Epoch: [2][0/8]	Loss 2.8761 (2.8761)	LossFusion 2.8761 (2.8761)	
Train Epoch: [2][0/8]	Loss 2.8761 (2.8761)	LossFusion 2.8761 (2.8761)	
Train Epoch: [2][7/8]	Loss 1.8757 (2.3625)	LossFusion 1.8757 (2.3625)	
Train Epoch: [2][7/8]	Loss 1.8757 (2.3625)	LossFusion 1.8757 (2.3625)	
Train Epoch: [2][7/8]	Loss 1.8757 (2.3625)	LossFusion 1.8757 (2.3625)	
Train Epoch: [2][7/8]	Loss 1.8757 (2.3625)	LossFusion 1.8757 (2.3625)	
Train Epoch: [2][7/8]	Loss 1.8757 (2.3625)	LossFusion 1.8757 (2.3625)	
Train Epoch: [2][7/8]	Loss 1.8757 (2.3625)	LossFusion 1.8757 (2.3625)	
Train Epoch: [2][7/8]	Loss 1.8757 (2.3625)	LossFusion 1.8757 (2.3625)	
Train Epoch: [2][7/8]	Loss 1.8757 (2.3625)	LossFusion 1.8757 (2.3625)	
R@10:  52.64054536819458     R@50:  78.59171032905579
Best Mean Now:  65.61613 ******************************
R@10:  52.64054536819458     R@50:  78.59171032905579
Best Mean Now:  65.61613 ******************************
R@10:  52.64054536819458     R@50:  78.59171032905579
Best Mean Now:  65.61613 ******************************
R@10:  52.64054536819458     R@50:  78.59171032905579
Best Mean Now:  65.61613 ******************************
R@10:  52.64054536819458     R@50:  78.59171032905579
Best Mean Now:  65.61613 ******************************
R@10:  52.64054536819458     R@50:  78.59171032905579
Best Mean Now:  65.61613 ******************************
R@10:  52.64054536819458     R@50:  78.59171032905579
Best Mean Now:  65.61613 ******************************
R@10:  52.64054536819458     R@50:  78.59171032905579
Best Mean Now:  65.61613 ******************************
Train Epoch: [3][0/8]	Loss 2.4008 (2.4008)	LossFusion 2.4008 (2.4008)	
Train Epoch: [3][0/8]	Loss 2.4008 (2.4008)	LossFusion 2.4008 (2.4008)	
Train Epoch: [3][0/8]	Loss 2.4008 (2.4008)	LossFusion 2.4008 (2.4008)	
Train Epoch: [3][0/8]	Loss 2.4008 (2.4008)	LossFusion 2.4008 (2.4008)	
Train Epoch: [3][0/8]	Loss 2.4008 (2.4008)	LossFusion 2.4008 (2.4008)	
Train Epoch: [3][0/8]	Loss 2.4008 (2.4008)	LossFusion 2.4008 (2.4008)	
Train Epoch: [3][0/8]	Loss 2.4008 (2.4008)	LossFusion 2.4008 (2.4008)	
Train Epoch: [3][0/8]	Loss 2.4008 (2.4008)	LossFusion 2.4008 (2.4008)	
Train Epoch: [3][7/8]	Loss 1.6489 (2.0476)	LossFusion 1.6489 (2.0476)	
Train Epoch: [3][7/8]	Loss 1.6489 (2.0476)	LossFusion 1.6489 (2.0476)	
Train Epoch: [3][7/8]	Loss 1.6489 (2.0476)	LossFusion 1.6489 (2.0476)	
Train Epoch: [3][7/8]	Loss 1.6489 (2.0476)	LossFusion 1.6489 (2.0476)	
Train Epoch: [3][7/8]	Loss 1.6489 (2.0476)	LossFusion 1.6489 (2.0476)	
Train Epoch: [3][7/8]	Loss 1.6489 (2.0476)	LossFusion 1.6489 (2.0476)	
Train Epoch: [3][7/8]	Loss 1.6489 (2.0476)	LossFusion 1.6489 (2.0476)	
Train Epoch: [3][7/8]	Loss 1.6489 (2.0476)	LossFusion 1.6489 (2.0476)	
R@10:  53.605908155441284     R@50:  79.55706715583801
Best Mean Now:  66.58149 ******************************
R@10:  53.605908155441284     R@50:  79.55706715583801
Best Mean Now:  66.58149 ******************************
R@10:  53.605908155441284     R@50:  79.55706715583801
Best Mean Now:  66.58149 ******************************
R@10:  53.605908155441284     R@50:  79.55706715583801
Best Mean Now:  66.58149 ******************************
R@10:  53.605908155441284     R@50:  79.55706715583801
Best Mean Now:  66.58149 ******************************
R@10:  53.605908155441284     R@50:  79.55706715583801
Best Mean Now:  66.58149 ******************************
R@10:  53.605908155441284     R@50:  79.55706715583801
Best Mean Now:  66.58149 ******************************
R@10:  53.605908155441284     R@50:  79.55706715583801
Best Mean Now:  66.58149 ******************************
Train Epoch: [4][0/8]	Loss 2.2598 (2.2598)	LossFusion 2.2598 (2.2598)	
Train Epoch: [4][0/8]	Loss 2.2598 (2.2598)	LossFusion 2.2598 (2.2598)	
Train Epoch: [4][0/8]	Loss 2.2598 (2.2598)	LossFusion 2.2598 (2.2598)	
Train Epoch: [4][0/8]	Loss 2.2598 (2.2598)	LossFusion 2.2598 (2.2598)	
Train Epoch: [4][0/8]	Loss 2.2598 (2.2598)	LossFusion 2.2598 (2.2598)	
Train Epoch: [4][0/8]	Loss 2.2598 (2.2598)	LossFusion 2.2598 (2.2598)	
Train Epoch: [4][0/8]	Loss 2.2598 (2.2598)	LossFusion 2.2598 (2.2598)	
Train Epoch: [4][0/8]	Loss 2.2598 (2.2598)	LossFusion 2.2598 (2.2598)	
Train Epoch: [4][7/8]	Loss 1.5719 (1.9151)	LossFusion 1.5719 (1.9151)	
Train Epoch: [4][7/8]	Loss 1.5719 (1.9151)	LossFusion 1.5719 (1.9151)	
Train Epoch: [4][7/8]	Loss 1.5719 (1.9151)	LossFusion 1.5719 (1.9151)	
Train Epoch: [4][7/8]	Loss 1.5719 (1.9151)	LossFusion 1.5719 (1.9151)	
Train Epoch: [4][7/8]	Loss 1.5719 (1.9151)	LossFusion 1.5719 (1.9151)	
Train Epoch: [4][7/8]	Loss 1.5719 (1.9151)	LossFusion 1.5719 (1.9151)	
Train Epoch: [4][7/8]	Loss 1.5719 (1.9151)	LossFusion 1.5719 (1.9151)	
Train Epoch: [4][7/8]	Loss 1.5719 (1.9151)	LossFusion 1.5719 (1.9151)	
R@10:  54.57126498222351     R@50:  80.35207390785217
Best Mean Now:  67.46167 ******************************
R@10:  54.57126498222351     R@50:  80.35207390785217
Best Mean Now:  67.46167 ******************************
R@10:  54.57126498222351     R@50:  80.35207390785217
Best Mean Now:  67.46167 ******************************
R@10:  54.57126498222351     R@50:  80.35207390785217
Best Mean Now:  67.46167 ******************************
R@10:  54.57126498222351     R@50:  80.35207390785217
Best Mean Now:  67.46167 ******************************
R@10:  54.57126498222351     R@50:  80.35207390785217
Best Mean Now:  67.46167 ******************************
R@10:  54.57126498222351     R@50:  80.35207390785217
Best Mean Now:  67.46167 ******************************
R@10:  54.57126498222351     R@50:  80.35207390785217
Best Mean Now:  67.46167 ******************************
Train Epoch: [5][0/8]	Loss 2.1912 (2.1912)	LossFusion 2.1912 (2.1912)	
Train Epoch: [5][0/8]	Loss 2.1912 (2.1912)	LossFusion 2.1912 (2.1912)	
Train Epoch: [5][0/8]	Loss 2.1912 (2.1912)	LossFusion 2.1912 (2.1912)	
Train Epoch: [5][0/8]	Loss 2.1912 (2.1912)	LossFusion 2.1912 (2.1912)	
Train Epoch: [5][0/8]	Loss 2.1912 (2.1912)	LossFusion 2.1912 (2.1912)	Train Epoch: [5][0/8]	Loss 2.1912 (2.1912)	LossFusion 2.1912 (2.1912)	

Train Epoch: [5][0/8]	Loss 2.1912 (2.1912)	LossFusion 2.1912 (2.1912)	
Train Epoch: [5][0/8]	Loss 2.1912 (2.1912)	LossFusion 2.1912 (2.1912)	
Train Epoch: [5][7/8]	Loss 1.4972 (1.8379)	LossFusion 1.4972 (1.8379)	
Train Epoch: [5][7/8]	Loss 1.4972 (1.8379)	LossFusion 1.4972 (1.8379)	
Train Epoch: [5][7/8]	Loss 1.4972 (1.8379)	LossFusion 1.4972 (1.8379)	
Train Epoch: [5][7/8]	Loss 1.4972 (1.8379)	LossFusion 1.4972 (1.8379)	
Train Epoch: [5][7/8]	Loss 1.4972 (1.8379)	LossFusion 1.4972 (1.8379)	
Train Epoch: [5][7/8]	Loss 1.4972 (1.8379)	LossFusion 1.4972 (1.8379)	
Train Epoch: [5][7/8]	Loss 1.4972 (1.8379)	LossFusion 1.4972 (1.8379)	
Train Epoch: [5][7/8]	Loss 1.4972 (1.8379)	LossFusion 1.4972 (1.8379)	
R@10:  54.57126498222351     R@50:  80.01135587692261
Mean Now:  67.29131042957306  Best Mean Before:  67.46167 --------------------
R@10:  54.57126498222351     R@50:  80.01135587692261
Mean Now:  67.29131042957306  Best Mean Before:  67.46167 --------------------
R@10:  54.57126498222351     R@50:  80.01135587692261
Mean Now:  67.29131042957306  Best Mean Before:  67.46167 --------------------
R@10:  54.57126498222351     R@50:  80.01135587692261
Mean Now:  67.29131042957306  Best Mean Before:  67.46167 --------------------
R@10:  54.57126498222351     R@50:  80.01135587692261
Mean Now:  67.29131042957306  Best Mean Before:  67.46167 --------------------
R@10:  54.57126498222351     R@50:  80.01135587692261
Mean Now:  67.29131042957306  Best Mean Before:  67.46167 --------------------
R@10:  54.57126498222351     R@50:  80.01135587692261
Mean Now:  67.29131042957306  Best Mean Before:  67.46167 --------------------
R@10:  54.57126498222351     R@50:  80.01135587692261
Mean Now:  67.29131042957306  Best Mean Before:  67.46167 --------------------
Train Epoch: [6][0/8]	Loss 2.1066 (2.1066)	LossFusion 2.1066 (2.1066)	
Train Epoch: [6][0/8]	Loss 2.1066 (2.1066)	LossFusion 2.1066 (2.1066)	
Train Epoch: [6][0/8]	Loss 2.1066 (2.1066)	LossFusion 2.1066 (2.1066)	
Train Epoch: [6][0/8]	Loss 2.1066 (2.1066)	LossFusion 2.1066 (2.1066)	
Train Epoch: [6][0/8]	Loss 2.1066 (2.1066)	LossFusion 2.1066 (2.1066)	
Train Epoch: [6][0/8]	Loss 2.1066 (2.1066)	LossFusion 2.1066 (2.1066)	
Train Epoch: [6][0/8]	Loss 2.1066 (2.1066)	LossFusion 2.1066 (2.1066)	
Train Epoch: [6][0/8]	Loss 2.1066 (2.1066)	LossFusion 2.1066 (2.1066)	
Train Epoch: [6][7/8]	Loss 1.3957 (1.7699)	LossFusion 1.3957 (1.7699)	
Train Epoch: [6][7/8]	Loss 1.3957 (1.7699)	LossFusion 1.3957 (1.7699)	
Train Epoch: [6][7/8]	Loss 1.3957 (1.7699)	LossFusion 1.3957 (1.7699)	
Train Epoch: [6][7/8]	Loss 1.3957 (1.7699)	LossFusion 1.3957 (1.7699)	
Train Epoch: [6][7/8]	Loss 1.3957 (1.7699)	LossFusion 1.3957 (1.7699)	
Train Epoch: [6][7/8]	Loss 1.3957 (1.7699)	LossFusion 1.3957 (1.7699)	
Train Epoch: [6][7/8]	Loss 1.3957 (1.7699)	LossFusion 1.3957 (1.7699)	
Train Epoch: [6][7/8]	Loss 1.3957 (1.7699)	LossFusion 1.3957 (1.7699)	
R@10:  54.34412360191345     R@50:  80.18171787261963
Mean Now:  67.26292073726654  Best Mean Before:  67.46167 --------------------
R@10:  54.34412360191345     R@50:  80.18171787261963
Mean Now:  67.26292073726654  Best Mean Before:  67.46167 --------------------
R@10:  54.34412360191345     R@50:  80.18171787261963
Mean Now:  67.26292073726654  Best Mean Before:  67.46167 --------------------
R@10:  54.34412360191345     R@50:  80.18171787261963
Mean Now:  67.26292073726654  Best Mean Before:  67.46167 --------------------
R@10:  54.34412360191345     R@50:  80.18171787261963
Mean Now:  67.26292073726654  Best Mean Before:  67.46167 --------------------
R@10:  54.34412360191345     R@50:  80.18171787261963
Mean Now:  67.26292073726654  Best Mean Before:  67.46167 --------------------
R@10:  54.34412360191345     R@50:  80.18171787261963
Mean Now:  67.26292073726654  Best Mean Before:  67.46167 --------------------
R@10:  54.34412360191345     R@50:  80.18171787261963
Mean Now:  67.26292073726654  Best Mean Before:  67.46167 --------------------
Train Epoch: [7][0/8]	Loss 2.0449 (2.0449)	LossFusion 2.0449 (2.0449)	
Train Epoch: [7][0/8]	Loss 2.0449 (2.0449)	LossFusion 2.0449 (2.0449)	
Train Epoch: [7][0/8]	Loss 2.0449 (2.0449)	LossFusion 2.0449 (2.0449)	
Train Epoch: [7][0/8]	Loss 2.0449 (2.0449)	LossFusion 2.0449 (2.0449)	
Train Epoch: [7][0/8]	Loss 2.0449 (2.0449)	LossFusion 2.0449 (2.0449)	
Train Epoch: [7][0/8]	Loss 2.0449 (2.0449)	LossFusion 2.0449 (2.0449)	
Train Epoch: [7][0/8]	Loss 2.0449 (2.0449)	LossFusion 2.0449 (2.0449)	
Train Epoch: [7][0/8]	Loss 2.0449 (2.0449)	LossFusion 2.0449 (2.0449)	
Train Epoch: [7][7/8]	Loss 1.3343 (1.7146)	LossFusion 1.3343 (1.7146)	
Train Epoch: [7][7/8]	Loss 1.3343 (1.7146)	LossFusion 1.3343 (1.7146)	
Train Epoch: [7][7/8]	Loss 1.3343 (1.7146)	LossFusion 1.3343 (1.7146)	
Train Epoch: [7][7/8]	Loss 1.3343 (1.7146)	LossFusion 1.3343 (1.7146)	
Train Epoch: [7][7/8]	Loss 1.3343 (1.7146)	LossFusion 1.3343 (1.7146)	
Train Epoch: [7][7/8]	Loss 1.3343 (1.7146)	LossFusion 1.3343 (1.7146)	
Train Epoch: [7][7/8]	Loss 1.3343 (1.7146)	LossFusion 1.3343 (1.7146)	
Train Epoch: [7][7/8]	Loss 1.3343 (1.7146)	LossFusion 1.3343 (1.7146)	
R@10:  54.85519766807556     R@50:  80.74957132339478
Best Mean Now:  67.80238 ******************************
R@10:  54.85519766807556     R@50:  80.74957132339478
Best Mean Now:  67.80238 ******************************
R@10:  54.85519766807556     R@50:  80.74957132339478
Best Mean Now:  67.80238 ******************************
R@10:  54.85519766807556     R@50:  80.74957132339478
Best Mean Now:  67.80238 ******************************
R@10:  54.85519766807556     R@50:  80.74957132339478
Best Mean Now:  67.80238 ******************************
R@10:  54.85519766807556     R@50:  80.74957132339478
Best Mean Now:  67.80238 ******************************
R@10:  54.85519766807556     R@50:  80.74957132339478
Best Mean Now:  67.80238 ******************************
R@10:  54.85519766807556     R@50:  80.74957132339478
Best Mean Now:  67.80238 ******************************
Train Epoch: [8][0/8]	Loss 1.9585 (1.9585)	LossFusion 1.9585 (1.9585)	
Train Epoch: [8][0/8]	Loss 1.9585 (1.9585)	LossFusion 1.9585 (1.9585)	
Train Epoch: [8][0/8]	Loss 1.9585 (1.9585)	LossFusion 1.9585 (1.9585)	
Train Epoch: [8][0/8]	Loss 1.9585 (1.9585)	LossFusion 1.9585 (1.9585)	
Train Epoch: [8][0/8]	Loss 1.9585 (1.9585)	LossFusion 1.9585 (1.9585)	
Train Epoch: [8][0/8]	Loss 1.9585 (1.9585)	LossFusion 1.9585 (1.9585)	
Train Epoch: [8][0/8]	Loss 1.9585 (1.9585)	LossFusion 1.9585 (1.9585)	
Train Epoch: [8][0/8]	Loss 1.9585 (1.9585)	LossFusion 1.9585 (1.9585)	
Train Epoch: [8][7/8]	Loss 1.3259 (1.6606)	LossFusion 1.3259 (1.6606)	
Train Epoch: [8][7/8]	Loss 1.3259 (1.6606)	LossFusion 1.3259 (1.6606)	
Train Epoch: [8][7/8]	Loss 1.3259 (1.6606)	LossFusion 1.3259 (1.6606)	
Train Epoch: [8][7/8]	Loss 1.3259 (1.6606)	LossFusion 1.3259 (1.6606)	
Train Epoch: [8][7/8]	Loss 1.3259 (1.6606)	LossFusion 1.3259 (1.6606)	
Train Epoch: [8][7/8]	Loss 1.3259 (1.6606)	LossFusion 1.3259 (1.6606)	Train Epoch: [8][7/8]	Loss 1.3259 (1.6606)	LossFusion 1.3259 (1.6606)	

Train Epoch: [8][7/8]	Loss 1.3259 (1.6606)	LossFusion 1.3259 (1.6606)	
R@10:  54.96876835823059     R@50:  80.18171787261963
Mean Now:  67.57524311542511  Best Mean Before:  67.80238 --------------------
R@10:  54.96876835823059     R@50:  80.18171787261963
Mean Now:  67.57524311542511  Best Mean Before:  67.80238 --------------------
R@10:  54.96876835823059     R@50:  80.18171787261963
Mean Now:  67.57524311542511  Best Mean Before:  67.80238 --------------------
R@10:  54.96876835823059     R@50:  80.18171787261963
Mean Now:  67.57524311542511  Best Mean Before:  67.80238 --------------------
R@10:  54.96876835823059     R@50:  80.18171787261963
Mean Now:  67.57524311542511  Best Mean Before:  67.80238 --------------------
R@10:  54.96876835823059     R@50:  80.18171787261963
Mean Now:  67.57524311542511  Best Mean Before:  67.80238 --------------------
R@10:  54.96876835823059     R@50:  80.18171787261963
Mean Now:  67.57524311542511  Best Mean Before:  67.80238 --------------------
R@10:  54.96876835823059     R@50:  80.18171787261963
Mean Now:  67.57524311542511  Best Mean Before:  67.80238 --------------------
Train Epoch: [9][0/8]	Loss 1.9373 (1.9373)	LossFusion 1.9373 (1.9373)	
Train Epoch: [9][0/8]	Loss 1.9373 (1.9373)	LossFusion 1.9373 (1.9373)	
Train Epoch: [9][0/8]	Loss 1.9373 (1.9373)	LossFusion 1.9373 (1.9373)	
Train Epoch: [9][0/8]	Loss 1.9373 (1.9373)	LossFusion 1.9373 (1.9373)	
Train Epoch: [9][0/8]	Loss 1.9373 (1.9373)	LossFusion 1.9373 (1.9373)	
Train Epoch: [9][0/8]	Loss 1.9373 (1.9373)	LossFusion 1.9373 (1.9373)	
Train Epoch: [9][0/8]	Loss 1.9373 (1.9373)	LossFusion 1.9373 (1.9373)	
Train Epoch: [9][0/8]	Loss 1.9373 (1.9373)	LossFusion 1.9373 (1.9373)	
Train Epoch: [9][7/8]	Loss 1.2825 (1.6252)	LossFusion 1.2825 (1.6252)	
Train Epoch: [9][7/8]	Loss 1.2825 (1.6252)	LossFusion 1.2825 (1.6252)	
Train Epoch: [9][7/8]	Loss 1.2825 (1.6252)	LossFusion 1.2825 (1.6252)	
Train Epoch: [9][7/8]	Loss 1.2825 (1.6252)	LossFusion 1.2825 (1.6252)	
Train Epoch: [9][7/8]	Loss 1.2825 (1.6252)	LossFusion 1.2825 (1.6252)	
Train Epoch: [9][7/8]	Loss 1.2825 (1.6252)	LossFusion 1.2825 (1.6252)	
Train Epoch: [9][7/8]	Loss 1.2825 (1.6252)	LossFusion 1.2825 (1.6252)	
Train Epoch: [9][7/8]	Loss 1.2825 (1.6252)	LossFusion 1.2825 (1.6252)	
R@10:  54.57126498222351     R@50:  80.18171787261963
Mean Now:  67.37649142742157  Best Mean Before:  67.80238 --------------------
R@10:  54.57126498222351     R@50:  80.18171787261963
Mean Now:  67.37649142742157  Best Mean Before:  67.80238 --------------------
R@10:  54.57126498222351     R@50:  80.18171787261963
Mean Now:  67.37649142742157  Best Mean Before:  67.80238 --------------------
R@10:  54.57126498222351     R@50:  80.18171787261963
Mean Now:  67.37649142742157  Best Mean Before:  67.80238 --------------------
R@10:  54.57126498222351     R@50:  80.18171787261963
Mean Now:  67.37649142742157  Best Mean Before:  67.80238 --------------------
R@10:  54.57126498222351     R@50:  80.18171787261963
Mean Now:  67.37649142742157  Best Mean Before:  67.80238 --------------------
R@10:  54.57126498222351     R@50:  80.18171787261963
Mean Now:  67.37649142742157  Best Mean Before:  67.80238 --------------------
R@10:  54.57126498222351     R@50:  80.18171787261963
Mean Now:  67.37649142742157  Best Mean Before:  67.80238 --------------------
Train Epoch: [10][0/8]	Loss 1.9098 (1.9098)	LossFusion 1.9098 (1.9098)	
Train Epoch: [10][0/8]	Loss 1.9098 (1.9098)	LossFusion 1.9098 (1.9098)	
Train Epoch: [10][0/8]	Loss 1.9098 (1.9098)	LossFusion 1.9098 (1.9098)	
Train Epoch: [10][0/8]	Loss 1.9098 (1.9098)	LossFusion 1.9098 (1.9098)	
Train Epoch: [10][0/8]	Loss 1.9098 (1.9098)	LossFusion 1.9098 (1.9098)	
Train Epoch: [10][0/8]	Loss 1.9098 (1.9098)	LossFusion 1.9098 (1.9098)	
Train Epoch: [10][0/8]	Loss 1.9098 (1.9098)	LossFusion 1.9098 (1.9098)	
Train Epoch: [10][0/8]	Loss 1.9098 (1.9098)	LossFusion 1.9098 (1.9098)	
Train Epoch: [10][7/8]	Loss 1.2155 (1.5845)	LossFusion 1.2155 (1.5845)	
Train Epoch: [10][7/8]	Loss 1.2155 (1.5845)	LossFusion 1.2155 (1.5845)	
Train Epoch: [10][7/8]	Loss 1.2155 (1.5845)	LossFusion 1.2155 (1.5845)	
Train Epoch: [10][7/8]	Loss 1.2155 (1.5845)	LossFusion 1.2155 (1.5845)	
Train Epoch: [10][7/8]	Loss 1.2155 (1.5845)	LossFusion 1.2155 (1.5845)	
Train Epoch: [10][7/8]	Loss 1.2155 (1.5845)	LossFusion 1.2155 (1.5845)	
Train Epoch: [10][7/8]	Loss 1.2155 (1.5845)	LossFusion 1.2155 (1.5845)	
Train Epoch: [10][7/8]	Loss 1.2155 (1.5845)	LossFusion 1.2155 (1.5845)	
R@10:  54.514479637145996     R@50:  80.80636262893677
Mean Now:  67.66042113304138  Best Mean Before:  67.80238 --------------------
R@10:  54.514479637145996     R@50:  80.80636262893677
Mean Now:  67.66042113304138  Best Mean Before:  67.80238 --------------------
R@10:  54.514479637145996     R@50:  80.80636262893677
Mean Now:  67.66042113304138  Best Mean Before:  67.80238 --------------------
R@10:  54.514479637145996     R@50:  80.80636262893677
Mean Now:  67.66042113304138  Best Mean Before:  67.80238 --------------------
R@10:  54.514479637145996     R@50:  80.80636262893677
Mean Now:  67.66042113304138  Best Mean Before:  67.80238 --------------------
R@10:  54.514479637145996     R@50:  80.80636262893677
Mean Now:  67.66042113304138  Best Mean Before:  67.80238 --------------------
R@10:  54.514479637145996     R@50:  80.80636262893677
Mean Now:  67.66042113304138  Best Mean Before:  67.80238 --------------------
R@10:  54.514479637145996     R@50:  80.80636262893677
Mean Now:  67.66042113304138  Best Mean Before:  67.80238 --------------------
Train Epoch: [11][0/8]	Loss 1.8662 (1.8662)	LossFusion 1.8662 (1.8662)	
Train Epoch: [11][0/8]	Loss 1.8662 (1.8662)	LossFusion 1.8662 (1.8662)	
Train Epoch: [11][0/8]	Loss 1.8662 (1.8662)	LossFusion 1.8662 (1.8662)	
Train Epoch: [11][0/8]	Loss 1.8662 (1.8662)	LossFusion 1.8662 (1.8662)	
Train Epoch: [11][0/8]	Loss 1.8662 (1.8662)	LossFusion 1.8662 (1.8662)	
Train Epoch: [11][0/8]	Loss 1.8662 (1.8662)	LossFusion 1.8662 (1.8662)	
Train Epoch: [11][0/8]	Loss 1.8662 (1.8662)	LossFusion 1.8662 (1.8662)	
Train Epoch: [11][0/8]	Loss 1.8662 (1.8662)	LossFusion 1.8662 (1.8662)	
Train Epoch: [11][7/8]	Loss 1.2439 (1.5441)	LossFusion 1.2439 (1.5441)	
Train Epoch: [11][7/8]	Loss 1.2439 (1.5441)	LossFusion 1.2439 (1.5441)	
Train Epoch: [11][7/8]	Loss 1.2439 (1.5441)	LossFusion 1.2439 (1.5441)	
Train Epoch: [11][7/8]	Loss 1.2439 (1.5441)	LossFusion 1.2439 (1.5441)	
Train Epoch: [11][7/8]	Loss 1.2439 (1.5441)	LossFusion 1.2439 (1.5441)	
Train Epoch: [11][7/8]	Loss 1.2439 (1.5441)	LossFusion 1.2439 (1.5441)	
Train Epoch: [11][7/8]	Loss 1.2439 (1.5441)	LossFusion 1.2439 (1.5441)	
Train Epoch: [11][7/8]	Loss 1.2439 (1.5441)	LossFusion 1.2439 (1.5441)	
R@10:  55.36627173423767     R@50:  80.86314797401428
Best Mean Now:  68.11471 ******************************
R@10:  55.36627173423767     R@50:  80.86314797401428
Best Mean Now:  68.11471 ******************************
R@10:  55.36627173423767     R@50:  80.86314797401428
Best Mean Now:  68.11471 ******************************
R@10:  55.36627173423767     R@50:  80.86314797401428
Best Mean Now:  68.11471 ******************************
R@10:  55.36627173423767     R@50:  80.86314797401428
Best Mean Now:  68.11471 ******************************
R@10:  55.36627173423767     R@50:  80.86314797401428
Best Mean Now:  68.11471 ******************************
R@10:  55.36627173423767     R@50:  80.86314797401428
Best Mean Now:  68.11471 ******************************
R@10:  55.36627173423767     R@50:  80.86314797401428
Best Mean Now:  68.11471 ******************************
Train Epoch: [12][0/8]	Loss 1.7759 (1.7759)	LossFusion 1.7759 (1.7759)	
Train Epoch: [12][0/8]	Loss 1.7759 (1.7759)	LossFusion 1.7759 (1.7759)	
Train Epoch: [12][0/8]	Loss 1.7759 (1.7759)	LossFusion 1.7759 (1.7759)	
Train Epoch: [12][0/8]	Loss 1.7759 (1.7759)	LossFusion 1.7759 (1.7759)	
Train Epoch: [12][0/8]	Loss 1.7759 (1.7759)	LossFusion 1.7759 (1.7759)	
Train Epoch: [12][0/8]	Loss 1.7759 (1.7759)	LossFusion 1.7759 (1.7759)	
Train Epoch: [12][0/8]	Loss 1.7759 (1.7759)	LossFusion 1.7759 (1.7759)	
Train Epoch: [12][0/8]	Loss 1.7759 (1.7759)	LossFusion 1.7759 (1.7759)	
Train Epoch: [12][7/8]	Loss 1.1961 (1.4858)	LossFusion 1.1961 (1.4858)	
Train Epoch: [12][7/8]	Loss 1.1961 (1.4858)	LossFusion 1.1961 (1.4858)	
Train Epoch: [12][7/8]	Loss 1.1961 (1.4858)	LossFusion 1.1961 (1.4858)	
Train Epoch: [12][7/8]	Loss 1.1961 (1.4858)	LossFusion 1.1961 (1.4858)	
Train Epoch: [12][7/8]	Loss 1.1961 (1.4858)	LossFusion 1.1961 (1.4858)	
Train Epoch: [12][7/8]	Loss 1.1961 (1.4858)	LossFusion 1.1961 (1.4858)	
Train Epoch: [12][7/8]	Loss 1.1961 (1.4858)	LossFusion 1.1961 (1.4858)	
Train Epoch: [12][7/8]	Loss 1.1961 (1.4858)	LossFusion 1.1961 (1.4858)	
R@10:  55.139124393463135     R@50:  81.20386004447937
Best Mean Now:  68.17149 ******************************
R@10:  55.139124393463135     R@50:  81.20386004447937
Best Mean Now:  68.17149 ******************************
R@10:  55.139124393463135     R@50:  81.20386004447937
Best Mean Now:  68.17149 ******************************
R@10:  55.139124393463135     R@50:  81.20386004447937
Best Mean Now:  68.17149 ******************************
R@10:  55.139124393463135     R@50:  81.20386004447937
Best Mean Now:  68.17149 ******************************
R@10:  55.139124393463135     R@50:  81.20386004447937
Best Mean Now:  68.17149 ******************************
R@10:  55.139124393463135     R@50:  81.20386004447937
Best Mean Now:  68.17149 ******************************
R@10:  55.139124393463135     R@50:  81.20386004447937
Best Mean Now:  68.17149 ******************************
Train Epoch: [13][0/8]	Loss 1.7377 (1.7377)	LossFusion 1.7377 (1.7377)	
Train Epoch: [13][0/8]	Loss 1.7377 (1.7377)	LossFusion 1.7377 (1.7377)	
Train Epoch: [13][0/8]	Loss 1.7377 (1.7377)	LossFusion 1.7377 (1.7377)	
Train Epoch: [13][0/8]	Loss 1.7377 (1.7377)	LossFusion 1.7377 (1.7377)	
Train Epoch: [13][0/8]	Loss 1.7377 (1.7377)	LossFusion 1.7377 (1.7377)	
Train Epoch: [13][0/8]	Loss 1.7377 (1.7377)	LossFusion 1.7377 (1.7377)	
Train Epoch: [13][0/8]	Loss 1.7377 (1.7377)	LossFusion 1.7377 (1.7377)	
Train Epoch: [13][0/8]	Loss 1.7377 (1.7377)	LossFusion 1.7377 (1.7377)	
Train Epoch: [13][7/8]	Loss 1.1407 (1.4693)	LossFusion 1.1407 (1.4693)	
Train Epoch: [13][7/8]	Loss 1.1407 (1.4693)	LossFusion 1.1407 (1.4693)	
Train Epoch: [13][7/8]	Loss 1.1407 (1.4693)	LossFusion 1.1407 (1.4693)	
Train Epoch: [13][7/8]	Loss 1.1407 (1.4693)	LossFusion 1.1407 (1.4693)	
Train Epoch: [13][7/8]	Loss 1.1407 (1.4693)	LossFusion 1.1407 (1.4693)	
Train Epoch: [13][7/8]	Loss 1.1407 (1.4693)	LossFusion 1.1407 (1.4693)	
Train Epoch: [13][7/8]	Loss 1.1407 (1.4693)	LossFusion 1.1407 (1.4693)	
Train Epoch: [13][7/8]	Loss 1.1407 (1.4693)	LossFusion 1.1407 (1.4693)	
R@10:  54.74162697792053     R@50:  81.03350400924683
Mean Now:  67.88756549358368  Best Mean Before:  68.17149 --------------------
R@10:  54.74162697792053     R@50:  81.03350400924683
Mean Now:  67.88756549358368  Best Mean Before:  68.17149 --------------------
R@10:  54.74162697792053     R@50:  81.03350400924683
Mean Now:  67.88756549358368  Best Mean Before:  68.17149 --------------------
R@10:  54.74162697792053     R@50:  81.03350400924683
Mean Now:  67.88756549358368  Best Mean Before:  68.17149 --------------------
R@10:  54.74162697792053     R@50:  81.03350400924683
Mean Now:  67.88756549358368  Best Mean Before:  68.17149 --------------------
R@10:  54.74162697792053     R@50:  81.03350400924683
Mean Now:  67.88756549358368  Best Mean Before:  68.17149 --------------------
R@10:  54.74162697792053     R@50:  81.03350400924683
Mean Now:  67.88756549358368  Best Mean Before:  68.17149 --------------------
R@10:  54.74162697792053     R@50:  81.03350400924683
Mean Now:  67.88756549358368  Best Mean Before:  68.17149 --------------------
Train Epoch: [14][0/8]	Loss 1.7290 (1.7290)	LossFusion 1.7290 (1.7290)	
Train Epoch: [14][0/8]	Loss 1.7290 (1.7290)	LossFusion 1.7290 (1.7290)	
Train Epoch: [14][0/8]	Loss 1.7290 (1.7290)	LossFusion 1.7290 (1.7290)	
Train Epoch: [14][0/8]	Loss 1.7290 (1.7290)	LossFusion 1.7290 (1.7290)	
Train Epoch: [14][0/8]	Loss 1.7290 (1.7290)	LossFusion 1.7290 (1.7290)	
Train Epoch: [14][0/8]	Loss 1.7290 (1.7290)	LossFusion 1.7290 (1.7290)	
Train Epoch: [14][0/8]	Loss 1.7290 (1.7290)	LossFusion 1.7290 (1.7290)	
Train Epoch: [14][0/8]	Loss 1.7290 (1.7290)	LossFusion 1.7290 (1.7290)	
Train Epoch: [14][7/8]	Loss 1.0813 (1.4430)	LossFusion 1.0813 (1.4430)	
Train Epoch: [14][7/8]	Loss 1.0813 (1.4430)	LossFusion 1.0813 (1.4430)	
Train Epoch: [14][7/8]	Loss 1.0813 (1.4430)	LossFusion 1.0813 (1.4430)	
Train Epoch: [14][7/8]	Loss 1.0813 (1.4430)	LossFusion 1.0813 (1.4430)	
Train Epoch: [14][7/8]	Loss 1.0813 (1.4430)	LossFusion 1.0813 (1.4430)	
Train Epoch: [14][7/8]	Loss 1.0813 (1.4430)	LossFusion 1.0813 (1.4430)	
Train Epoch: [14][7/8]	Loss 1.0813 (1.4430)	LossFusion 1.0813 (1.4430)	
Train Epoch: [14][7/8]	Loss 1.0813 (1.4430)	LossFusion 1.0813 (1.4430)	
R@10:  54.911983013153076     R@50:  80.80636262893677
Mean Now:  67.85917282104492  Best Mean Before:  68.17149 --------------------
R@10:  54.911983013153076     R@50:  80.80636262893677
Mean Now:  67.85917282104492  Best Mean Before:  68.17149 --------------------
R@10:  54.911983013153076     R@50:  80.80636262893677
Mean Now:  67.85917282104492  Best Mean Before:  68.17149 --------------------
R@10:  54.911983013153076     R@50:  80.80636262893677
Mean Now:  67.85917282104492  Best Mean Before:  68.17149 --------------------
R@10:  54.911983013153076     R@50:  80.80636262893677
Mean Now:  67.85917282104492  Best Mean Before:  68.17149 --------------------
R@10:  54.911983013153076     R@50:  80.80636262893677
Mean Now:  67.85917282104492  Best Mean Before:  68.17149 --------------------
R@10:  54.911983013153076     R@50:  80.80636262893677
Mean Now:  67.85917282104492  Best Mean Before:  68.17149 --------------------
R@10:  54.911983013153076     R@50:  80.80636262893677
Mean Now:  67.85917282104492  Best Mean Before:  68.17149 --------------------
Train Epoch: [15][0/8]	Loss 1.6999 (1.6999)	LossFusion 1.6999 (1.6999)	
Train Epoch: [15][0/8]	Loss 1.6999 (1.6999)	LossFusion 1.6999 (1.6999)	
Train Epoch: [15][0/8]	Loss 1.6999 (1.6999)	LossFusion 1.6999 (1.6999)	
Train Epoch: [15][0/8]	Loss 1.6999 (1.6999)	LossFusion 1.6999 (1.6999)	
Train Epoch: [15][0/8]	Loss 1.6999 (1.6999)	LossFusion 1.6999 (1.6999)	
Train Epoch: [15][0/8]	Loss 1.6999 (1.6999)	LossFusion 1.6999 (1.6999)	
Train Epoch: [15][0/8]	Loss 1.6999 (1.6999)	LossFusion 1.6999 (1.6999)	
Train Epoch: [15][0/8]	Loss 1.6999 (1.6999)	LossFusion 1.6999 (1.6999)	
Train Epoch: [15][7/8]	Loss 1.0534 (1.4028)	LossFusion 1.0534 (1.4028)	
Train Epoch: [15][7/8]	Loss 1.0534 (1.4028)	LossFusion 1.0534 (1.4028)	
Train Epoch: [15][7/8]	Loss 1.0534 (1.4028)	LossFusion 1.0534 (1.4028)	
Train Epoch: [15][7/8]	Loss 1.0534 (1.4028)	LossFusion 1.0534 (1.4028)	
Train Epoch: [15][7/8]	Loss 1.0534 (1.4028)	LossFusion 1.0534 (1.4028)	
Train Epoch: [15][7/8]	Loss 1.0534 (1.4028)	LossFusion 1.0534 (1.4028)	
Train Epoch: [15][7/8]	Loss 1.0534 (1.4028)	LossFusion 1.0534 (1.4028)	
Train Epoch: [15][7/8]	Loss 1.0534 (1.4028)	LossFusion 1.0534 (1.4028)	
R@10:  55.423057079315186     R@50:  81.20386004447937
Best Mean Now:  68.31346 ******************************
R@10:  55.423057079315186     R@50:  81.20386004447937
Best Mean Now:  68.31346 ******************************
R@10:  55.423057079315186     R@50:  81.20386004447937
Best Mean Now:  68.31346 ******************************
R@10:  55.423057079315186     R@50:  81.20386004447937
Best Mean Now:  68.31346 ******************************
R@10:  55.423057079315186     R@50:  81.20386004447937
Best Mean Now:  68.31346 ******************************
R@10:  55.423057079315186     R@50:  81.20386004447937
Best Mean Now:  68.31346 ******************************
R@10:  55.423057079315186     R@50:  81.20386004447937
Best Mean Now:  68.31346 ******************************
R@10:  55.423057079315186     R@50:  81.20386004447937
Best Mean Now:  68.31346 ******************************
Train Epoch: [16][0/8]	Loss 1.7004 (1.7004)	LossFusion 1.7004 (1.7004)	
Train Epoch: [16][0/8]	Loss 1.7004 (1.7004)	LossFusion 1.7004 (1.7004)	
Train Epoch: [16][0/8]	Loss 1.7004 (1.7004)	LossFusion 1.7004 (1.7004)	
Train Epoch: [16][0/8]	Loss 1.7004 (1.7004)	LossFusion 1.7004 (1.7004)	
Train Epoch: [16][0/8]	Loss 1.7004 (1.7004)	LossFusion 1.7004 (1.7004)	
Train Epoch: [16][0/8]	Loss 1.7004 (1.7004)	LossFusion 1.7004 (1.7004)	
Train Epoch: [16][0/8]	Loss 1.7004 (1.7004)	LossFusion 1.7004 (1.7004)	
Train Epoch: [16][0/8]	Loss 1.7004 (1.7004)	LossFusion 1.7004 (1.7004)	
Train Epoch: [16][7/8]	Loss 1.0592 (1.3985)	LossFusion 1.0592 (1.3985)	
Train Epoch: [16][7/8]	Loss 1.0592 (1.3985)	LossFusion 1.0592 (1.3985)	
Train Epoch: [16][7/8]	Loss 1.0592 (1.3985)	LossFusion 1.0592 (1.3985)	
Train Epoch: [16][7/8]	Loss 1.0592 (1.3985)	LossFusion 1.0592 (1.3985)	
Train Epoch: [16][7/8]	Loss 1.0592 (1.3985)	LossFusion 1.0592 (1.3985)	
Train Epoch: [16][7/8]	Loss 1.0592 (1.3985)	LossFusion 1.0592 (1.3985)	
Train Epoch: [16][7/8]	Loss 1.0592 (1.3985)	LossFusion 1.0592 (1.3985)	
Train Epoch: [16][7/8]	Loss 1.0592 (1.3985)	LossFusion 1.0592 (1.3985)	
R@10:  54.911983013153076     R@50:  80.97671866416931
Mean Now:  67.9443508386612  Best Mean Before:  68.31346 --------------------
R@10:  54.911983013153076     R@50:  80.97671866416931
Mean Now:  67.9443508386612  Best Mean Before:  68.31346 --------------------
R@10:  54.911983013153076     R@50:  80.97671866416931
Mean Now:  67.9443508386612  Best Mean Before:  68.31346 --------------------
R@10:  54.911983013153076     R@50:  80.97671866416931
Mean Now:  67.9443508386612  Best Mean Before:  68.31346 --------------------
R@10:  54.911983013153076     R@50:  80.97671866416931
Mean Now:  67.9443508386612  Best Mean Before:  68.31346 --------------------
R@10:  54.911983013153076     R@50:  80.97671866416931
Mean Now:  67.9443508386612  Best Mean Before:  68.31346 --------------------
R@10:  54.911983013153076     R@50:  80.97671866416931
Mean Now:  67.9443508386612  Best Mean Before:  68.31346 --------------------
R@10:  54.911983013153076     R@50:  80.97671866416931
Mean Now:  67.9443508386612  Best Mean Before:  68.31346 --------------------
Train Epoch: [17][0/8]	Loss 1.6379 (1.6379)	LossFusion 1.6379 (1.6379)	
Train Epoch: [17][0/8]	Loss 1.6379 (1.6379)	LossFusion 1.6379 (1.6379)	Train Epoch: [17][0/8]	Loss 1.6379 (1.6379)	LossFusion 1.6379 (1.6379)	

Train Epoch: [17][0/8]	Loss 1.6379 (1.6379)	LossFusion 1.6379 (1.6379)	
Train Epoch: [17][0/8]	Loss 1.6379 (1.6379)	LossFusion 1.6379 (1.6379)	
Train Epoch: [17][0/8]	Loss 1.6379 (1.6379)	LossFusion 1.6379 (1.6379)	
Train Epoch: [17][0/8]	Loss 1.6379 (1.6379)	LossFusion 1.6379 (1.6379)	
Train Epoch: [17][0/8]	Loss 1.6379 (1.6379)	LossFusion 1.6379 (1.6379)	
Train Epoch: [17][7/8]	Loss 1.0240 (1.3410)	LossFusion 1.0240 (1.3410)	
Train Epoch: [17][7/8]	Loss 1.0240 (1.3410)	LossFusion 1.0240 (1.3410)	
Train Epoch: [17][7/8]	Loss 1.0240 (1.3410)	LossFusion 1.0240 (1.3410)	
Train Epoch: [17][7/8]	Loss 1.0240 (1.3410)	LossFusion 1.0240 (1.3410)	
Train Epoch: [17][7/8]	Loss 1.0240 (1.3410)	LossFusion 1.0240 (1.3410)	
Train Epoch: [17][7/8]	Loss 1.0240 (1.3410)	LossFusion 1.0240 (1.3410)	
Train Epoch: [17][7/8]	Loss 1.0240 (1.3410)	LossFusion 1.0240 (1.3410)	
Train Epoch: [17][7/8]	Loss 1.0240 (1.3410)	LossFusion 1.0240 (1.3410)	
R@10:  55.36627173423767     R@50:  81.60136342048645
Best Mean Now:  68.48382 ******************************
R@10:  55.36627173423767     R@50:  81.60136342048645
Best Mean Now:  68.48382 ******************************
R@10:  55.36627173423767     R@50:  81.60136342048645
Best Mean Now:  68.48382 ******************************
R@10:  55.36627173423767     R@50:  81.60136342048645
Best Mean Now:  68.48382 ******************************
R@10:  55.36627173423767     R@50:  81.60136342048645
Best Mean Now:  68.48382 ******************************
R@10:  55.36627173423767     R@50:  81.60136342048645
Best Mean Now:  68.48382 ******************************
R@10:  55.36627173423767     R@50:  81.60136342048645
Best Mean Now:  68.48382 ******************************
R@10:  55.36627173423767     R@50:  81.60136342048645
Best Mean Now:  68.48382 ******************************
Train Epoch: [18][0/8]	Loss 1.5734 (1.5734)	LossFusion 1.5734 (1.5734)	
Train Epoch: [18][0/8]	Loss 1.5734 (1.5734)	LossFusion 1.5734 (1.5734)	
Train Epoch: [18][0/8]	Loss 1.5734 (1.5734)	LossFusion 1.5734 (1.5734)	
Train Epoch: [18][0/8]	Loss 1.5734 (1.5734)	LossFusion 1.5734 (1.5734)	
Train Epoch: [18][0/8]	Loss 1.5734 (1.5734)	LossFusion 1.5734 (1.5734)	
Train Epoch: [18][0/8]	Loss 1.5734 (1.5734)	LossFusion 1.5734 (1.5734)	
Train Epoch: [18][0/8]	Loss 1.5734 (1.5734)	LossFusion 1.5734 (1.5734)	
Train Epoch: [18][0/8]	Loss 1.5734 (1.5734)	LossFusion 1.5734 (1.5734)	
Train Epoch: [18][7/8]	Loss 0.9990 (1.3169)	LossFusion 0.9990 (1.3169)	
Train Epoch: [18][7/8]	Loss 0.9990 (1.3169)	LossFusion 0.9990 (1.3169)	
Train Epoch: [18][7/8]	Loss 0.9990 (1.3169)	LossFusion 0.9990 (1.3169)	
Train Epoch: [18][7/8]	Loss 0.9990 (1.3169)	LossFusion 0.9990 (1.3169)	
Train Epoch: [18][7/8]	Loss 0.9990 (1.3169)	LossFusion 0.9990 (1.3169)	
Train Epoch: [18][7/8]	Loss 0.9990 (1.3169)	LossFusion 0.9990 (1.3169)	
Train Epoch: [18][7/8]	Loss 0.9990 (1.3169)	LossFusion 0.9990 (1.3169)	Train Epoch: [18][7/8]	Loss 0.9990 (1.3169)	LossFusion 0.9990 (1.3169)	

R@10:  55.423057079315186     R@50:  81.09028935432434
Mean Now:  68.25667321681976  Best Mean Before:  68.48382 --------------------
R@10:  55.423057079315186     R@50:  81.09028935432434
Mean Now:  68.25667321681976  Best Mean Before:  68.48382 --------------------
R@10:  55.423057079315186     R@50:  81.09028935432434
Mean Now:  68.25667321681976  Best Mean Before:  68.48382 --------------------
R@10:  55.423057079315186     R@50:  81.09028935432434
Mean Now:  68.25667321681976  Best Mean Before:  68.48382 --------------------
R@10:  55.423057079315186     R@50:  81.09028935432434
Mean Now:  68.25667321681976  Best Mean Before:  68.48382 --------------------
R@10:  55.423057079315186     R@50:  81.09028935432434
Mean Now:  68.25667321681976  Best Mean Before:  68.48382 --------------------
R@10:  55.423057079315186     R@50:  81.09028935432434
Mean Now:  68.25667321681976  Best Mean Before:  68.48382 --------------------
R@10:  55.423057079315186     R@50:  81.09028935432434
Mean Now:  68.25667321681976  Best Mean Before:  68.48382 --------------------
Train Epoch: [19][0/8]	Loss 1.5504 (1.5504)	LossFusion 1.5504 (1.5504)	
Train Epoch: [19][0/8]	Loss 1.5504 (1.5504)	LossFusion 1.5504 (1.5504)	
Train Epoch: [19][0/8]	Loss 1.5504 (1.5504)	LossFusion 1.5504 (1.5504)	
Train Epoch: [19][0/8]	Loss 1.5504 (1.5504)	LossFusion 1.5504 (1.5504)	
Train Epoch: [19][0/8]	Loss 1.5504 (1.5504)	LossFusion 1.5504 (1.5504)	
Train Epoch: [19][0/8]	Loss 1.5504 (1.5504)	LossFusion 1.5504 (1.5504)	
Train Epoch: [19][0/8]	Loss 1.5504 (1.5504)	LossFusion 1.5504 (1.5504)	
Train Epoch: [19][0/8]	Loss 1.5504 (1.5504)	LossFusion 1.5504 (1.5504)	
Train Epoch: [19][7/8]	Loss 0.9548 (1.2816)	LossFusion 0.9548 (1.2816)	
Train Epoch: [19][7/8]	Loss 0.9548 (1.2816)	LossFusion 0.9548 (1.2816)	Train Epoch: [19][7/8]	Loss 0.9548 (1.2816)	LossFusion 0.9548 (1.2816)	

Train Epoch: [19][7/8]	Loss 0.9548 (1.2816)	LossFusion 0.9548 (1.2816)	
Train Epoch: [19][7/8]	Loss 0.9548 (1.2816)	LossFusion 0.9548 (1.2816)	
Train Epoch: [19][7/8]	Loss 0.9548 (1.2816)	LossFusion 0.9548 (1.2816)	
Train Epoch: [19][7/8]	Loss 0.9548 (1.2816)	LossFusion 0.9548 (1.2816)	
Train Epoch: [19][7/8]	Loss 0.9548 (1.2816)	LossFusion 0.9548 (1.2816)	
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  68.48382 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  68.48382 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  68.48382 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  68.48382 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  68.48382 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  68.48382 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  68.48382 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  68.48382 --------------------
Train Epoch: [20][0/8]	Loss 1.4817 (1.4817)	LossFusion 1.4817 (1.4817)	
Train Epoch: [20][0/8]	Loss 1.4817 (1.4817)	LossFusion 1.4817 (1.4817)	
Train Epoch: [20][0/8]	Loss 1.4817 (1.4817)	LossFusion 1.4817 (1.4817)	
Train Epoch: [20][0/8]	Loss 1.4817 (1.4817)	LossFusion 1.4817 (1.4817)	
Train Epoch: [20][0/8]	Loss 1.4817 (1.4817)	LossFusion 1.4817 (1.4817)	
Train Epoch: [20][0/8]	Loss 1.4817 (1.4817)	LossFusion 1.4817 (1.4817)	
Train Epoch: [20][0/8]	Loss 1.4817 (1.4817)	LossFusion 1.4817 (1.4817)	
Train Epoch: [20][0/8]	Loss 1.4817 (1.4817)	LossFusion 1.4817 (1.4817)	
Train Epoch: [20][7/8]	Loss 0.9690 (1.2636)	LossFusion 0.9690 (1.2636)	
Train Epoch: [20][7/8]	Loss 0.9690 (1.2636)	LossFusion 0.9690 (1.2636)	
Train Epoch: [20][7/8]	Loss 0.9690 (1.2636)	LossFusion 0.9690 (1.2636)	
Train Epoch: [20][7/8]	Loss 0.9690 (1.2636)	LossFusion 0.9690 (1.2636)	
Train Epoch: [20][7/8]	Loss 0.9690 (1.2636)	LossFusion 0.9690 (1.2636)	
Train Epoch: [20][7/8]	Loss 0.9690 (1.2636)	LossFusion 0.9690 (1.2636)	
Train Epoch: [20][7/8]	Loss 0.9690 (1.2636)	LossFusion 0.9690 (1.2636)	
Train Epoch: [20][7/8]	Loss 0.9690 (1.2636)	LossFusion 0.9690 (1.2636)	
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  68.48382 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  68.48382 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  68.48382 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  68.48382 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  68.48382 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  68.48382 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  68.48382 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  68.48382 --------------------
Train Epoch: [21][0/8]	Loss 1.5061 (1.5061)	LossFusion 1.5061 (1.5061)	
Train Epoch: [21][0/8]	Loss 1.5061 (1.5061)	LossFusion 1.5061 (1.5061)	
Train Epoch: [21][0/8]	Loss 1.5061 (1.5061)	LossFusion 1.5061 (1.5061)	
Train Epoch: [21][0/8]	Loss 1.5061 (1.5061)	LossFusion 1.5061 (1.5061)	
Train Epoch: [21][0/8]	Loss 1.5061 (1.5061)	LossFusion 1.5061 (1.5061)	
Train Epoch: [21][0/8]	Loss 1.5061 (1.5061)	LossFusion 1.5061 (1.5061)	
Train Epoch: [21][0/8]	Loss 1.5061 (1.5061)	LossFusion 1.5061 (1.5061)	
Train Epoch: [21][0/8]	Loss 1.5061 (1.5061)	LossFusion 1.5061 (1.5061)	
Train Epoch: [21][7/8]	Loss 0.9175 (1.2397)	LossFusion 0.9175 (1.2397)	
Train Epoch: [21][7/8]	Loss 0.9175 (1.2397)	LossFusion 0.9175 (1.2397)	
Train Epoch: [21][7/8]	Loss 0.9175 (1.2397)	LossFusion 0.9175 (1.2397)	
Train Epoch: [21][7/8]	Loss 0.9175 (1.2397)	LossFusion 0.9175 (1.2397)	
Train Epoch: [21][7/8]	Loss 0.9175 (1.2397)	LossFusion 0.9175 (1.2397)	
Train Epoch: [21][7/8]	Loss 0.9175 (1.2397)	LossFusion 0.9175 (1.2397)	
Train Epoch: [21][7/8]	Loss 0.9175 (1.2397)	LossFusion 0.9175 (1.2397)	
Train Epoch: [21][7/8]	Loss 0.9175 (1.2397)	LossFusion 0.9175 (1.2397)	
R@10:  55.59341311454773     R@50:  81.14707469940186
Mean Now:  68.37024390697479  Best Mean Before:  68.48382 --------------------
R@10:  55.59341311454773     R@50:  81.14707469940186
Mean Now:  68.37024390697479  Best Mean Before:  68.48382 --------------------
R@10:  55.59341311454773     R@50:  81.14707469940186
Mean Now:  68.37024390697479  Best Mean Before:  68.48382 --------------------
R@10:  55.59341311454773     R@50:  81.14707469940186
Mean Now:  68.37024390697479  Best Mean Before:  68.48382 --------------------
R@10:  55.59341311454773     R@50:  81.14707469940186
Mean Now:  68.37024390697479  Best Mean Before:  68.48382 --------------------
R@10:  55.59341311454773     R@50:  81.14707469940186
Mean Now:  68.37024390697479  Best Mean Before:  68.48382 --------------------
R@10:  55.59341311454773     R@50:  81.14707469940186
Mean Now:  68.37024390697479  Best Mean Before:  68.48382 --------------------
R@10:  55.59341311454773     R@50:  81.14707469940186
Mean Now:  68.37024390697479  Best Mean Before:  68.48382 --------------------
Train Epoch: [22][0/8]	Loss 1.4717 (1.4717)	LossFusion 1.4717 (1.4717)	
Train Epoch: [22][0/8]	Loss 1.4717 (1.4717)	LossFusion 1.4717 (1.4717)	
Train Epoch: [22][0/8]	Loss 1.4717 (1.4717)	LossFusion 1.4717 (1.4717)	
Train Epoch: [22][0/8]	Loss 1.4717 (1.4717)	LossFusion 1.4717 (1.4717)	
Train Epoch: [22][0/8]	Loss 1.4717 (1.4717)	LossFusion 1.4717 (1.4717)	
Train Epoch: [22][0/8]	Loss 1.4717 (1.4717)	LossFusion 1.4717 (1.4717)	
Train Epoch: [22][0/8]	Loss 1.4717 (1.4717)	LossFusion 1.4717 (1.4717)	
Train Epoch: [22][0/8]	Loss 1.4717 (1.4717)	LossFusion 1.4717 (1.4717)	
Train Epoch: [22][7/8]	Loss 0.8779 (1.1845)	LossFusion 0.8779 (1.1845)	
Train Epoch: [22][7/8]	Loss 0.8779 (1.1845)	LossFusion 0.8779 (1.1845)	
Train Epoch: [22][7/8]	Loss 0.8779 (1.1845)	LossFusion 0.8779 (1.1845)	
Train Epoch: [22][7/8]	Loss 0.8779 (1.1845)	LossFusion 0.8779 (1.1845)	
Train Epoch: [22][7/8]	Loss 0.8779 (1.1845)	LossFusion 0.8779 (1.1845)	
Train Epoch: [22][7/8]	Loss 0.8779 (1.1845)	LossFusion 0.8779 (1.1845)	
Train Epoch: [22][7/8]	Loss 0.8779 (1.1845)	LossFusion 0.8779 (1.1845)	
Train Epoch: [22][7/8]	Loss 0.8779 (1.1845)	LossFusion 0.8779 (1.1845)	
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  68.48382 --------------------
Train Epoch: [23][0/8]	Loss 1.4474 (1.4474)	LossFusion 1.4474 (1.4474)	
Train Epoch: [23][0/8]	Loss 1.4474 (1.4474)	LossFusion 1.4474 (1.4474)	
Train Epoch: [23][0/8]	Loss 1.4474 (1.4474)	LossFusion 1.4474 (1.4474)	
Train Epoch: [23][0/8]	Loss 1.4474 (1.4474)	LossFusion 1.4474 (1.4474)	
Train Epoch: [23][0/8]	Loss 1.4474 (1.4474)	LossFusion 1.4474 (1.4474)	
Train Epoch: [23][0/8]	Loss 1.4474 (1.4474)	LossFusion 1.4474 (1.4474)	
Train Epoch: [23][0/8]	Loss 1.4474 (1.4474)	LossFusion 1.4474 (1.4474)	
Train Epoch: [23][0/8]	Loss 1.4474 (1.4474)	LossFusion 1.4474 (1.4474)	
Train Epoch: [23][7/8]	Loss 0.8983 (1.1829)	LossFusion 0.8983 (1.1829)	
Train Epoch: [23][7/8]	Loss 0.8983 (1.1829)	LossFusion 0.8983 (1.1829)	
Train Epoch: [23][7/8]	Loss 0.8983 (1.1829)	LossFusion 0.8983 (1.1829)	
Train Epoch: [23][7/8]	Loss 0.8983 (1.1829)	LossFusion 0.8983 (1.1829)	
Train Epoch: [23][7/8]	Loss 0.8983 (1.1829)	LossFusion 0.8983 (1.1829)	
Train Epoch: [23][7/8]	Loss 0.8983 (1.1829)	LossFusion 0.8983 (1.1829)	
Train Epoch: [23][7/8]	Loss 0.8983 (1.1829)	LossFusion 0.8983 (1.1829)	
Train Epoch: [23][7/8]	Loss 0.8983 (1.1829)	LossFusion 0.8983 (1.1829)	
R@10:  55.252695083618164     R@50:  81.03350400924683
Mean Now:  68.1430995464325  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.03350400924683
Mean Now:  68.1430995464325  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.03350400924683
Mean Now:  68.1430995464325  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.03350400924683
Mean Now:  68.1430995464325  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.03350400924683
Mean Now:  68.1430995464325  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.03350400924683
Mean Now:  68.1430995464325  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.03350400924683
Mean Now:  68.1430995464325  Best Mean Before:  68.48382 --------------------
R@10:  55.252695083618164     R@50:  81.03350400924683
Mean Now:  68.1430995464325  Best Mean Before:  68.48382 --------------------
Train Epoch: [24][0/8]	Loss 1.4056 (1.4056)	LossFusion 1.4056 (1.4056)	
Train Epoch: [24][0/8]	Loss 1.4056 (1.4056)	LossFusion 1.4056 (1.4056)	
Train Epoch: [24][0/8]	Loss 1.4056 (1.4056)	LossFusion 1.4056 (1.4056)	
Train Epoch: [24][0/8]	Loss 1.4056 (1.4056)	LossFusion 1.4056 (1.4056)	
Train Epoch: [24][0/8]	Loss 1.4056 (1.4056)	LossFusion 1.4056 (1.4056)	
Train Epoch: [24][0/8]	Loss 1.4056 (1.4056)	LossFusion 1.4056 (1.4056)	
Train Epoch: [24][0/8]	Loss 1.4056 (1.4056)	LossFusion 1.4056 (1.4056)	
Train Epoch: [24][0/8]	Loss 1.4056 (1.4056)	LossFusion 1.4056 (1.4056)	
Train Epoch: [24][7/8]	Loss 0.8481 (1.1500)	LossFusion 0.8481 (1.1500)	
Train Epoch: [24][7/8]	Loss 0.8481 (1.1500)	LossFusion 0.8481 (1.1500)	
Train Epoch: [24][7/8]	Loss 0.8481 (1.1500)	LossFusion 0.8481 (1.1500)	
Train Epoch: [24][7/8]	Loss 0.8481 (1.1500)	LossFusion 0.8481 (1.1500)	
Train Epoch: [24][7/8]	Loss 0.8481 (1.1500)	LossFusion 0.8481 (1.1500)	
Train Epoch: [24][7/8]	Loss 0.8481 (1.1500)	LossFusion 0.8481 (1.1500)	
Train Epoch: [24][7/8]	Loss 0.8481 (1.1500)	LossFusion 0.8481 (1.1500)	
Train Epoch: [24][7/8]	Loss 0.8481 (1.1500)	LossFusion 0.8481 (1.1500)	
R@10:  55.36627173423767     R@50:  81.4310073852539
Mean Now:  68.39863955974579  Best Mean Before:  68.48382 --------------------
R@10:  55.36627173423767     R@50:  81.4310073852539
Mean Now:  68.39863955974579  Best Mean Before:  68.48382 --------------------
R@10:  55.36627173423767     R@50:  81.4310073852539
Mean Now:  68.39863955974579  Best Mean Before:  68.48382 --------------------
R@10:  55.36627173423767     R@50:  81.4310073852539
Mean Now:  68.39863955974579  Best Mean Before:  68.48382 --------------------
R@10:  55.36627173423767     R@50:  81.4310073852539
Mean Now:  68.39863955974579  Best Mean Before:  68.48382 --------------------
R@10:  55.36627173423767     R@50:  81.4310073852539
Mean Now:  68.39863955974579  Best Mean Before:  68.48382 --------------------
R@10:  55.36627173423767     R@50:  81.4310073852539
Mean Now:  68.39863955974579  Best Mean Before:  68.48382 --------------------
R@10:  55.36627173423767     R@50:  81.4310073852539
Mean Now:  68.39863955974579  Best Mean Before:  68.48382 --------------------
Train Epoch: [25][0/8]	Loss 1.4077 (1.4077)	LossFusion 1.4077 (1.4077)	
Train Epoch: [25][0/8]	Loss 1.4077 (1.4077)	LossFusion 1.4077 (1.4077)	
Train Epoch: [25][0/8]	Loss 1.4077 (1.4077)	LossFusion 1.4077 (1.4077)	
Train Epoch: [25][0/8]	Loss 1.4077 (1.4077)	LossFusion 1.4077 (1.4077)	
Train Epoch: [25][0/8]	Loss 1.4077 (1.4077)	LossFusion 1.4077 (1.4077)	
Train Epoch: [25][0/8]	Loss 1.4077 (1.4077)	LossFusion 1.4077 (1.4077)	
Train Epoch: [25][0/8]	Loss 1.4077 (1.4077)	LossFusion 1.4077 (1.4077)	
Train Epoch: [25][0/8]	Loss 1.4077 (1.4077)	LossFusion 1.4077 (1.4077)	
Train Epoch: [25][7/8]	Loss 0.8464 (1.1420)	LossFusion 0.8464 (1.1420)	
Train Epoch: [25][7/8]	Loss 0.8464 (1.1420)	LossFusion 0.8464 (1.1420)	
Train Epoch: [25][7/8]	Loss 0.8464 (1.1420)	LossFusion 0.8464 (1.1420)	
Train Epoch: [25][7/8]	Loss 0.8464 (1.1420)	LossFusion 0.8464 (1.1420)	
Train Epoch: [25][7/8]	Loss 0.8464 (1.1420)	LossFusion 0.8464 (1.1420)	
Train Epoch: [25][7/8]	Loss 0.8464 (1.1420)	LossFusion 0.8464 (1.1420)	
Train Epoch: [25][7/8]	Loss 0.8464 (1.1420)	LossFusion 0.8464 (1.1420)	
Train Epoch: [25][7/8]	Loss 0.8464 (1.1420)	LossFusion 0.8464 (1.1420)	
R@10:  55.536627769470215     R@50:  81.48779273033142
Best Mean Now:  68.51221 ******************************
R@10:  55.536627769470215     R@50:  81.48779273033142
Best Mean Now:  68.51221 ******************************
R@10:  55.536627769470215     R@50:  81.48779273033142
Best Mean Now:  68.51221 ******************************
R@10:  55.536627769470215     R@50:  81.48779273033142
Best Mean Now:  68.51221 ******************************
R@10:  55.536627769470215     R@50:  81.48779273033142
Best Mean Now:  68.51221 ******************************
R@10:  55.536627769470215     R@50:  81.48779273033142
Best Mean Now:  68.51221 ******************************
R@10:  55.536627769470215     R@50:  81.48779273033142
Best Mean Now:  68.51221 ******************************
R@10:  55.536627769470215     R@50:  81.48779273033142
Best Mean Now:  68.51221 ******************************
Train Epoch: [26][0/8]	Loss 1.3976 (1.3976)	LossFusion 1.3976 (1.3976)	
Train Epoch: [26][0/8]	Loss 1.3976 (1.3976)	LossFusion 1.3976 (1.3976)	
Train Epoch: [26][0/8]	Loss 1.3976 (1.3976)	LossFusion 1.3976 (1.3976)	
Train Epoch: [26][0/8]	Loss 1.3976 (1.3976)	LossFusion 1.3976 (1.3976)	
Train Epoch: [26][0/8]	Loss 1.3976 (1.3976)	LossFusion 1.3976 (1.3976)	
Train Epoch: [26][0/8]	Loss 1.3976 (1.3976)	LossFusion 1.3976 (1.3976)	
Train Epoch: [26][0/8]	Loss 1.3976 (1.3976)	LossFusion 1.3976 (1.3976)	
Train Epoch: [26][0/8]	Loss 1.3976 (1.3976)	LossFusion 1.3976 (1.3976)	
Train Epoch: [26][7/8]	Loss 0.8339 (1.1176)	LossFusion 0.8339 (1.1176)	
Train Epoch: [26][7/8]	Loss 0.8339 (1.1176)	LossFusion 0.8339 (1.1176)	
Train Epoch: [26][7/8]	Loss 0.8339 (1.1176)	LossFusion 0.8339 (1.1176)	
Train Epoch: [26][7/8]	Loss 0.8339 (1.1176)	LossFusion 0.8339 (1.1176)	
Train Epoch: [26][7/8]	Loss 0.8339 (1.1176)	LossFusion 0.8339 (1.1176)	
Train Epoch: [26][7/8]	Loss 0.8339 (1.1176)	LossFusion 0.8339 (1.1176)	
Train Epoch: [26][7/8]	Loss 0.8339 (1.1176)	LossFusion 0.8339 (1.1176)	
Train Epoch: [26][7/8]	Loss 0.8339 (1.1176)	LossFusion 0.8339 (1.1176)	
R@10:  55.19590973854065     R@50:  81.20386004447937
Mean Now:  68.19988489151001  Best Mean Before:  68.51221 --------------------
R@10:  55.19590973854065     R@50:  81.20386004447937
Mean Now:  68.19988489151001  Best Mean Before:  68.51221 --------------------
R@10:  55.19590973854065     R@50:  81.20386004447937
Mean Now:  68.19988489151001  Best Mean Before:  68.51221 --------------------
R@10:  55.19590973854065     R@50:  81.20386004447937
Mean Now:  68.19988489151001  Best Mean Before:  68.51221 --------------------
R@10:  55.19590973854065     R@50:  81.20386004447937
Mean Now:  68.19988489151001  Best Mean Before:  68.51221 --------------------
R@10:  55.19590973854065     R@50:  81.20386004447937
Mean Now:  68.19988489151001  Best Mean Before:  68.51221 --------------------
R@10:  55.19590973854065     R@50:  81.20386004447937
Mean Now:  68.19988489151001  Best Mean Before:  68.51221 --------------------
R@10:  55.19590973854065     R@50:  81.20386004447937
Mean Now:  68.19988489151001  Best Mean Before:  68.51221 --------------------
Train Epoch: [27][0/8]	Loss 1.3873 (1.3873)	LossFusion 1.3873 (1.3873)	
Train Epoch: [27][0/8]	Loss 1.3873 (1.3873)	LossFusion 1.3873 (1.3873)	
Train Epoch: [27][0/8]	Loss 1.3873 (1.3873)	LossFusion 1.3873 (1.3873)	
Train Epoch: [27][0/8]	Loss 1.3873 (1.3873)	LossFusion 1.3873 (1.3873)	
Train Epoch: [27][0/8]	Loss 1.3873 (1.3873)	LossFusion 1.3873 (1.3873)	
Train Epoch: [27][0/8]	Loss 1.3873 (1.3873)	LossFusion 1.3873 (1.3873)	
Train Epoch: [27][0/8]	Loss 1.3873 (1.3873)	LossFusion 1.3873 (1.3873)	
Train Epoch: [27][0/8]	Loss 1.3873 (1.3873)	LossFusion 1.3873 (1.3873)	
Train Epoch: [27][7/8]	Loss 0.7930 (1.0873)	LossFusion 0.7930 (1.0873)	
Train Epoch: [27][7/8]	Loss 0.7930 (1.0873)	LossFusion 0.7930 (1.0873)	
Train Epoch: [27][7/8]	Loss 0.7930 (1.0873)	LossFusion 0.7930 (1.0873)	
Train Epoch: [27][7/8]	Loss 0.7930 (1.0873)	LossFusion 0.7930 (1.0873)	
Train Epoch: [27][7/8]	Loss 0.7930 (1.0873)	LossFusion 0.7930 (1.0873)	
Train Epoch: [27][7/8]	Loss 0.7930 (1.0873)	LossFusion 0.7930 (1.0873)	
Train Epoch: [27][7/8]	Loss 0.7930 (1.0873)	LossFusion 0.7930 (1.0873)	
Train Epoch: [27][7/8]	Loss 0.7930 (1.0873)	LossFusion 0.7930 (1.0873)	
R@10:  R@10: 55.423057079315186     R@50:   81.48779273033142
55.423057079315186 Mean Now:     R@50:   68.455424904823381.48779273033142  Best Mean Before: 
 68.51221 Mean Now: -------------------- 
68.4554249048233  Best Mean Before:  68.51221 --------------------
R@10:  55.423057079315186     R@50:  81.48779273033142
Mean Now:  68.4554249048233  Best Mean Before:  68.51221 --------------------
R@10:  55.423057079315186     R@50:  81.48779273033142
Mean Now:  68.4554249048233  Best Mean Before:  68.51221 --------------------
R@10:  55.423057079315186     R@50:  81.48779273033142
Mean Now:  68.4554249048233  Best Mean Before:  68.51221 --------------------
R@10:  55.423057079315186     R@50:  81.48779273033142
Mean Now:  68.4554249048233  Best Mean Before:  68.51221 --------------------
R@10:  55.423057079315186     R@50:  81.48779273033142
Mean Now:  68.4554249048233  Best Mean Before:  68.51221 --------------------
R@10:  55.423057079315186     R@50:  81.48779273033142
Mean Now:  68.4554249048233  Best Mean Before:  68.51221 --------------------
Train Epoch: [28][0/8]	Loss 1.3354 (1.3354)	LossFusion 1.3354 (1.3354)	
Train Epoch: [28][0/8]	Loss 1.3354 (1.3354)	LossFusion 1.3354 (1.3354)	
Train Epoch: [28][0/8]	Loss 1.3354 (1.3354)	LossFusion 1.3354 (1.3354)	
Train Epoch: [28][0/8]	Loss 1.3354 (1.3354)	LossFusion 1.3354 (1.3354)	
Train Epoch: [28][0/8]	Loss 1.3354 (1.3354)	LossFusion 1.3354 (1.3354)	
Train Epoch: [28][0/8]	Loss 1.3354 (1.3354)	LossFusion 1.3354 (1.3354)	
Train Epoch: [28][0/8]	Loss 1.3354 (1.3354)	LossFusion 1.3354 (1.3354)	
Train Epoch: [28][0/8]	Loss 1.3354 (1.3354)	LossFusion 1.3354 (1.3354)	
Train Epoch: [28][7/8]	Loss 0.7679 (1.0728)	LossFusion 0.7679 (1.0728)	
Train Epoch: [28][7/8]	Loss 0.7679 (1.0728)	LossFusion 0.7679 (1.0728)	
Train Epoch: [28][7/8]	Loss 0.7679 (1.0728)	LossFusion 0.7679 (1.0728)	
Train Epoch: [28][7/8]	Loss 0.7679 (1.0728)	LossFusion 0.7679 (1.0728)	
Train Epoch: [28][7/8]	Loss 0.7679 (1.0728)	LossFusion 0.7679 (1.0728)	
Train Epoch: [28][7/8]	Loss 0.7679 (1.0728)	LossFusion 0.7679 (1.0728)	
Train Epoch: [28][7/8]	Loss 0.7679 (1.0728)	LossFusion 0.7679 (1.0728)	
Train Epoch: [28][7/8]	Loss 0.7679 (1.0728)	LossFusion 0.7679 (1.0728)	
R@10:  55.70698380470276     R@50:  81.54457807540894
Best Mean Now:  68.62578 ******************************
R@10:  55.70698380470276     R@50:  81.54457807540894
Best Mean Now:  68.62578 ******************************
R@10:  55.70698380470276     R@50:  81.54457807540894
Best Mean Now:  68.62578 ******************************
R@10:  55.70698380470276     R@50:  81.54457807540894
Best Mean Now:  68.62578 ******************************
R@10:  55.70698380470276     R@50:  81.54457807540894
Best Mean Now:  68.62578 ******************************
R@10:  55.70698380470276     R@50:  81.54457807540894
Best Mean Now:  68.62578 ******************************
R@10:  55.70698380470276     R@50:  81.54457807540894
Best Mean Now:  68.62578 ******************************
R@10:  55.70698380470276     R@50:  81.54457807540894
Best Mean Now:  68.62578 ******************************
Train Epoch: [29][0/8]	Loss 1.2896 (1.2896)	LossFusion 1.2896 (1.2896)	
Train Epoch: [29][0/8]	Loss 1.2896 (1.2896)	LossFusion 1.2896 (1.2896)	
Train Epoch: [29][0/8]	Loss 1.2896 (1.2896)	LossFusion 1.2896 (1.2896)	
Train Epoch: [29][0/8]	Loss 1.2896 (1.2896)	LossFusion 1.2896 (1.2896)	
Train Epoch: [29][0/8]	Loss 1.2896 (1.2896)	LossFusion 1.2896 (1.2896)	
Train Epoch: [29][0/8]	Loss 1.2896 (1.2896)	LossFusion 1.2896 (1.2896)	
Train Epoch: [29][0/8]	Loss 1.2896 (1.2896)	LossFusion 1.2896 (1.2896)	
Train Epoch: [29][0/8]	Loss 1.2896 (1.2896)	LossFusion 1.2896 (1.2896)	
Train Epoch: [29][7/8]	Loss 0.7569 (1.0297)	LossFusion 0.7569 (1.0297)	
Train Epoch: [29][7/8]	Loss 0.7569 (1.0297)	LossFusion 0.7569 (1.0297)	
Train Epoch: [29][7/8]	Loss 0.7569 (1.0297)	LossFusion 0.7569 (1.0297)	
Train Epoch: [29][7/8]	Loss 0.7569 (1.0297)	LossFusion 0.7569 (1.0297)	
Train Epoch: [29][7/8]	Loss 0.7569 (1.0297)	LossFusion 0.7569 (1.0297)	
Train Epoch: [29][7/8]	Loss 0.7569 (1.0297)	LossFusion 0.7569 (1.0297)	
Train Epoch: [29][7/8]	Loss 0.7569 (1.0297)	LossFusion 0.7569 (1.0297)	
Train Epoch: [29][7/8]	Loss 0.7569 (1.0297)	LossFusion 0.7569 (1.0297)	
R@10:  55.536627769470215     R@50:  81.771719455719
Best Mean Now:  68.65417 ******************************
R@10:  55.536627769470215     R@50:  81.771719455719
Best Mean Now:  68.65417 ******************************
R@10:  55.536627769470215     R@50:  81.771719455719
Best Mean Now:  68.65417 ******************************
R@10:  55.536627769470215     R@50:  81.771719455719
Best Mean Now:  68.65417 ******************************
R@10:  55.536627769470215     R@50:  81.771719455719
Best Mean Now:  68.65417 ******************************
R@10:  55.536627769470215     R@50:  81.771719455719
Best Mean Now:  68.65417 ******************************
R@10:  55.536627769470215     R@50:  81.771719455719
Best Mean Now:  68.65417 ******************************
R@10:  55.536627769470215     R@50:  81.771719455719
Best Mean Now:  68.65417 ******************************
Train Epoch: [30][0/8]	Loss 1.2946 (1.2946)	LossFusion 1.2946 (1.2946)	
Train Epoch: [30][0/8]	Loss 1.2946 (1.2946)	LossFusion 1.2946 (1.2946)	
Train Epoch: [30][0/8]	Loss 1.2946 (1.2946)	LossFusion 1.2946 (1.2946)	
Train Epoch: [30][0/8]	Loss 1.2946 (1.2946)	LossFusion 1.2946 (1.2946)	
Train Epoch: [30][0/8]	Loss 1.2946 (1.2946)	LossFusion 1.2946 (1.2946)	
Train Epoch: [30][0/8]	Loss 1.2946 (1.2946)	LossFusion 1.2946 (1.2946)	
Train Epoch: [30][0/8]	Loss 1.2946 (1.2946)	LossFusion 1.2946 (1.2946)	
Train Epoch: [30][0/8]	Loss 1.2946 (1.2946)	LossFusion 1.2946 (1.2946)	
Train Epoch: [30][7/8]	Loss 0.7436 (1.0198)	LossFusion 0.7436 (1.0198)	
Train Epoch: [30][7/8]	Loss 0.7436 (1.0198)	LossFusion 0.7436 (1.0198)	
Train Epoch: [30][7/8]	Loss 0.7436 (1.0198)	LossFusion 0.7436 (1.0198)	
Train Epoch: [30][7/8]	Loss 0.7436 (1.0198)	LossFusion 0.7436 (1.0198)	
Train Epoch: [30][7/8]	Loss 0.7436 (1.0198)	LossFusion 0.7436 (1.0198)	
Train Epoch: [30][7/8]	Loss 0.7436 (1.0198)	LossFusion 0.7436 (1.0198)	
Train Epoch: [30][7/8]	Loss 0.7436 (1.0198)	LossFusion 0.7436 (1.0198)	
Train Epoch: [30][7/8]	Loss 0.7436 (1.0198)	LossFusion 0.7436 (1.0198)	
R@10:  56.16127252578735     R@50:  81.60136342048645
Best Mean Now:  68.88132 ******************************
R@10:  56.16127252578735     R@50:  81.60136342048645
Best Mean Now:  68.88132 ******************************
R@10:  56.16127252578735     R@50:  81.60136342048645
Best Mean Now:  68.88132 ******************************
R@10:  56.16127252578735     R@50:  81.60136342048645
Best Mean Now:  68.88132 ******************************
R@10:  56.16127252578735     R@50:  81.60136342048645
Best Mean Now:  68.88132 ******************************
R@10:  56.16127252578735     R@50:  81.60136342048645
Best Mean Now:  68.88132 ******************************
R@10:  56.16127252578735     R@50:  81.60136342048645
Best Mean Now:  68.88132 ******************************
R@10:  56.16127252578735     R@50:  81.60136342048645
Best Mean Now:  68.88132 ******************************
Train Epoch: [31][0/8]	Loss 1.2722 (1.2722)	LossFusion 1.2722 (1.2722)	
Train Epoch: [31][0/8]	Loss 1.2722 (1.2722)	LossFusion 1.2722 (1.2722)	
Train Epoch: [31][0/8]	Loss 1.2722 (1.2722)	LossFusion 1.2722 (1.2722)	
Train Epoch: [31][0/8]	Loss 1.2722 (1.2722)	LossFusion 1.2722 (1.2722)	
Train Epoch: [31][0/8]	Loss 1.2722 (1.2722)	LossFusion 1.2722 (1.2722)	
Train Epoch: [31][0/8]	Loss 1.2722 (1.2722)	LossFusion 1.2722 (1.2722)	
Train Epoch: [31][0/8]	Loss 1.2722 (1.2722)	LossFusion 1.2722 (1.2722)	
Train Epoch: [31][0/8]	Loss 1.2722 (1.2722)	LossFusion 1.2722 (1.2722)	
Train Epoch: [31][7/8]	Loss 0.7313 (1.0017)	LossFusion 0.7313 (1.0017)	
Train Epoch: [31][7/8]	Loss 0.7313 (1.0017)	LossFusion 0.7313 (1.0017)	
Train Epoch: [31][7/8]	Loss 0.7313 (1.0017)	LossFusion 0.7313 (1.0017)	
Train Epoch: [31][7/8]	Loss 0.7313 (1.0017)	LossFusion 0.7313 (1.0017)	
Train Epoch: [31][7/8]	Loss 0.7313 (1.0017)	LossFusion 0.7313 (1.0017)	
Train Epoch: [31][7/8]	Loss 0.7313 (1.0017)	LossFusion 0.7313 (1.0017)	
Train Epoch: [31][7/8]	Loss 0.7313 (1.0017)	LossFusion 0.7313 (1.0017)	
Train Epoch: [31][7/8]	Loss 0.7313 (1.0017)	LossFusion 0.7313 (1.0017)	
R@10:  55.536627769470215     R@50:  81.65814876556396
Mean Now:  68.59738826751709  Best Mean Before:  68.88132 --------------------
R@10:  55.536627769470215     R@50:  81.65814876556396
Mean Now:  68.59738826751709  Best Mean Before:  68.88132 --------------------
R@10:  55.536627769470215     R@50:  81.65814876556396
Mean Now:  68.59738826751709  Best Mean Before:  68.88132 --------------------
R@10:  55.536627769470215     R@50:  81.65814876556396
Mean Now:  68.59738826751709  Best Mean Before:  68.88132 --------------------
R@10:  55.536627769470215     R@50:  81.65814876556396
Mean Now:  68.59738826751709  Best Mean Before:  68.88132 --------------------
R@10:  55.536627769470215     R@50:  81.65814876556396
Mean Now:  68.59738826751709  Best Mean Before:  68.88132 --------------------
R@10:  55.536627769470215     R@50:  81.65814876556396
Mean Now:  68.59738826751709  Best Mean Before:  68.88132 --------------------
R@10:  55.536627769470215     R@50:  81.65814876556396
Mean Now:  68.59738826751709  Best Mean Before:  68.88132 --------------------
Train Epoch: [32][0/8]	Loss 1.2219 (1.2219)	LossFusion 1.2219 (1.2219)	
Train Epoch: [32][0/8]	Loss 1.2219 (1.2219)	LossFusion 1.2219 (1.2219)	
Train Epoch: [32][0/8]	Loss 1.2219 (1.2219)	LossFusion 1.2219 (1.2219)	
Train Epoch: [32][0/8]	Loss 1.2219 (1.2219)	LossFusion 1.2219 (1.2219)	
Train Epoch: [32][0/8]	Loss 1.2219 (1.2219)	LossFusion 1.2219 (1.2219)	
Train Epoch: [32][0/8]	Loss 1.2219 (1.2219)	LossFusion 1.2219 (1.2219)	
Train Epoch: [32][0/8]	Loss 1.2219 (1.2219)	LossFusion 1.2219 (1.2219)	
Train Epoch: [32][0/8]	Loss 1.2219 (1.2219)	LossFusion 1.2219 (1.2219)	
Train Epoch: [32][7/8]	Loss 0.7672 (0.9987)	LossFusion 0.7672 (0.9987)	
Train Epoch: [32][7/8]	Loss 0.7672 (0.9987)	LossFusion 0.7672 (0.9987)	
Train Epoch: [32][7/8]	Loss 0.7672 (0.9987)	LossFusion 0.7672 (0.9987)	
Train Epoch: [32][7/8]	Loss 0.7672 (0.9987)	LossFusion 0.7672 (0.9987)	
Train Epoch: [32][7/8]	Loss 0.7672 (0.9987)	LossFusion 0.7672 (0.9987)	
Train Epoch: [32][7/8]	Loss 0.7672 (0.9987)	LossFusion 0.7672 (0.9987)	
Train Epoch: [32][7/8]	Loss 0.7672 (0.9987)	LossFusion 0.7672 (0.9987)	
Train Epoch: [32][7/8]	Loss 0.7672 (0.9987)	LossFusion 0.7672 (0.9987)	
R@10:  55.423057079315186     R@50:  81.71493411064148
Mean Now:  68.56899559497833  Best Mean Before:  68.88132 --------------------
R@10:  55.423057079315186     R@50:  81.71493411064148
Mean Now:  68.56899559497833  Best Mean Before:  68.88132 --------------------
R@10:  55.423057079315186     R@50:  81.71493411064148
Mean Now:  68.56899559497833  Best Mean Before:  68.88132 --------------------
R@10:  55.423057079315186     R@50:  81.71493411064148
Mean Now:  68.56899559497833  Best Mean Before:  68.88132 --------------------
R@10:  55.423057079315186     R@50:  81.71493411064148
Mean Now:  68.56899559497833  Best Mean Before:  68.88132 --------------------
R@10:  55.423057079315186     R@50:  81.71493411064148
Mean Now:  68.56899559497833  Best Mean Before:  68.88132 --------------------
R@10:  55.423057079315186     R@50:  81.71493411064148
Mean Now:  68.56899559497833  Best Mean Before:  68.88132 --------------------
R@10:  55.423057079315186     R@50:  81.71493411064148
Mean Now:  68.56899559497833  Best Mean Before:  68.88132 --------------------
Train Epoch: [33][0/8]	Loss 1.2082 (1.2082)	LossFusion 1.2082 (1.2082)	Train Epoch: [33][0/8]	Loss 1.2082 (1.2082)	LossFusion 1.2082 (1.2082)	

Train Epoch: [33][0/8]	Loss 1.2082 (1.2082)	LossFusion 1.2082 (1.2082)	
Train Epoch: [33][0/8]	Loss 1.2082 (1.2082)	LossFusion 1.2082 (1.2082)	
Train Epoch: [33][0/8]	Loss 1.2082 (1.2082)	LossFusion 1.2082 (1.2082)	
Train Epoch: [33][0/8]	Loss 1.2082 (1.2082)	LossFusion 1.2082 (1.2082)	
Train Epoch: [33][0/8]	Loss 1.2082 (1.2082)	LossFusion 1.2082 (1.2082)	
Train Epoch: [33][0/8]	Loss 1.2082 (1.2082)	LossFusion 1.2082 (1.2082)	
Train Epoch: [33][7/8]	Loss 0.6922 (0.9623)	LossFusion 0.6922 (0.9623)	
Train Epoch: [33][7/8]	Loss 0.6922 (0.9623)	LossFusion 0.6922 (0.9623)	
Train Epoch: [33][7/8]	Loss 0.6922 (0.9623)	LossFusion 0.6922 (0.9623)	
Train Epoch: [33][7/8]	Loss 0.6922 (0.9623)	LossFusion 0.6922 (0.9623)	
Train Epoch: [33][7/8]	Loss 0.6922 (0.9623)	LossFusion 0.6922 (0.9623)	
Train Epoch: [33][7/8]	Loss 0.6922 (0.9623)	LossFusion 0.6922 (0.9623)	
Train Epoch: [33][7/8]	Loss 0.6922 (0.9623)	LossFusion 0.6922 (0.9623)	
Train Epoch: [33][7/8]	Loss 0.6922 (0.9623)	LossFusion 0.6922 (0.9623)	
R@10:  56.10448718070984     R@50:  81.99886679649353
Best Mean Now:  69.05168 ******************************
R@10:  56.10448718070984     R@50:  81.99886679649353
Best Mean Now:  69.05168 ******************************
R@10:  56.10448718070984     R@50:  81.99886679649353
Best Mean Now:  69.05168 ******************************
R@10:  56.10448718070984     R@50:  81.99886679649353
Best Mean Now:  69.05168 ******************************
R@10:  56.10448718070984     R@50:  81.99886679649353
Best Mean Now:  69.05168 ******************************
R@10:  56.10448718070984     R@50:  81.99886679649353
Best Mean Now:  69.05168 ******************************
R@10:  56.10448718070984     R@50:  81.99886679649353
Best Mean Now:  69.05168 ******************************
R@10:  56.10448718070984     R@50:  81.99886679649353
Best Mean Now:  69.05168 ******************************
Train Epoch: [34][0/8]	Loss 1.1625 (1.1625)	LossFusion 1.1625 (1.1625)	
Train Epoch: [34][0/8]	Loss 1.1625 (1.1625)	LossFusion 1.1625 (1.1625)	
Train Epoch: [34][0/8]	Loss 1.1625 (1.1625)	LossFusion 1.1625 (1.1625)	
Train Epoch: [34][0/8]	Loss 1.1625 (1.1625)	LossFusion 1.1625 (1.1625)	
Train Epoch: [34][0/8]	Loss 1.1625 (1.1625)	LossFusion 1.1625 (1.1625)	
Train Epoch: [34][0/8]	Loss 1.1625 (1.1625)	LossFusion 1.1625 (1.1625)	
Train Epoch: [34][0/8]	Loss 1.1625 (1.1625)	LossFusion 1.1625 (1.1625)	
Train Epoch: [34][0/8]	Loss 1.1625 (1.1625)	LossFusion 1.1625 (1.1625)	
Train Epoch: [34][7/8]	Loss 0.6927 (0.9466)	LossFusion 0.6927 (0.9466)	
Train Epoch: [34][7/8]	Loss 0.6927 (0.9466)	LossFusion 0.6927 (0.9466)	
Train Epoch: [34][7/8]	Loss 0.6927 (0.9466)	LossFusion 0.6927 (0.9466)	
Train Epoch: [34][7/8]	Loss 0.6927 (0.9466)	LossFusion 0.6927 (0.9466)	
Train Epoch: [34][7/8]	Loss 0.6927 (0.9466)	LossFusion 0.6927 (0.9466)	
Train Epoch: [34][7/8]	Loss 0.6927 (0.9466)	LossFusion 0.6927 (0.9466)	
Train Epoch: [34][7/8]	Loss 0.6927 (0.9466)	LossFusion 0.6927 (0.9466)	
Train Epoch: [34][7/8]	Loss 0.6927 (0.9466)	LossFusion 0.6927 (0.9466)	
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.05168 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.05168 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.05168 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.05168 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.05168 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.05168 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.05168 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.05168 --------------------
Train Epoch: [35][0/8]	Loss 1.1675 (1.1675)	LossFusion 1.1675 (1.1675)	
Train Epoch: [35][0/8]	Loss 1.1675 (1.1675)	LossFusion 1.1675 (1.1675)	
Train Epoch: [35][0/8]	Loss 1.1675 (1.1675)	LossFusion 1.1675 (1.1675)	
Train Epoch: [35][0/8]	Loss 1.1675 (1.1675)	LossFusion 1.1675 (1.1675)	
Train Epoch: [35][0/8]	Loss 1.1675 (1.1675)	LossFusion 1.1675 (1.1675)	
Train Epoch: [35][0/8]	Loss 1.1675 (1.1675)	LossFusion 1.1675 (1.1675)	
Train Epoch: [35][0/8]	Loss 1.1675 (1.1675)	LossFusion 1.1675 (1.1675)	
Train Epoch: [35][0/8]	Loss 1.1675 (1.1675)	LossFusion 1.1675 (1.1675)	
Train Epoch: [35][7/8]	Loss 0.7063 (0.9358)	LossFusion 0.7063 (0.9358)	
Train Epoch: [35][7/8]	Loss 0.7063 (0.9358)	LossFusion 0.7063 (0.9358)	
Train Epoch: [35][7/8]	Loss 0.7063 (0.9358)	LossFusion 0.7063 (0.9358)	
Train Epoch: [35][7/8]	Loss 0.7063 (0.9358)	LossFusion 0.7063 (0.9358)	
Train Epoch: [35][7/8]	Loss 0.7063 (0.9358)	LossFusion 0.7063 (0.9358)	
Train Epoch: [35][7/8]	Loss 0.7063 (0.9358)	LossFusion 0.7063 (0.9358)	
Train Epoch: [35][7/8]	Loss 0.7063 (0.9358)	LossFusion 0.7063 (0.9358)	
Train Epoch: [35][7/8]	Loss 0.7063 (0.9358)	LossFusion 0.7063 (0.9358)	
R@10:  56.44519925117493     R@50:  81.60136342048645
Mean Now:  69.02328133583069  Best Mean Before:  69.05168 --------------------
R@10:  56.44519925117493     R@50:  81.60136342048645
Mean Now:  69.02328133583069  Best Mean Before:  69.05168 --------------------
R@10:  56.44519925117493     R@50:  81.60136342048645
Mean Now:  69.02328133583069  Best Mean Before:  69.05168 --------------------
R@10:  56.44519925117493     R@50:  81.60136342048645
Mean Now:  69.02328133583069  Best Mean Before:  69.05168 --------------------
R@10:  56.44519925117493     R@50:  81.60136342048645
Mean Now:  69.02328133583069  Best Mean Before:  69.05168 --------------------
R@10:  56.44519925117493     R@50:  81.60136342048645
Mean Now:  69.02328133583069  Best Mean Before:  69.05168 --------------------
R@10:  56.44519925117493     R@50:  81.60136342048645
Mean Now:  69.02328133583069  Best Mean Before:  69.05168 --------------------
R@10:  56.44519925117493     R@50:  81.60136342048645
Mean Now:  69.02328133583069  Best Mean Before:  69.05168 --------------------
Train Epoch: [36][0/8]	Loss 1.1800 (1.1800)	LossFusion 1.1800 (1.1800)	
Train Epoch: [36][0/8]	Loss 1.1800 (1.1800)	LossFusion 1.1800 (1.1800)	
Train Epoch: [36][0/8]	Loss 1.1800 (1.1800)	LossFusion 1.1800 (1.1800)	
Train Epoch: [36][0/8]	Loss 1.1800 (1.1800)	LossFusion 1.1800 (1.1800)	
Train Epoch: [36][0/8]	Loss 1.1800 (1.1800)	LossFusion 1.1800 (1.1800)	
Train Epoch: [36][0/8]	Loss 1.1800 (1.1800)	LossFusion 1.1800 (1.1800)	
Train Epoch: [36][0/8]	Loss 1.1800 (1.1800)	LossFusion 1.1800 (1.1800)	
Train Epoch: [36][0/8]	Loss 1.1800 (1.1800)	LossFusion 1.1800 (1.1800)	
Train Epoch: [36][7/8]	Loss 0.6599 (0.9289)	LossFusion 0.6599 (0.9289)	
Train Epoch: [36][7/8]	Loss 0.6599 (0.9289)	LossFusion 0.6599 (0.9289)	
Train Epoch: [36][7/8]	Loss 0.6599 (0.9289)	LossFusion 0.6599 (0.9289)	
Train Epoch: [36][7/8]	Loss 0.6599 (0.9289)	LossFusion 0.6599 (0.9289)	
Train Epoch: [36][7/8]	Loss 0.6599 (0.9289)	LossFusion 0.6599 (0.9289)	
Train Epoch: [36][7/8]	Loss 0.6599 (0.9289)	LossFusion 0.6599 (0.9289)	
Train Epoch: [36][7/8]	Loss 0.6599 (0.9289)	LossFusion 0.6599 (0.9289)	
Train Epoch: [36][7/8]	Loss 0.6599 (0.9289)	LossFusion 0.6599 (0.9289)	
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.05168 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.05168 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.05168 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.05168 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.05168 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.05168 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.05168 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.05168 --------------------
Train Epoch: [37][0/8]	Loss 1.0872 (1.0872)	LossFusion 1.0872 (1.0872)	
Train Epoch: [37][0/8]	Loss 1.0872 (1.0872)	LossFusion 1.0872 (1.0872)	
Train Epoch: [37][0/8]	Loss 1.0872 (1.0872)	LossFusion 1.0872 (1.0872)	
Train Epoch: [37][0/8]	Loss 1.0872 (1.0872)	LossFusion 1.0872 (1.0872)	
Train Epoch: [37][0/8]	Loss 1.0872 (1.0872)	LossFusion 1.0872 (1.0872)	
Train Epoch: [37][0/8]	Loss 1.0872 (1.0872)	LossFusion 1.0872 (1.0872)	
Train Epoch: [37][0/8]	Loss 1.0872 (1.0872)	LossFusion 1.0872 (1.0872)	
Train Epoch: [37][0/8]	Loss 1.0872 (1.0872)	LossFusion 1.0872 (1.0872)	
Train Epoch: [37][7/8]	Loss 0.6593 (0.8971)	LossFusion 0.6593 (0.8971)	
Train Epoch: [37][7/8]	Loss 0.6593 (0.8971)	LossFusion 0.6593 (0.8971)	
Train Epoch: [37][7/8]	Loss 0.6593 (0.8971)	LossFusion 0.6593 (0.8971)	
Train Epoch: [37][7/8]	Loss 0.6593 (0.8971)	LossFusion 0.6593 (0.8971)	
Train Epoch: [37][7/8]	Loss 0.6593 (0.8971)	LossFusion 0.6593 (0.8971)	
Train Epoch: [37][7/8]	Loss 0.6593 (0.8971)	LossFusion 0.6593 (0.8971)	
Train Epoch: [37][7/8]	Loss 0.6593 (0.8971)	LossFusion 0.6593 (0.8971)	
Train Epoch: [37][7/8]	Loss 0.6593 (0.8971)	LossFusion 0.6593 (0.8971)	
R@10:  56.21805787086487     R@50:  81.54457807540894
Mean Now:  68.8813179731369  Best Mean Before:  69.05168 --------------------
R@10:  56.21805787086487     R@50:  81.54457807540894
Mean Now:  68.8813179731369  Best Mean Before:  69.05168 --------------------
R@10:  56.21805787086487     R@50:  81.54457807540894
Mean Now:  68.8813179731369  Best Mean Before:  69.05168 --------------------
R@10:  56.21805787086487     R@50:  81.54457807540894
Mean Now:  68.8813179731369  Best Mean Before:  69.05168 --------------------
R@10:  56.21805787086487     R@50:  81.54457807540894
Mean Now:  68.8813179731369  Best Mean Before:  69.05168 --------------------
R@10:  56.21805787086487     R@50:  81.54457807540894
Mean Now:  68.8813179731369  Best Mean Before:  69.05168 --------------------
R@10:  56.21805787086487     R@50:  81.54457807540894
Mean Now:  68.8813179731369  Best Mean Before:  69.05168 --------------------
R@10:  56.21805787086487     R@50:  81.54457807540894
Mean Now:  68.8813179731369  Best Mean Before:  69.05168 --------------------
Train Epoch: [38][0/8]	Loss 1.1110 (1.1110)	LossFusion 1.1110 (1.1110)	
Train Epoch: [38][0/8]	Loss 1.1110 (1.1110)	LossFusion 1.1110 (1.1110)	
Train Epoch: [38][0/8]	Loss 1.1110 (1.1110)	LossFusion 1.1110 (1.1110)	
Train Epoch: [38][0/8]	Loss 1.1110 (1.1110)	LossFusion 1.1110 (1.1110)	
Train Epoch: [38][0/8]	Loss 1.1110 (1.1110)	LossFusion 1.1110 (1.1110)	
Train Epoch: [38][0/8]	Loss 1.1110 (1.1110)	LossFusion 1.1110 (1.1110)	
Train Epoch: [38][0/8]	Loss 1.1110 (1.1110)	LossFusion 1.1110 (1.1110)	
Train Epoch: [38][0/8]	Loss 1.1110 (1.1110)	LossFusion 1.1110 (1.1110)	
Train Epoch: [38][7/8]	Loss 0.6479 (0.8860)	LossFusion 0.6479 (0.8860)	
Train Epoch: [38][7/8]	Loss 0.6479 (0.8860)	LossFusion 0.6479 (0.8860)	
Train Epoch: [38][7/8]	Loss 0.6479 (0.8860)	LossFusion 0.6479 (0.8860)	
Train Epoch: [38][7/8]	Loss 0.6479 (0.8860)	LossFusion 0.6479 (0.8860)	
Train Epoch: [38][7/8]	Loss 0.6479 (0.8860)	LossFusion 0.6479 (0.8860)	
Train Epoch: [38][7/8]	Loss 0.6479 (0.8860)	LossFusion 0.6479 (0.8860)	
Train Epoch: [38][7/8]	Loss 0.6479 (0.8860)	LossFusion 0.6479 (0.8860)	
Train Epoch: [38][7/8]	Loss 0.6479 (0.8860)	LossFusion 0.6479 (0.8860)	
R@10:  56.89948797225952     R@50:  81.99886679649353
Best Mean Now:  69.44918 ******************************
R@10:  56.89948797225952     R@50:  81.99886679649353
Best Mean Now:  69.44918 ******************************
R@10:  56.89948797225952     R@50:  81.99886679649353
Best Mean Now:  69.44918 ******************************
R@10:  56.89948797225952     R@50:  81.99886679649353
Best Mean Now:  69.44918 ******************************
R@10:  56.89948797225952     R@50:  81.99886679649353
Best Mean Now:  69.44918 ******************************
R@10:  56.89948797225952     R@50:  81.99886679649353
Best Mean Now:  69.44918 ******************************
R@10:  56.89948797225952     R@50:  81.99886679649353
Best Mean Now:  69.44918 ******************************
R@10:  56.89948797225952     R@50:  81.99886679649353
Best Mean Now:  69.44918 ******************************
Train Epoch: [39][0/8]	Loss 1.1509 (1.1509)	LossFusion 1.1509 (1.1509)	
Train Epoch: [39][0/8]	Loss 1.1509 (1.1509)	LossFusion 1.1509 (1.1509)	Train Epoch: [39][0/8]	Loss 1.1509 (1.1509)	LossFusion 1.1509 (1.1509)	

Train Epoch: [39][0/8]	Loss 1.1509 (1.1509)	LossFusion 1.1509 (1.1509)	
Train Epoch: [39][0/8]	Loss 1.1509 (1.1509)	LossFusion 1.1509 (1.1509)	
Train Epoch: [39][0/8]	Loss 1.1509 (1.1509)	LossFusion 1.1509 (1.1509)	
Train Epoch: [39][0/8]	Loss 1.1509 (1.1509)	LossFusion 1.1509 (1.1509)	
Train Epoch: [39][0/8]	Loss 1.1509 (1.1509)	LossFusion 1.1509 (1.1509)	
Train Epoch: [39][7/8]	Loss 0.6561 (0.8802)	LossFusion 0.6561 (0.8802)	
Train Epoch: [39][7/8]	Loss 0.6561 (0.8802)	LossFusion 0.6561 (0.8802)	
Train Epoch: [39][7/8]	Loss 0.6561 (0.8802)	LossFusion 0.6561 (0.8802)	
Train Epoch: [39][7/8]	Loss 0.6561 (0.8802)	LossFusion 0.6561 (0.8802)	
Train Epoch: [39][7/8]	Loss 0.6561 (0.8802)	LossFusion 0.6561 (0.8802)	
Train Epoch: [39][7/8]	Loss 0.6561 (0.8802)	LossFusion 0.6561 (0.8802)	
Train Epoch: [39][7/8]	Loss 0.6561 (0.8802)	LossFusion 0.6561 (0.8802)	
Train Epoch: [39][7/8]	Loss 0.6561 (0.8802)	LossFusion 0.6561 (0.8802)	
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.99886679649353
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
Train Epoch: [40][0/8]	Loss 1.0804 (1.0804)	LossFusion 1.0804 (1.0804)	
Train Epoch: [40][0/8]	Loss 1.0804 (1.0804)	LossFusion 1.0804 (1.0804)	
Train Epoch: [40][0/8]	Loss 1.0804 (1.0804)	LossFusion 1.0804 (1.0804)	
Train Epoch: [40][0/8]	Loss 1.0804 (1.0804)	LossFusion 1.0804 (1.0804)	
Train Epoch: [40][0/8]	Loss 1.0804 (1.0804)	LossFusion 1.0804 (1.0804)	
Train Epoch: [40][0/8]	Loss 1.0804 (1.0804)	LossFusion 1.0804 (1.0804)	
Train Epoch: [40][0/8]	Loss 1.0804 (1.0804)	LossFusion 1.0804 (1.0804)	
Train Epoch: [40][0/8]	Loss 1.0804 (1.0804)	LossFusion 1.0804 (1.0804)	
Train Epoch: [40][7/8]	Loss 0.6072 (0.8529)	LossFusion 0.6072 (0.8529)	
Train Epoch: [40][7/8]	Loss 0.6072 (0.8529)	LossFusion 0.6072 (0.8529)	
Train Epoch: [40][7/8]	Loss 0.6072 (0.8529)	LossFusion 0.6072 (0.8529)	
Train Epoch: [40][7/8]	Loss 0.6072 (0.8529)	LossFusion 0.6072 (0.8529)	
Train Epoch: [40][7/8]	Loss 0.6072 (0.8529)	LossFusion 0.6072 (0.8529)	
Train Epoch: [40][7/8]	Loss 0.6072 (0.8529)	LossFusion 0.6072 (0.8529)	
Train Epoch: [40][7/8]	Loss 0.6072 (0.8529)	LossFusion 0.6072 (0.8529)	
Train Epoch: [40][7/8]	Loss 0.6072 (0.8529)	LossFusion 0.6072 (0.8529)	
R@10:  56.16127252578735     R@50:  81.99886679649353
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.99886679649353
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.99886679649353
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.99886679649353
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.99886679649353
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.99886679649353
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.99886679649353
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.99886679649353
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
Train Epoch: [41][0/8]	Loss 1.0223 (1.0223)	LossFusion 1.0223 (1.0223)	
Train Epoch: [41][0/8]	Loss 1.0223 (1.0223)	LossFusion 1.0223 (1.0223)	
Train Epoch: [41][0/8]	Loss 1.0223 (1.0223)	LossFusion 1.0223 (1.0223)	
Train Epoch: [41][0/8]	Loss 1.0223 (1.0223)	LossFusion 1.0223 (1.0223)	
Train Epoch: [41][0/8]	Loss 1.0223 (1.0223)	LossFusion 1.0223 (1.0223)	
Train Epoch: [41][0/8]	Loss 1.0223 (1.0223)	LossFusion 1.0223 (1.0223)	
Train Epoch: [41][0/8]	Loss 1.0223 (1.0223)	LossFusion 1.0223 (1.0223)	
Train Epoch: [41][0/8]	Loss 1.0223 (1.0223)	LossFusion 1.0223 (1.0223)	
Train Epoch: [41][7/8]	Loss 0.6170 (0.8328)	LossFusion 0.6170 (0.8328)	
Train Epoch: [41][7/8]	Loss 0.6170 (0.8328)	LossFusion 0.6170 (0.8328)	
Train Epoch: [41][7/8]	Loss 0.6170 (0.8328)	LossFusion 0.6170 (0.8328)	
Train Epoch: [41][7/8]	Loss 0.6170 (0.8328)	LossFusion 0.6170 (0.8328)	
Train Epoch: [41][7/8]	Loss 0.6170 (0.8328)	LossFusion 0.6170 (0.8328)	
Train Epoch: [41][7/8]	Loss 0.6170 (0.8328)	LossFusion 0.6170 (0.8328)	
Train Epoch: [41][7/8]	Loss 0.6170 (0.8328)	LossFusion 0.6170 (0.8328)	
Train Epoch: [41][7/8]	Loss 0.6170 (0.8328)	LossFusion 0.6170 (0.8328)	
R@10:  56.16127252578735     R@50:  81.65814876556396
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.65814876556396
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.65814876556396
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.65814876556396
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.65814876556396
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.65814876556396
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.65814876556396
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.16127252578735     R@50:  81.65814876556396
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
Train Epoch: [42][0/8]	Loss 1.0368 (1.0368)	LossFusion 1.0368 (1.0368)	Train Epoch: [42][0/8]	Loss 1.0368 (1.0368)	LossFusion 1.0368 (1.0368)	

Train Epoch: [42][0/8]	Loss 1.0368 (1.0368)	LossFusion 1.0368 (1.0368)	
Train Epoch: [42][0/8]	Loss 1.0368 (1.0368)	LossFusion 1.0368 (1.0368)	
Train Epoch: [42][0/8]	Loss 1.0368 (1.0368)	LossFusion 1.0368 (1.0368)	
Train Epoch: [42][0/8]	Loss 1.0368 (1.0368)	LossFusion 1.0368 (1.0368)	
Train Epoch: [42][0/8]	Loss 1.0368 (1.0368)	LossFusion 1.0368 (1.0368)	
Train Epoch: [42][0/8]	Loss 1.0368 (1.0368)	LossFusion 1.0368 (1.0368)	
Train Epoch: [42][7/8]	Loss 0.5835 (0.8242)	LossFusion 0.5835 (0.8242)	
Train Epoch: [42][7/8]	Loss 0.5835 (0.8242)	LossFusion 0.5835 (0.8242)	Train Epoch: [42][7/8]	Loss 0.5835 (0.8242)	LossFusion 0.5835 (0.8242)	

Train Epoch: [42][7/8]	Loss 0.5835 (0.8242)	LossFusion 0.5835 (0.8242)	
Train Epoch: [42][7/8]	Loss 0.5835 (0.8242)	LossFusion 0.5835 (0.8242)	
Train Epoch: [42][7/8]	Loss 0.5835 (0.8242)	LossFusion 0.5835 (0.8242)	
Train Epoch: [42][7/8]	Loss 0.5835 (0.8242)	LossFusion 0.5835 (0.8242)	
Train Epoch: [42][7/8]	Loss 0.5835 (0.8242)	LossFusion 0.5835 (0.8242)	
R@10:  56.558775901794434     R@50:  82.22600817680359
Mean Now:  69.39239203929901  Best Mean Before:  69.44918 --------------------
R@10:  56.558775901794434     R@50:  82.22600817680359
Mean Now:  69.39239203929901  Best Mean Before:  69.44918 --------------------
R@10:  56.558775901794434     R@50:  82.22600817680359
Mean Now:  69.39239203929901  Best Mean Before:  69.44918 --------------------
R@10:  56.558775901794434     R@50:  82.22600817680359
Mean Now:  69.39239203929901  Best Mean Before:  69.44918 --------------------
R@10:  56.558775901794434     R@50:  82.22600817680359
Mean Now:  69.39239203929901  Best Mean Before:  69.44918 --------------------
R@10:  56.558775901794434     R@50:  82.22600817680359
Mean Now:  69.39239203929901  Best Mean Before:  69.44918 --------------------
R@10:  56.558775901794434     R@50:  82.22600817680359
Mean Now:  69.39239203929901  Best Mean Before:  69.44918 --------------------
R@10:  56.558775901794434     R@50:  82.22600817680359
Mean Now:  69.39239203929901  Best Mean Before:  69.44918 --------------------
Train Epoch: [43][0/8]	Loss 1.0306 (1.0306)	LossFusion 1.0306 (1.0306)	
Train Epoch: [43][0/8]	Loss 1.0306 (1.0306)	LossFusion 1.0306 (1.0306)	
Train Epoch: [43][0/8]	Loss 1.0306 (1.0306)	LossFusion 1.0306 (1.0306)	
Train Epoch: [43][0/8]	Loss 1.0306 (1.0306)	LossFusion 1.0306 (1.0306)	
Train Epoch: [43][0/8]	Loss 1.0306 (1.0306)	LossFusion 1.0306 (1.0306)	Train Epoch: [43][0/8]	Loss 1.0306 (1.0306)	LossFusion 1.0306 (1.0306)	

Train Epoch: [43][0/8]	Loss 1.0306 (1.0306)	LossFusion 1.0306 (1.0306)	
Train Epoch: [43][0/8]	Loss 1.0306 (1.0306)	LossFusion 1.0306 (1.0306)	
Train Epoch: [43][7/8]	Loss 0.5639 (0.8044)	LossFusion 0.5639 (0.8044)	
Train Epoch: [43][7/8]	Loss 0.5639 (0.8044)	LossFusion 0.5639 (0.8044)	
Train Epoch: [43][7/8]	Loss 0.5639 (0.8044)	LossFusion 0.5639 (0.8044)	
Train Epoch: [43][7/8]	Loss 0.5639 (0.8044)	LossFusion 0.5639 (0.8044)	
Train Epoch: [43][7/8]	Loss 0.5639 (0.8044)	LossFusion 0.5639 (0.8044)	
Train Epoch: [43][7/8]	Loss 0.5639 (0.8044)	LossFusion 0.5639 (0.8044)	
Train Epoch: [43][7/8]	Loss 0.5639 (0.8044)	LossFusion 0.5639 (0.8044)	
Train Epoch: [43][7/8]	Loss 0.5639 (0.8044)	LossFusion 0.5639 (0.8044)	
R@10:  56.38841390609741     R@50:  81.82850480079651
Mean Now:  69.10845935344696  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.82850480079651
Mean Now:  69.10845935344696  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.82850480079651
Mean Now:  69.10845935344696  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.82850480079651
Mean Now:  69.10845935344696  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.82850480079651
Mean Now:  69.10845935344696  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.82850480079651
Mean Now:  69.10845935344696  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.82850480079651
Mean Now:  69.10845935344696  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.82850480079651
Mean Now:  69.10845935344696  Best Mean Before:  69.44918 --------------------
Train Epoch: [44][0/8]	Loss 1.0478 (1.0478)	LossFusion 1.0478 (1.0478)	
Train Epoch: [44][0/8]	Loss 1.0478 (1.0478)	LossFusion 1.0478 (1.0478)	
Train Epoch: [44][0/8]	Loss 1.0478 (1.0478)	LossFusion 1.0478 (1.0478)	
Train Epoch: [44][0/8]	Loss 1.0478 (1.0478)	LossFusion 1.0478 (1.0478)	
Train Epoch: [44][0/8]	Loss 1.0478 (1.0478)	LossFusion 1.0478 (1.0478)	
Train Epoch: [44][0/8]	Loss 1.0478 (1.0478)	LossFusion 1.0478 (1.0478)	
Train Epoch: [44][0/8]	Loss 1.0478 (1.0478)	LossFusion 1.0478 (1.0478)	
Train Epoch: [44][0/8]	Loss 1.0478 (1.0478)	LossFusion 1.0478 (1.0478)	
Train Epoch: [44][7/8]	Loss 0.5666 (0.8086)	LossFusion 0.5666 (0.8086)	
Train Epoch: [44][7/8]	Loss 0.5666 (0.8086)	LossFusion 0.5666 (0.8086)	
Train Epoch: [44][7/8]	Loss 0.5666 (0.8086)	LossFusion 0.5666 (0.8086)	
Train Epoch: [44][7/8]	Loss 0.5666 (0.8086)	LossFusion 0.5666 (0.8086)	
Train Epoch: [44][7/8]	Loss 0.5666 (0.8086)	LossFusion 0.5666 (0.8086)	
Train Epoch: [44][7/8]	Loss 0.5666 (0.8086)	LossFusion 0.5666 (0.8086)	
Train Epoch: [44][7/8]	Loss 0.5666 (0.8086)	LossFusion 0.5666 (0.8086)	
Train Epoch: [44][7/8]	Loss 0.5666 (0.8086)	LossFusion 0.5666 (0.8086)	
R@10:  56.047701835632324     R@50:  81.99886679649353
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.99886679649353
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.99886679649353
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.99886679649353
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.99886679649353
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.99886679649353
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.99886679649353
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.99886679649353
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
Train Epoch: [45][0/8]	Loss 0.9649 (0.9649)	LossFusion 0.9649 (0.9649)	
Train Epoch: [45][0/8]	Loss 0.9649 (0.9649)	LossFusion 0.9649 (0.9649)	
Train Epoch: [45][0/8]	Loss 0.9649 (0.9649)	LossFusion 0.9649 (0.9649)	
Train Epoch: [45][0/8]	Loss 0.9649 (0.9649)	LossFusion 0.9649 (0.9649)	
Train Epoch: [45][0/8]	Loss 0.9649 (0.9649)	LossFusion 0.9649 (0.9649)	
Train Epoch: [45][0/8]	Loss 0.9649 (0.9649)	LossFusion 0.9649 (0.9649)	
Train Epoch: [45][0/8]	Loss 0.9649 (0.9649)	LossFusion 0.9649 (0.9649)	
Train Epoch: [45][0/8]	Loss 0.9649 (0.9649)	LossFusion 0.9649 (0.9649)	
Train Epoch: [45][7/8]	Loss 0.5752 (0.7789)	LossFusion 0.5752 (0.7789)	
Train Epoch: [45][7/8]	Loss 0.5752 (0.7789)	LossFusion 0.5752 (0.7789)	
Train Epoch: [45][7/8]	Loss 0.5752 (0.7789)	LossFusion 0.5752 (0.7789)	
Train Epoch: [45][7/8]	Loss 0.5752 (0.7789)	LossFusion 0.5752 (0.7789)	
Train Epoch: [45][7/8]	Loss 0.5752 (0.7789)	LossFusion 0.5752 (0.7789)	
Train Epoch: [45][7/8]	Loss 0.5752 (0.7789)	LossFusion 0.5752 (0.7789)	
Train Epoch: [45][7/8]	Loss 0.5752 (0.7789)	LossFusion 0.5752 (0.7789)	
Train Epoch: [45][7/8]	Loss 0.5752 (0.7789)	LossFusion 0.5752 (0.7789)	
R@10:  55.650198459625244     R@50:  81.71493411064148
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.71493411064148
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.71493411064148
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.71493411064148
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.71493411064148
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.71493411064148
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.71493411064148
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.71493411064148
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
Train Epoch: [46][0/8]	Loss 0.9907 (0.9907)	LossFusion 0.9907 (0.9907)	
Train Epoch: [46][0/8]	Loss 0.9907 (0.9907)	LossFusion 0.9907 (0.9907)	
Train Epoch: [46][0/8]	Loss 0.9907 (0.9907)	LossFusion 0.9907 (0.9907)	
Train Epoch: [46][0/8]	Loss 0.9907 (0.9907)	LossFusion 0.9907 (0.9907)	
Train Epoch: [46][0/8]	Loss 0.9907 (0.9907)	LossFusion 0.9907 (0.9907)	
Train Epoch: [46][0/8]	Loss 0.9907 (0.9907)	LossFusion 0.9907 (0.9907)	
Train Epoch: [46][0/8]	Loss 0.9907 (0.9907)	LossFusion 0.9907 (0.9907)	
Train Epoch: [46][0/8]	Loss 0.9907 (0.9907)	LossFusion 0.9907 (0.9907)	
Train Epoch: [46][7/8]	Loss 0.5567 (0.7895)	LossFusion 0.5567 (0.7895)	
Train Epoch: [46][7/8]	Loss 0.5567 (0.7895)	LossFusion 0.5567 (0.7895)	
Train Epoch: [46][7/8]	Loss 0.5567 (0.7895)	LossFusion 0.5567 (0.7895)	
Train Epoch: [46][7/8]	Loss 0.5567 (0.7895)	LossFusion 0.5567 (0.7895)	
Train Epoch: [46][7/8]	Loss 0.5567 (0.7895)	LossFusion 0.5567 (0.7895)	
Train Epoch: [46][7/8]	Loss 0.5567 (0.7895)	LossFusion 0.5567 (0.7895)	
Train Epoch: [46][7/8]	Loss 0.5567 (0.7895)	LossFusion 0.5567 (0.7895)	
Train Epoch: [46][7/8]	Loss 0.5567 (0.7895)	LossFusion 0.5567 (0.7895)	
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
Train Epoch: [47][0/8]	Loss 0.9740 (0.9740)	LossFusion 0.9740 (0.9740)	
Train Epoch: [47][0/8]	Loss 0.9740 (0.9740)	LossFusion 0.9740 (0.9740)	
Train Epoch: [47][0/8]	Loss 0.9740 (0.9740)	LossFusion 0.9740 (0.9740)	
Train Epoch: [47][0/8]	Loss 0.9740 (0.9740)	LossFusion 0.9740 (0.9740)	
Train Epoch: [47][0/8]	Loss 0.9740 (0.9740)	LossFusion 0.9740 (0.9740)	
Train Epoch: [47][0/8]	Loss 0.9740 (0.9740)	LossFusion 0.9740 (0.9740)	
Train Epoch: [47][0/8]	Loss 0.9740 (0.9740)	LossFusion 0.9740 (0.9740)	
Train Epoch: [47][0/8]	Loss 0.9740 (0.9740)	LossFusion 0.9740 (0.9740)	
Train Epoch: [47][7/8]	Loss 0.5815 (0.7637)	LossFusion 0.5815 (0.7637)	
Train Epoch: [47][7/8]	Loss 0.5815 (0.7637)	LossFusion 0.5815 (0.7637)	
Train Epoch: [47][7/8]	Loss 0.5815 (0.7637)	LossFusion 0.5815 (0.7637)	
Train Epoch: [47][7/8]	Loss 0.5815 (0.7637)	LossFusion 0.5815 (0.7637)	
Train Epoch: [47][7/8]	Loss 0.5815 (0.7637)	LossFusion 0.5815 (0.7637)	
Train Epoch: [47][7/8]	Loss 0.5815 (0.7637)	LossFusion 0.5815 (0.7637)	
Train Epoch: [47][7/8]	Loss 0.5815 (0.7637)	LossFusion 0.5815 (0.7637)	
Train Epoch: [47][7/8]	Loss 0.5815 (0.7637)	LossFusion 0.5815 (0.7637)	
R@10:  55.650198459625244     R@50:  82.22600817680359
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.22600817680359
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.22600817680359
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.22600817680359
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.22600817680359
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.22600817680359
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.22600817680359
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.22600817680359
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
Train Epoch: [48][0/8]	Loss 0.9925 (0.9925)	LossFusion 0.9925 (0.9925)	
Train Epoch: [48][0/8]	Loss 0.9925 (0.9925)	LossFusion 0.9925 (0.9925)	
Train Epoch: [48][0/8]	Loss 0.9925 (0.9925)	LossFusion 0.9925 (0.9925)	
Train Epoch: [48][0/8]	Loss 0.9925 (0.9925)	LossFusion 0.9925 (0.9925)	
Train Epoch: [48][0/8]	Loss 0.9925 (0.9925)	LossFusion 0.9925 (0.9925)	
Train Epoch: [48][0/8]	Loss 0.9925 (0.9925)	LossFusion 0.9925 (0.9925)	
Train Epoch: [48][0/8]	Loss 0.9925 (0.9925)	LossFusion 0.9925 (0.9925)	
Train Epoch: [48][0/8]	Loss 0.9925 (0.9925)	LossFusion 0.9925 (0.9925)	
Train Epoch: [48][7/8]	Loss 0.5394 (0.7566)	LossFusion 0.5394 (0.7566)	
Train Epoch: [48][7/8]	Loss 0.5394 (0.7566)	LossFusion 0.5394 (0.7566)	
Train Epoch: [48][7/8]	Loss 0.5394 (0.7566)	LossFusion 0.5394 (0.7566)	
Train Epoch: [48][7/8]	Loss 0.5394 (0.7566)	LossFusion 0.5394 (0.7566)	
Train Epoch: [48][7/8]	Loss 0.5394 (0.7566)	LossFusion 0.5394 (0.7566)	
Train Epoch: [48][7/8]	Loss 0.5394 (0.7566)	LossFusion 0.5394 (0.7566)	
Train Epoch: [48][7/8]	Loss 0.5394 (0.7566)	LossFusion 0.5394 (0.7566)	
Train Epoch: [48][7/8]	Loss 0.5394 (0.7566)	LossFusion 0.5394 (0.7566)	
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
Train Epoch: [49][0/8]	Loss 0.9501 (0.9501)	LossFusion 0.9501 (0.9501)	
Train Epoch: [49][0/8]	Loss 0.9501 (0.9501)	LossFusion 0.9501 (0.9501)	
Train Epoch: [49][0/8]	Loss 0.9501 (0.9501)	LossFusion 0.9501 (0.9501)	
Train Epoch: [49][0/8]	Loss 0.9501 (0.9501)	LossFusion 0.9501 (0.9501)	
Train Epoch: [49][0/8]	Loss 0.9501 (0.9501)	LossFusion 0.9501 (0.9501)	
Train Epoch: [49][0/8]	Loss 0.9501 (0.9501)	LossFusion 0.9501 (0.9501)	
Train Epoch: [49][0/8]	Loss 0.9501 (0.9501)	LossFusion 0.9501 (0.9501)	
Train Epoch: [49][0/8]	Loss 0.9501 (0.9501)	LossFusion 0.9501 (0.9501)	
Train Epoch: [49][7/8]	Loss 0.5268 (0.7370)	LossFusion 0.5268 (0.7370)	
Train Epoch: [49][7/8]	Loss 0.5268 (0.7370)	LossFusion 0.5268 (0.7370)	
Train Epoch: [49][7/8]	Loss 0.5268 (0.7370)	LossFusion 0.5268 (0.7370)	
Train Epoch: [49][7/8]	Loss 0.5268 (0.7370)	LossFusion 0.5268 (0.7370)	
Train Epoch: [49][7/8]	Loss 0.5268 (0.7370)	LossFusion 0.5268 (0.7370)	
Train Epoch: [49][7/8]	Loss 0.5268 (0.7370)	LossFusion 0.5268 (0.7370)	
Train Epoch: [49][7/8]	Loss 0.5268 (0.7370)	LossFusion 0.5268 (0.7370)	
Train Epoch: [49][7/8]	Loss 0.5268 (0.7370)	LossFusion 0.5268 (0.7370)	
R@10:  55.99091649055481     R@50:  81.71493411064148
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.71493411064148
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.71493411064148
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.71493411064148
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.71493411064148
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.71493411064148
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.71493411064148
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.71493411064148
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
Train Epoch: [50][0/8]	Loss 0.9647 (0.9647)	LossFusion 0.9647 (0.9647)	
Train Epoch: [50][0/8]	Loss 0.9647 (0.9647)	LossFusion 0.9647 (0.9647)	
Train Epoch: [50][0/8]	Loss 0.9647 (0.9647)	LossFusion 0.9647 (0.9647)	
Train Epoch: [50][0/8]	Loss 0.9647 (0.9647)	LossFusion 0.9647 (0.9647)	
Train Epoch: [50][0/8]	Loss 0.9647 (0.9647)	LossFusion 0.9647 (0.9647)	
Train Epoch: [50][0/8]	Loss 0.9647 (0.9647)	LossFusion 0.9647 (0.9647)	
Train Epoch: [50][0/8]	Loss 0.9647 (0.9647)	LossFusion 0.9647 (0.9647)	
Train Epoch: [50][0/8]	Loss 0.9647 (0.9647)	LossFusion 0.9647 (0.9647)	
Train Epoch: [50][7/8]	Loss 0.5185 (0.7442)	LossFusion 0.5185 (0.7442)	
Train Epoch: [50][7/8]	Loss 0.5185 (0.7442)	LossFusion 0.5185 (0.7442)	
Train Epoch: [50][7/8]	Loss 0.5185 (0.7442)	LossFusion 0.5185 (0.7442)	
Train Epoch: [50][7/8]	Loss 0.5185 (0.7442)	LossFusion 0.5185 (0.7442)	
Train Epoch: [50][7/8]	Loss 0.5185 (0.7442)	LossFusion 0.5185 (0.7442)	
Train Epoch: [50][7/8]	Loss 0.5185 (0.7442)	LossFusion 0.5185 (0.7442)	
Train Epoch: [50][7/8]	Loss 0.5185 (0.7442)	LossFusion 0.5185 (0.7442)	
Train Epoch: [50][7/8]	Loss 0.5185 (0.7442)	LossFusion 0.5185 (0.7442)	
R@10:  55.99091649055481     R@50:  82.05565214157104
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  82.05565214157104
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  82.05565214157104
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  82.05565214157104
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  82.05565214157104
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  82.05565214157104
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  82.05565214157104
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  82.05565214157104
Mean Now:  69.02328431606293  Best Mean Before:  69.44918 --------------------
Train Epoch: [51][0/8]	Loss 0.9213 (0.9213)	LossFusion 0.9213 (0.9213)	
Train Epoch: [51][0/8]	Loss 0.9213 (0.9213)	LossFusion 0.9213 (0.9213)	
Train Epoch: [51][0/8]	Loss 0.9213 (0.9213)	LossFusion 0.9213 (0.9213)	
Train Epoch: [51][0/8]	Loss 0.9213 (0.9213)	LossFusion 0.9213 (0.9213)	
Train Epoch: [51][0/8]	Loss 0.9213 (0.9213)	LossFusion 0.9213 (0.9213)	
Train Epoch: [51][0/8]	Loss 0.9213 (0.9213)	LossFusion 0.9213 (0.9213)	
Train Epoch: [51][0/8]	Loss 0.9213 (0.9213)	LossFusion 0.9213 (0.9213)	
Train Epoch: [51][0/8]	Loss 0.9213 (0.9213)	LossFusion 0.9213 (0.9213)	
Train Epoch: [51][7/8]	Loss 0.5201 (0.7097)	LossFusion 0.5201 (0.7097)	
Train Epoch: [51][7/8]	Loss 0.5201 (0.7097)	LossFusion 0.5201 (0.7097)	
Train Epoch: [51][7/8]	Loss 0.5201 (0.7097)	LossFusion 0.5201 (0.7097)	
Train Epoch: [51][7/8]	Loss 0.5201 (0.7097)	LossFusion 0.5201 (0.7097)	
Train Epoch: [51][7/8]	Loss 0.5201 (0.7097)	LossFusion 0.5201 (0.7097)	
Train Epoch: [51][7/8]	Loss 0.5201 (0.7097)	LossFusion 0.5201 (0.7097)	
Train Epoch: [51][7/8]	Loss 0.5201 (0.7097)	LossFusion 0.5201 (0.7097)	
Train Epoch: [51][7/8]	Loss 0.5201 (0.7097)	LossFusion 0.5201 (0.7097)	
R@10:  55.650198459625244     R@50:  81.771719455719
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.771719455719
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.771719455719
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.771719455719
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.771719455719
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.771719455719
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.771719455719
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.771719455719
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
Train Epoch: [52][0/8]	Loss 0.8941 (0.8941)	LossFusion 0.8941 (0.8941)	
Train Epoch: [52][0/8]	Loss 0.8941 (0.8941)	LossFusion 0.8941 (0.8941)	
Train Epoch: [52][0/8]	Loss 0.8941 (0.8941)	LossFusion 0.8941 (0.8941)	
Train Epoch: [52][0/8]	Loss 0.8941 (0.8941)	LossFusion 0.8941 (0.8941)	
Train Epoch: [52][0/8]	Loss 0.8941 (0.8941)	LossFusion 0.8941 (0.8941)	
Train Epoch: [52][0/8]	Loss 0.8941 (0.8941)	LossFusion 0.8941 (0.8941)	
Train Epoch: [52][0/8]	Loss 0.8941 (0.8941)	LossFusion 0.8941 (0.8941)	
Train Epoch: [52][0/8]	Loss 0.8941 (0.8941)	LossFusion 0.8941 (0.8941)	
Train Epoch: [52][7/8]	Loss 0.4955 (0.7073)	LossFusion 0.4955 (0.7073)	
Train Epoch: [52][7/8]	Loss 0.4955 (0.7073)	LossFusion 0.4955 (0.7073)	
Train Epoch: [52][7/8]	Loss 0.4955 (0.7073)	LossFusion 0.4955 (0.7073)	
Train Epoch: [52][7/8]	Loss 0.4955 (0.7073)	LossFusion 0.4955 (0.7073)	
Train Epoch: [52][7/8]	Loss 0.4955 (0.7073)	LossFusion 0.4955 (0.7073)	
Train Epoch: [52][7/8]	Loss 0.4955 (0.7073)	LossFusion 0.4955 (0.7073)	
Train Epoch: [52][7/8]	Loss 0.4955 (0.7073)	LossFusion 0.4955 (0.7073)	
Train Epoch: [52][7/8]	Loss 0.4955 (0.7073)	LossFusion 0.4955 (0.7073)	
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
Train Epoch: [53][0/8]	Loss 0.9273 (0.9273)	LossFusion 0.9273 (0.9273)	
Train Epoch: [53][0/8]	Loss 0.9273 (0.9273)	LossFusion 0.9273 (0.9273)	
Train Epoch: [53][0/8]	Loss 0.9273 (0.9273)	LossFusion 0.9273 (0.9273)	
Train Epoch: [53][0/8]	Loss 0.9273 (0.9273)	LossFusion 0.9273 (0.9273)	
Train Epoch: [53][0/8]	Loss 0.9273 (0.9273)	LossFusion 0.9273 (0.9273)	
Train Epoch: [53][0/8]	Loss 0.9273 (0.9273)	LossFusion 0.9273 (0.9273)	
Train Epoch: [53][0/8]	Loss 0.9273 (0.9273)	LossFusion 0.9273 (0.9273)	
Train Epoch: [53][0/8]	Loss 0.9273 (0.9273)	LossFusion 0.9273 (0.9273)	
Train Epoch: [53][7/8]	Loss 0.5215 (0.7079)	LossFusion 0.5215 (0.7079)	
Train Epoch: [53][7/8]	Loss 0.5215 (0.7079)	LossFusion 0.5215 (0.7079)	
Train Epoch: [53][7/8]	Loss 0.5215 (0.7079)	LossFusion 0.5215 (0.7079)	
Train Epoch: [53][7/8]	Loss 0.5215 (0.7079)	LossFusion 0.5215 (0.7079)	
Train Epoch: [53][7/8]	Loss 0.5215 (0.7079)	LossFusion 0.5215 (0.7079)	
Train Epoch: [53][7/8]	Loss 0.5215 (0.7079)	LossFusion 0.5215 (0.7079)	
Train Epoch: [53][7/8]	Loss 0.5215 (0.7079)	LossFusion 0.5215 (0.7079)	
Train Epoch: [53][7/8]	Loss 0.5215 (0.7079)	LossFusion 0.5215 (0.7079)	
R@10:  55.99091649055481     R@50:  81.48779273033142
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.48779273033142
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.48779273033142
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.48779273033142
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.48779273033142
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.48779273033142
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.48779273033142
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.48779273033142
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
Train Epoch: [54][0/8]	Loss 0.8886 (0.8886)	LossFusion 0.8886 (0.8886)	
Train Epoch: [54][0/8]	Loss 0.8886 (0.8886)	LossFusion 0.8886 (0.8886)	
Train Epoch: [54][0/8]	Loss 0.8886 (0.8886)	LossFusion 0.8886 (0.8886)	
Train Epoch: [54][0/8]	Loss 0.8886 (0.8886)	LossFusion 0.8886 (0.8886)	
Train Epoch: [54][0/8]	Loss 0.8886 (0.8886)	LossFusion 0.8886 (0.8886)	
Train Epoch: [54][0/8]	Loss 0.8886 (0.8886)	LossFusion 0.8886 (0.8886)	
Train Epoch: [54][0/8]	Loss 0.8886 (0.8886)	LossFusion 0.8886 (0.8886)	
Train Epoch: [54][0/8]	Loss 0.8886 (0.8886)	LossFusion 0.8886 (0.8886)	
Train Epoch: [54][7/8]	Loss 0.5022 (0.7002)	LossFusion 0.5022 (0.7002)	
Train Epoch: [54][7/8]	Loss 0.5022 (0.7002)	LossFusion 0.5022 (0.7002)	
Train Epoch: [54][7/8]	Loss 0.5022 (0.7002)	LossFusion 0.5022 (0.7002)	
Train Epoch: [54][7/8]	Loss 0.5022 (0.7002)	LossFusion 0.5022 (0.7002)	
Train Epoch: [54][7/8]	Loss 0.5022 (0.7002)	LossFusion 0.5022 (0.7002)	
Train Epoch: [54][7/8]	Loss 0.5022 (0.7002)	LossFusion 0.5022 (0.7002)	
Train Epoch: [54][7/8]	Loss 0.5022 (0.7002)	LossFusion 0.5022 (0.7002)	
Train Epoch: [54][7/8]	Loss 0.5022 (0.7002)	LossFusion 0.5022 (0.7002)	
R@10:  55.650198459625244     R@50:  82.05565214157104
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.05565214157104
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.05565214157104
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.05565214157104
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.05565214157104
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.05565214157104
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.05565214157104
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  82.05565214157104
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
Train Epoch: [55][0/8]	Loss 0.8702 (0.8702)	LossFusion 0.8702 (0.8702)	
Train Epoch: [55][0/8]	Loss 0.8702 (0.8702)	LossFusion 0.8702 (0.8702)	
Train Epoch: [55][0/8]	Loss 0.8702 (0.8702)	LossFusion 0.8702 (0.8702)	
Train Epoch: [55][0/8]	Loss 0.8702 (0.8702)	LossFusion 0.8702 (0.8702)	
Train Epoch: [55][0/8]	Loss 0.8702 (0.8702)	LossFusion 0.8702 (0.8702)	
Train Epoch: [55][0/8]	Loss 0.8702 (0.8702)	LossFusion 0.8702 (0.8702)	
Train Epoch: [55][0/8]	Loss 0.8702 (0.8702)	LossFusion 0.8702 (0.8702)	
Train Epoch: [55][0/8]	Loss 0.8702 (0.8702)	LossFusion 0.8702 (0.8702)	
Train Epoch: [55][7/8]	Loss 0.4914 (0.6910)	LossFusion 0.4914 (0.6910)	
Train Epoch: [55][7/8]	Loss 0.4914 (0.6910)	LossFusion 0.4914 (0.6910)	
Train Epoch: [55][7/8]	Loss 0.4914 (0.6910)	LossFusion 0.4914 (0.6910)	
Train Epoch: [55][7/8]	Loss 0.4914 (0.6910)	LossFusion 0.4914 (0.6910)	
Train Epoch: [55][7/8]	Loss 0.4914 (0.6910)	LossFusion 0.4914 (0.6910)	
Train Epoch: [55][7/8]	Loss 0.4914 (0.6910)	LossFusion 0.4914 (0.6910)	
Train Epoch: [55][7/8]	Loss 0.4914 (0.6910)	LossFusion 0.4914 (0.6910)	
Train Epoch: [55][7/8]	Loss 0.4914 (0.6910)	LossFusion 0.4914 (0.6910)	
R@10:  55.934131145477295     R@50:  82.22600817680359
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  82.22600817680359
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  82.22600817680359
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  82.22600817680359
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  82.22600817680359
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  82.22600817680359
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  82.22600817680359
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  82.22600817680359
Mean Now:  69.08006966114044  Best Mean Before:  69.44918 --------------------
Train Epoch: [56][0/8]	Loss 0.9011 (0.9011)	LossFusion 0.9011 (0.9011)	
Train Epoch: [56][0/8]	Loss 0.9011 (0.9011)	LossFusion 0.9011 (0.9011)	
Train Epoch: [56][0/8]	Loss 0.9011 (0.9011)	LossFusion 0.9011 (0.9011)	
Train Epoch: [56][0/8]	Loss 0.9011 (0.9011)	LossFusion 0.9011 (0.9011)	
Train Epoch: [56][0/8]	Loss 0.9011 (0.9011)	LossFusion 0.9011 (0.9011)	
Train Epoch: [56][0/8]	Loss 0.9011 (0.9011)	LossFusion 0.9011 (0.9011)	
Train Epoch: [56][0/8]	Loss 0.9011 (0.9011)	LossFusion 0.9011 (0.9011)	
Train Epoch: [56][0/8]	Loss 0.9011 (0.9011)	LossFusion 0.9011 (0.9011)	
Train Epoch: [56][7/8]	Loss 0.4817 (0.6966)	LossFusion 0.4817 (0.6966)	
Train Epoch: [56][7/8]	Loss 0.4817 (0.6966)	LossFusion 0.4817 (0.6966)	
Train Epoch: [56][7/8]	Loss 0.4817 (0.6966)	LossFusion 0.4817 (0.6966)	
Train Epoch: [56][7/8]	Loss 0.4817 (0.6966)	LossFusion 0.4817 (0.6966)	
Train Epoch: [56][7/8]	Loss 0.4817 (0.6966)	LossFusion 0.4817 (0.6966)	
Train Epoch: [56][7/8]	Loss 0.4817 (0.6966)	LossFusion 0.4817 (0.6966)	
Train Epoch: [56][7/8]	Loss 0.4817 (0.6966)	LossFusion 0.4817 (0.6966)	
Train Epoch: [56][7/8]	Loss 0.4817 (0.6966)	LossFusion 0.4817 (0.6966)	
R@10:  55.934131145477295     R@50:  81.71493411064148
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.71493411064148
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.71493411064148
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.71493411064148
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.71493411064148
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.71493411064148
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295R@10:      R@50:   81.71493411064148
55.934131145477295     R@50:  Mean Now: 81.71493411064148 
68.82453262805939  Best Mean Before: Mean Now:   69.4491868.82453262805939  -------------------- Best Mean Before: 
 69.44918 --------------------
Train Epoch: [57][0/8]	Loss 0.8172 (0.8172)	LossFusion 0.8172 (0.8172)	
Train Epoch: [57][0/8]	Loss 0.8172 (0.8172)	LossFusion 0.8172 (0.8172)	
Train Epoch: [57][0/8]	Loss 0.8172 (0.8172)	LossFusion 0.8172 (0.8172)	
Train Epoch: [57][0/8]	Loss 0.8172 (0.8172)	LossFusion 0.8172 (0.8172)	
Train Epoch: [57][0/8]	Loss 0.8172 (0.8172)	LossFusion 0.8172 (0.8172)	
Train Epoch: [57][0/8]	Loss 0.8172 (0.8172)	LossFusion 0.8172 (0.8172)	
Train Epoch: [57][0/8]	Loss 0.8172 (0.8172)	LossFusion 0.8172 (0.8172)	
Train Epoch: [57][0/8]	Loss 0.8172 (0.8172)	LossFusion 0.8172 (0.8172)	
Train Epoch: [57][7/8]	Loss 0.4965 (0.6815)	LossFusion 0.4965 (0.6815)	
Train Epoch: [57][7/8]	Loss 0.4965 (0.6815)	LossFusion 0.4965 (0.6815)	
Train Epoch: [57][7/8]	Loss 0.4965 (0.6815)	LossFusion 0.4965 (0.6815)	
Train Epoch: [57][7/8]	Loss 0.4965 (0.6815)	LossFusion 0.4965 (0.6815)	
Train Epoch: [57][7/8]	Loss 0.4965 (0.6815)	LossFusion 0.4965 (0.6815)	
Train Epoch: [57][7/8]	Loss 0.4965 (0.6815)	LossFusion 0.4965 (0.6815)	
Train Epoch: [57][7/8]	Loss 0.4965 (0.6815)	LossFusion 0.4965 (0.6815)	
Train Epoch: [57][7/8]	Loss 0.4965 (0.6815)	LossFusion 0.4965 (0.6815)	
R@10:  56.047701835632324     R@50:  81.771719455719
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.771719455719
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.771719455719
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.771719455719
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.771719455719
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.771719455719
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.771719455719
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.771719455719
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
Train Epoch: [58][0/8]	Loss 0.8304 (0.8304)	LossFusion 0.8304 (0.8304)	
Train Epoch: [58][0/8]	Loss 0.8304 (0.8304)	LossFusion 0.8304 (0.8304)	
Train Epoch: [58][0/8]	Loss 0.8304 (0.8304)	LossFusion 0.8304 (0.8304)	
Train Epoch: [58][0/8]	Loss 0.8304 (0.8304)	LossFusion 0.8304 (0.8304)	
Train Epoch: [58][0/8]	Loss 0.8304 (0.8304)	LossFusion 0.8304 (0.8304)	
Train Epoch: [58][0/8]	Loss 0.8304 (0.8304)	LossFusion 0.8304 (0.8304)	
Train Epoch: [58][0/8]	Loss 0.8304 (0.8304)	LossFusion 0.8304 (0.8304)	
Train Epoch: [58][0/8]	Loss 0.8304 (0.8304)	LossFusion 0.8304 (0.8304)	
Train Epoch: [58][7/8]	Loss 0.4707 (0.6642)	LossFusion 0.4707 (0.6642)	
Train Epoch: [58][7/8]	Loss 0.4707 (0.6642)	LossFusion 0.4707 (0.6642)	
Train Epoch: [58][7/8]	Loss 0.4707 (0.6642)	LossFusion 0.4707 (0.6642)	
Train Epoch: [58][7/8]	Loss 0.4707 (0.6642)	LossFusion 0.4707 (0.6642)	
Train Epoch: [58][7/8]	Loss 0.4707 (0.6642)	LossFusion 0.4707 (0.6642)	
Train Epoch: [58][7/8]	Loss 0.4707 (0.6642)	LossFusion 0.4707 (0.6642)	
Train Epoch: [58][7/8]	Loss 0.4707 (0.6642)	LossFusion 0.4707 (0.6642)	
Train Epoch: [58][7/8]	Loss 0.4707 (0.6642)	LossFusion 0.4707 (0.6642)	
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10: R@10:   55.877339839935355.8773398399353      R@50:     R@50:   81.9420754909515481.94207549095154

Mean Now: Mean Now:   68.9097076654434268.90970766544342   Best Mean Before:  Best Mean Before:   69.4491869.44918  ----------------------------------------

R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  R@10: 81.94207549095154 
55.8773398399353 Mean Now:     R@50:   68.9097076654434281.94207549095154  Best Mean Before:  
69.44918 --------------------Mean Now: 
 68.90970766544342  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.94207549095154
Mean Now:  68.90970766544342  Best Mean Before:  69.44918 --------------------
Train Epoch: [59][0/8]	Loss 0.8643 (0.8643)	LossFusion 0.8643 (0.8643)	
Train Epoch: [59][0/8]	Loss 0.8643 (0.8643)	LossFusion 0.8643 (0.8643)	
Train Epoch: [59][0/8]	Loss 0.8643 (0.8643)	LossFusion 0.8643 (0.8643)	
Train Epoch: [59][0/8]	Loss 0.8643 (0.8643)	LossFusion 0.8643 (0.8643)	
Train Epoch: [59][0/8]	Loss 0.8643 (0.8643)	LossFusion 0.8643 (0.8643)	
Train Epoch: [59][0/8]	Loss 0.8643 (0.8643)	LossFusion 0.8643 (0.8643)	
Train Epoch: [59][0/8]	Loss 0.8643 (0.8643)	LossFusion 0.8643 (0.8643)	
Train Epoch: [59][0/8]	Loss 0.8643 (0.8643)	LossFusion 0.8643 (0.8643)	
Train Epoch: [59][7/8]	Loss 0.4808 (0.6555)	LossFusion 0.4808 (0.6555)	
Train Epoch: [59][7/8]	Loss 0.4808 (0.6555)	LossFusion 0.4808 (0.6555)	
Train Epoch: [59][7/8]	Loss 0.4808 (0.6555)	LossFusion 0.4808 (0.6555)	
Train Epoch: [59][7/8]	Loss 0.4808 (0.6555)	LossFusion 0.4808 (0.6555)	
Train Epoch: [59][7/8]	Loss 0.4808 (0.6555)	LossFusion 0.4808 (0.6555)	
Train Epoch: [59][7/8]	Loss 0.4808 (0.6555)	LossFusion 0.4808 (0.6555)	
Train Epoch: [59][7/8]	Loss 0.4808 (0.6555)	LossFusion 0.4808 (0.6555)	
Train Epoch: [59][7/8]	Loss 0.4808 (0.6555)	LossFusion 0.4808 (0.6555)	
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
Train Epoch: [60][0/8]	Loss 0.8106 (0.8106)	LossFusion 0.8106 (0.8106)	
Train Epoch: [60][0/8]	Loss 0.8106 (0.8106)	LossFusion 0.8106 (0.8106)	
Train Epoch: [60][0/8]	Loss 0.8106 (0.8106)	LossFusion 0.8106 (0.8106)	
Train Epoch: [60][0/8]	Loss 0.8106 (0.8106)	LossFusion 0.8106 (0.8106)	
Train Epoch: [60][0/8]	Loss 0.8106 (0.8106)	LossFusion 0.8106 (0.8106)	
Train Epoch: [60][0/8]	Loss 0.8106 (0.8106)	LossFusion 0.8106 (0.8106)	
Train Epoch: [60][0/8]	Loss 0.8106 (0.8106)	LossFusion 0.8106 (0.8106)	
Train Epoch: [60][0/8]	Loss 0.8106 (0.8106)	LossFusion 0.8106 (0.8106)	
Train Epoch: [60][7/8]	Loss 0.4735 (0.6508)	LossFusion 0.4735 (0.6508)	
Train Epoch: [60][7/8]	Loss 0.4735 (0.6508)	LossFusion 0.4735 (0.6508)	
Train Epoch: [60][7/8]	Loss 0.4735 (0.6508)	LossFusion 0.4735 (0.6508)	
Train Epoch: [60][7/8]	Loss 0.4735 (0.6508)	LossFusion 0.4735 (0.6508)	
Train Epoch: [60][7/8]	Loss 0.4735 (0.6508)	LossFusion 0.4735 (0.6508)	
Train Epoch: [60][7/8]	Loss 0.4735 (0.6508)	LossFusion 0.4735 (0.6508)	
Train Epoch: [60][7/8]	Loss 0.4735 (0.6508)	LossFusion 0.4735 (0.6508)	
Train Epoch: [60][7/8]	Loss 0.4735 (0.6508)	LossFusion 0.4735 (0.6508)	
R@10:  55.650198459625244     R@50:  81.99886679649353
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.99886679649353
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.99886679649353
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.99886679649353
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.99886679649353
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.99886679649353
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.99886679649353
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.99886679649353
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
Train Epoch: [61][0/8]	Loss 0.8245 (0.8245)	LossFusion 0.8245 (0.8245)	
Train Epoch: [61][0/8]	Loss 0.8245 (0.8245)	LossFusion 0.8245 (0.8245)	
Train Epoch: [61][0/8]	Loss 0.8245 (0.8245)	LossFusion 0.8245 (0.8245)	
Train Epoch: [61][0/8]	Loss 0.8245 (0.8245)	LossFusion 0.8245 (0.8245)	
Train Epoch: [61][0/8]	Loss 0.8245 (0.8245)	LossFusion 0.8245 (0.8245)	
Train Epoch: [61][0/8]	Loss 0.8245 (0.8245)	LossFusion 0.8245 (0.8245)	
Train Epoch: [61][0/8]	Loss 0.8245 (0.8245)	LossFusion 0.8245 (0.8245)	
Train Epoch: [61][0/8]	Loss 0.8245 (0.8245)	LossFusion 0.8245 (0.8245)	
Train Epoch: [61][7/8]	Loss 0.4582 (0.6512)	LossFusion 0.4582 (0.6512)	
Train Epoch: [61][7/8]	Loss 0.4582 (0.6512)	LossFusion 0.4582 (0.6512)	
Train Epoch: [61][7/8]	Loss 0.4582 (0.6512)	LossFusion 0.4582 (0.6512)	
Train Epoch: [61][7/8]	Loss 0.4582 (0.6512)	LossFusion 0.4582 (0.6512)	
Train Epoch: [61][7/8]	Loss 0.4582 (0.6512)	LossFusion 0.4582 (0.6512)	
Train Epoch: [61][7/8]	Loss 0.4582 (0.6512)	LossFusion 0.4582 (0.6512)	
Train Epoch: [61][7/8]	Loss 0.4582 (0.6512)	LossFusion 0.4582 (0.6512)	
Train Epoch: [61][7/8]	Loss 0.4582 (0.6512)	LossFusion 0.4582 (0.6512)	
R@10:  55.650198459625244     R@50:  81.94207549095154
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.94207549095154
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.94207549095154
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.94207549095154
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.94207549095154
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.94207549095154
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.94207549095154
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.94207549095154
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [62][0/8]	Loss 0.8583 (0.8583)	LossFusion 0.8583 (0.8583)	
Train Epoch: [62][0/8]	Loss 0.8583 (0.8583)	LossFusion 0.8583 (0.8583)	
Train Epoch: [62][0/8]	Loss 0.8583 (0.8583)	LossFusion 0.8583 (0.8583)	
Train Epoch: [62][0/8]	Loss 0.8583 (0.8583)	LossFusion 0.8583 (0.8583)	
Train Epoch: [62][0/8]	Loss 0.8583 (0.8583)	LossFusion 0.8583 (0.8583)	
Train Epoch: [62][0/8]	Loss 0.8583 (0.8583)	LossFusion 0.8583 (0.8583)	
Train Epoch: [62][0/8]	Loss 0.8583 (0.8583)	LossFusion 0.8583 (0.8583)	
Train Epoch: [62][0/8]	Loss 0.8583 (0.8583)	LossFusion 0.8583 (0.8583)	
Train Epoch: [62][7/8]	Loss 0.4409 (0.6513)	LossFusion 0.4409 (0.6513)	
Train Epoch: [62][7/8]	Loss 0.4409 (0.6513)	LossFusion 0.4409 (0.6513)	
Train Epoch: [62][7/8]	Loss 0.4409 (0.6513)	LossFusion 0.4409 (0.6513)	
Train Epoch: [62][7/8]	Loss 0.4409 (0.6513)	LossFusion 0.4409 (0.6513)	
Train Epoch: [62][7/8]	Loss 0.4409 (0.6513)	LossFusion 0.4409 (0.6513)	
Train Epoch: [62][7/8]	Loss 0.4409 (0.6513)	LossFusion 0.4409 (0.6513)	
Train Epoch: [62][7/8]	Loss 0.4409 (0.6513)	LossFusion 0.4409 (0.6513)	
Train Epoch: [62][7/8]	Loss 0.4409 (0.6513)	LossFusion 0.4409 (0.6513)	
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
Train Epoch: [63][0/8]	Loss 0.8189 (0.8189)	LossFusion 0.8189 (0.8189)	
Train Epoch: [63][0/8]	Loss 0.8189 (0.8189)	LossFusion 0.8189 (0.8189)	
Train Epoch: [63][0/8]	Loss 0.8189 (0.8189)	LossFusion 0.8189 (0.8189)	
Train Epoch: [63][0/8]	Loss 0.8189 (0.8189)	LossFusion 0.8189 (0.8189)	
Train Epoch: [63][0/8]	Loss 0.8189 (0.8189)	LossFusion 0.8189 (0.8189)	
Train Epoch: [63][0/8]	Loss 0.8189 (0.8189)	LossFusion 0.8189 (0.8189)	
Train Epoch: [63][0/8]	Loss 0.8189 (0.8189)	LossFusion 0.8189 (0.8189)	
Train Epoch: [63][0/8]	Loss 0.8189 (0.8189)	LossFusion 0.8189 (0.8189)	
Train Epoch: [63][7/8]	Loss 0.4566 (0.6260)	LossFusion 0.4566 (0.6260)	
Train Epoch: [63][7/8]	Loss 0.4566 (0.6260)	LossFusion 0.4566 (0.6260)	
Train Epoch: [63][7/8]	Loss 0.4566 (0.6260)	LossFusion 0.4566 (0.6260)	
Train Epoch: [63][7/8]	Loss 0.4566 (0.6260)	LossFusion 0.4566 (0.6260)	
Train Epoch: [63][7/8]	Loss 0.4566 (0.6260)	LossFusion 0.4566 (0.6260)	
Train Epoch: [63][7/8]	Loss 0.4566 (0.6260)	LossFusion 0.4566 (0.6260)	
Train Epoch: [63][7/8]	Loss 0.4566 (0.6260)	LossFusion 0.4566 (0.6260)	
Train Epoch: [63][7/8]	Loss 0.4566 (0.6260)	LossFusion 0.4566 (0.6260)	
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.771719455719
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
Train Epoch: [64][0/8]	Loss 0.8222 (0.8222)	LossFusion 0.8222 (0.8222)	
Train Epoch: [64][0/8]	Loss 0.8222 (0.8222)	LossFusion 0.8222 (0.8222)	
Train Epoch: [64][0/8]	Loss 0.8222 (0.8222)	LossFusion 0.8222 (0.8222)	
Train Epoch: [64][0/8]	Loss 0.8222 (0.8222)	LossFusion 0.8222 (0.8222)	
Train Epoch: [64][0/8]	Loss 0.8222 (0.8222)	LossFusion 0.8222 (0.8222)	
Train Epoch: [64][0/8]	Loss 0.8222 (0.8222)	LossFusion 0.8222 (0.8222)	
Train Epoch: [64][0/8]	Loss 0.8222 (0.8222)	LossFusion 0.8222 (0.8222)	
Train Epoch: [64][0/8]	Loss 0.8222 (0.8222)	LossFusion 0.8222 (0.8222)	
Train Epoch: [64][7/8]	Loss 0.4159 (0.6305)	LossFusion 0.4159 (0.6305)	
Train Epoch: [64][7/8]	Loss 0.4159 (0.6305)	LossFusion 0.4159 (0.6305)	
Train Epoch: [64][7/8]	Loss 0.4159 (0.6305)	LossFusion 0.4159 (0.6305)	
Train Epoch: [64][7/8]	Loss 0.4159 (0.6305)	LossFusion 0.4159 (0.6305)	
Train Epoch: [64][7/8]	Loss 0.4159 (0.6305)	LossFusion 0.4159 (0.6305)	
Train Epoch: [64][7/8]	Loss 0.4159 (0.6305)	LossFusion 0.4159 (0.6305)	
Train Epoch: [64][7/8]	Loss 0.4159 (0.6305)	LossFusion 0.4159 (0.6305)	
Train Epoch: [64][7/8]	Loss 0.4159 (0.6305)	LossFusion 0.4159 (0.6305)	
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
Train Epoch: [65][0/8]	Loss 0.8079 (0.8079)	LossFusion 0.8079 (0.8079)	
Train Epoch: [65][0/8]	Loss 0.8079 (0.8079)	LossFusion 0.8079 (0.8079)	
Train Epoch: [65][0/8]	Loss 0.8079 (0.8079)	LossFusion 0.8079 (0.8079)	
Train Epoch: [65][0/8]	Loss 0.8079 (0.8079)	LossFusion 0.8079 (0.8079)	
Train Epoch: [65][0/8]	Loss 0.8079 (0.8079)	LossFusion 0.8079 (0.8079)	
Train Epoch: [65][0/8]	Loss 0.8079 (0.8079)	LossFusion 0.8079 (0.8079)	
Train Epoch: [65][0/8]	Loss 0.8079 (0.8079)	LossFusion 0.8079 (0.8079)	
Train Epoch: [65][0/8]	Loss 0.8079 (0.8079)	LossFusion 0.8079 (0.8079)	
Train Epoch: [65][7/8]	Loss 0.4463 (0.6248)	LossFusion 0.4463 (0.6248)	
Train Epoch: [65][7/8]	Loss 0.4463 (0.6248)	LossFusion 0.4463 (0.6248)	
Train Epoch: [65][7/8]	Loss 0.4463 (0.6248)	LossFusion 0.4463 (0.6248)	
Train Epoch: [65][7/8]	Loss 0.4463 (0.6248)	LossFusion 0.4463 (0.6248)	
Train Epoch: [65][7/8]	Loss 0.4463 (0.6248)	LossFusion 0.4463 (0.6248)	
Train Epoch: [65][7/8]	Loss 0.4463 (0.6248)	LossFusion 0.4463 (0.6248)	
Train Epoch: [65][7/8]	Loss 0.4463 (0.6248)	LossFusion 0.4463 (0.6248)	
Train Epoch: [65][7/8]	Loss 0.4463 (0.6248)	LossFusion 0.4463 (0.6248)	
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
Train Epoch: [66][0/8]	Loss 0.8131 (0.8131)	LossFusion 0.8131 (0.8131)	
Train Epoch: [66][0/8]	Loss 0.8131 (0.8131)	LossFusion 0.8131 (0.8131)	
Train Epoch: [66][0/8]	Loss 0.8131 (0.8131)	LossFusion 0.8131 (0.8131)	
Train Epoch: [66][0/8]	Loss 0.8131 (0.8131)	LossFusion 0.8131 (0.8131)	
Train Epoch: [66][0/8]	Loss 0.8131 (0.8131)	LossFusion 0.8131 (0.8131)	
Train Epoch: [66][0/8]	Loss 0.8131 (0.8131)	LossFusion 0.8131 (0.8131)	
Train Epoch: [66][0/8]	Loss 0.8131 (0.8131)	LossFusion 0.8131 (0.8131)	
Train Epoch: [66][0/8]	Loss 0.8131 (0.8131)	LossFusion 0.8131 (0.8131)	
Train Epoch: [66][7/8]	Loss 0.4334 (0.6204)	LossFusion 0.4334 (0.6204)	
Train Epoch: [66][7/8]	Loss 0.4334 (0.6204)	LossFusion 0.4334 (0.6204)	
Train Epoch: [66][7/8]	Loss 0.4334 (0.6204)	LossFusion 0.4334 (0.6204)	
Train Epoch: [66][7/8]	Loss 0.4334 (0.6204)	LossFusion 0.4334 (0.6204)	
Train Epoch: [66][7/8]	Loss 0.4334 (0.6204)	LossFusion 0.4334 (0.6204)	
Train Epoch: [66][7/8]	Loss 0.4334 (0.6204)	LossFusion 0.4334 (0.6204)	
Train Epoch: [66][7/8]	Loss 0.4334 (0.6204)	LossFusion 0.4334 (0.6204)	
Train Epoch: [66][7/8]	Loss 0.4334 (0.6204)	LossFusion 0.4334 (0.6204)	
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
Train Epoch: [67][0/8]	Loss 0.8291 (0.8291)	LossFusion 0.8291 (0.8291)	
Train Epoch: [67][0/8]	Loss 0.8291 (0.8291)	LossFusion 0.8291 (0.8291)	
Train Epoch: [67][0/8]	Loss 0.8291 (0.8291)	LossFusion 0.8291 (0.8291)	
Train Epoch: [67][0/8]	Loss 0.8291 (0.8291)	LossFusion 0.8291 (0.8291)	
Train Epoch: [67][0/8]	Loss 0.8291 (0.8291)	LossFusion 0.8291 (0.8291)	
Train Epoch: [67][0/8]	Loss 0.8291 (0.8291)	LossFusion 0.8291 (0.8291)	
Train Epoch: [67][0/8]	Loss 0.8291 (0.8291)	LossFusion 0.8291 (0.8291)	
Train Epoch: [67][0/8]	Loss 0.8291 (0.8291)	LossFusion 0.8291 (0.8291)	
Train Epoch: [67][7/8]	Loss 0.4377 (0.6132)	LossFusion 0.4377 (0.6132)	
Train Epoch: [67][7/8]	Loss 0.4377 (0.6132)	LossFusion 0.4377 (0.6132)	
Train Epoch: [67][7/8]	Loss 0.4377 (0.6132)	LossFusion 0.4377 (0.6132)	
Train Epoch: [67][7/8]	Loss 0.4377 (0.6132)	LossFusion 0.4377 (0.6132)	
Train Epoch: [67][7/8]	Loss 0.4377 (0.6132)	LossFusion 0.4377 (0.6132)	
Train Epoch: [67][7/8]	Loss 0.4377 (0.6132)	LossFusion 0.4377 (0.6132)	
Train Epoch: [67][7/8]	Loss 0.4377 (0.6132)	LossFusion 0.4377 (0.6132)	
Train Epoch: [67][7/8]	Loss 0.4377 (0.6132)	LossFusion 0.4377 (0.6132)	
R@10:  55.70698380470276     R@50:  81.54457807540894
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.54457807540894
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.54457807540894
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.54457807540894
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.54457807540894
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.54457807540894
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.54457807540894
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.54457807540894
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
Train Epoch: [68][0/8]	Loss 0.7985 (0.7985)	LossFusion 0.7985 (0.7985)	
Train Epoch: [68][0/8]	Loss 0.7985 (0.7985)	LossFusion 0.7985 (0.7985)	
Train Epoch: [68][0/8]	Loss 0.7985 (0.7985)	LossFusion 0.7985 (0.7985)	
Train Epoch: [68][0/8]	Loss 0.7985 (0.7985)	LossFusion 0.7985 (0.7985)	
Train Epoch: [68][0/8]	Loss 0.7985 (0.7985)	LossFusion 0.7985 (0.7985)	
Train Epoch: [68][0/8]	Loss 0.7985 (0.7985)	LossFusion 0.7985 (0.7985)	
Train Epoch: [68][0/8]	Loss 0.7985 (0.7985)	LossFusion 0.7985 (0.7985)	
Train Epoch: [68][0/8]	Loss 0.7985 (0.7985)	LossFusion 0.7985 (0.7985)	
Train Epoch: [68][7/8]	Loss 0.4160 (0.6036)	LossFusion 0.4160 (0.6036)	
Train Epoch: [68][7/8]	Loss 0.4160 (0.6036)	LossFusion 0.4160 (0.6036)	
Train Epoch: [68][7/8]	Loss 0.4160 (0.6036)	LossFusion 0.4160 (0.6036)	
Train Epoch: [68][7/8]	Loss 0.4160 (0.6036)	LossFusion 0.4160 (0.6036)	
Train Epoch: [68][7/8]	Loss 0.4160 (0.6036)	LossFusion 0.4160 (0.6036)	
Train Epoch: [68][7/8]	Loss 0.4160 (0.6036)	LossFusion 0.4160 (0.6036)	
Train Epoch: [68][7/8]	Loss 0.4160 (0.6036)	LossFusion 0.4160 (0.6036)	
Train Epoch: [68][7/8]	Loss 0.4160 (0.6036)	LossFusion 0.4160 (0.6036)	
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
Train Epoch: [69][0/8]	Loss 0.7968 (0.7968)	LossFusion 0.7968 (0.7968)	
Train Epoch: [69][0/8]	Loss 0.7968 (0.7968)	LossFusion 0.7968 (0.7968)	
Train Epoch: [69][0/8]	Loss 0.7968 (0.7968)	LossFusion 0.7968 (0.7968)	
Train Epoch: [69][0/8]	Loss 0.7968 (0.7968)	LossFusion 0.7968 (0.7968)	
Train Epoch: [69][0/8]	Loss 0.7968 (0.7968)	LossFusion 0.7968 (0.7968)	
Train Epoch: [69][0/8]	Loss 0.7968 (0.7968)	LossFusion 0.7968 (0.7968)	
Train Epoch: [69][0/8]	Loss 0.7968 (0.7968)	LossFusion 0.7968 (0.7968)	
Train Epoch: [69][0/8]	Loss 0.7968 (0.7968)	LossFusion 0.7968 (0.7968)	
Train Epoch: [69][7/8]	Loss 0.4195 (0.6002)	LossFusion 0.4195 (0.6002)	
Train Epoch: [69][7/8]	Loss 0.4195 (0.6002)	LossFusion 0.4195 (0.6002)	
Train Epoch: [69][7/8]	Loss 0.4195 (0.6002)	LossFusion 0.4195 (0.6002)	
Train Epoch: [69][7/8]	Loss 0.4195 (0.6002)	LossFusion 0.4195 (0.6002)	
Train Epoch: [69][7/8]	Loss 0.4195 (0.6002)	LossFusion 0.4195 (0.6002)	
Train Epoch: [69][7/8]	Loss 0.4195 (0.6002)	LossFusion 0.4195 (0.6002)	
Train Epoch: [69][7/8]	Loss 0.4195 (0.6002)	LossFusion 0.4195 (0.6002)	
Train Epoch: [69][7/8]	Loss 0.4195 (0.6002)	LossFusion 0.4195 (0.6002)	
R@10:  55.59341311454773     R@50:  82.05565214157104
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  82.05565214157104
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  82.05565214157104
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  82.05565214157104
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  82.05565214157104
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  82.05565214157104
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  82.05565214157104
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  82.05565214157104
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
Train Epoch: [70][0/8]	Loss 0.7810 (0.7810)	LossFusion 0.7810 (0.7810)	
Train Epoch: [70][0/8]	Loss 0.7810 (0.7810)	LossFusion 0.7810 (0.7810)	
Train Epoch: [70][0/8]	Loss 0.7810 (0.7810)	LossFusion 0.7810 (0.7810)	
Train Epoch: [70][0/8]	Loss 0.7810 (0.7810)	LossFusion 0.7810 (0.7810)	
Train Epoch: [70][0/8]	Loss 0.7810 (0.7810)	LossFusion 0.7810 (0.7810)	
Train Epoch: [70][0/8]	Loss 0.7810 (0.7810)	LossFusion 0.7810 (0.7810)	
Train Epoch: [70][0/8]	Loss 0.7810 (0.7810)	LossFusion 0.7810 (0.7810)	
Train Epoch: [70][0/8]	Loss 0.7810 (0.7810)	LossFusion 0.7810 (0.7810)	
Train Epoch: [70][7/8]	Loss 0.4051 (0.5933)	LossFusion 0.4051 (0.5933)	
Train Epoch: [70][7/8]	Loss 0.4051 (0.5933)	LossFusion 0.4051 (0.5933)	
Train Epoch: [70][7/8]	Loss 0.4051 (0.5933)	LossFusion 0.4051 (0.5933)	
Train Epoch: [70][7/8]	Loss 0.4051 (0.5933)	LossFusion 0.4051 (0.5933)	
Train Epoch: [70][7/8]	Loss 0.4051 (0.5933)	LossFusion 0.4051 (0.5933)	
Train Epoch: [70][7/8]	Loss 0.4051 (0.5933)	LossFusion 0.4051 (0.5933)	
Train Epoch: [70][7/8]	Loss 0.4051 (0.5933)	LossFusion 0.4051 (0.5933)	
Train Epoch: [70][7/8]	Loss 0.4051 (0.5933)	LossFusion 0.4051 (0.5933)	
R@10:  55.8773398399353     R@50:  81.88529014587402
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.88529014587402
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.88529014587402
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.88529014587402
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.88529014587402
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.88529014587402
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.88529014587402
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.88529014587402
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
Train Epoch: [71][0/8]	Loss 0.7698 (0.7698)	LossFusion 0.7698 (0.7698)	
Train Epoch: [71][0/8]	Loss 0.7698 (0.7698)	LossFusion 0.7698 (0.7698)	
Train Epoch: [71][0/8]	Loss 0.7698 (0.7698)	LossFusion 0.7698 (0.7698)	
Train Epoch: [71][0/8]	Loss 0.7698 (0.7698)	LossFusion 0.7698 (0.7698)	
Train Epoch: [71][0/8]	Loss 0.7698 (0.7698)	LossFusion 0.7698 (0.7698)	
Train Epoch: [71][0/8]	Loss 0.7698 (0.7698)	LossFusion 0.7698 (0.7698)	
Train Epoch: [71][0/8]	Loss 0.7698 (0.7698)	LossFusion 0.7698 (0.7698)	
Train Epoch: [71][0/8]	Loss 0.7698 (0.7698)	LossFusion 0.7698 (0.7698)	
Train Epoch: [71][7/8]	Loss 0.4301 (0.6107)	LossFusion 0.4301 (0.6107)	
Train Epoch: [71][7/8]	Loss 0.4301 (0.6107)	LossFusion 0.4301 (0.6107)	
Train Epoch: [71][7/8]	Loss 0.4301 (0.6107)	LossFusion 0.4301 (0.6107)	
Train Epoch: [71][7/8]	Loss 0.4301 (0.6107)	LossFusion 0.4301 (0.6107)	
Train Epoch: [71][7/8]	Loss 0.4301 (0.6107)	LossFusion 0.4301 (0.6107)	
Train Epoch: [71][7/8]	Loss 0.4301 (0.6107)	LossFusion 0.4301 (0.6107)	
Train Epoch: [71][7/8]	Loss 0.4301 (0.6107)	LossFusion 0.4301 (0.6107)	
Train Epoch: [71][7/8]	Loss 0.4301 (0.6107)	LossFusion 0.4301 (0.6107)	
R@10:  56.10448718070984     R@50:  81.71493411064148
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.71493411064148
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.71493411064148
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.71493411064148
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.71493411064148
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.71493411064148
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.71493411064148
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.71493411064148
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
Train Epoch: [72][0/8]	Loss 0.8334 (0.8334)	LossFusion 0.8334 (0.8334)	
Train Epoch: [72][0/8]	Loss 0.8334 (0.8334)	LossFusion 0.8334 (0.8334)	
Train Epoch: [72][0/8]	Loss 0.8334 (0.8334)	LossFusion 0.8334 (0.8334)	
Train Epoch: [72][0/8]	Loss 0.8334 (0.8334)	LossFusion 0.8334 (0.8334)	
Train Epoch: [72][0/8]	Loss 0.8334 (0.8334)	LossFusion 0.8334 (0.8334)	
Train Epoch: [72][0/8]	Loss 0.8334 (0.8334)	LossFusion 0.8334 (0.8334)	
Train Epoch: [72][0/8]	Loss 0.8334 (0.8334)	LossFusion 0.8334 (0.8334)	
Train Epoch: [72][0/8]	Loss 0.8334 (0.8334)	LossFusion 0.8334 (0.8334)	
Train Epoch: [72][7/8]	Loss 0.3934 (0.6060)	LossFusion 0.3934 (0.6060)	
Train Epoch: [72][7/8]	Loss 0.3934 (0.6060)	LossFusion 0.3934 (0.6060)	
Train Epoch: [72][7/8]	Loss 0.3934 (0.6060)	LossFusion 0.3934 (0.6060)	
Train Epoch: [72][7/8]	Loss 0.3934 (0.6060)	LossFusion 0.3934 (0.6060)	
Train Epoch: [72][7/8]	Loss 0.3934 (0.6060)	LossFusion 0.3934 (0.6060)	
Train Epoch: [72][7/8]	Loss 0.3934 (0.6060)	LossFusion 0.3934 (0.6060)	
Train Epoch: [72][7/8]	Loss 0.3934 (0.6060)	LossFusion 0.3934 (0.6060)	
Train Epoch: [72][7/8]	Loss 0.3934 (0.6060)	LossFusion 0.3934 (0.6060)	
R@10:  55.934131145477295     R@50:  81.4310073852539
Mean Now:  68.6825692653656  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.4310073852539
Mean Now:  68.6825692653656  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.4310073852539
Mean Now:  68.6825692653656  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.4310073852539
Mean Now:  68.6825692653656  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.4310073852539
Mean Now:  68.6825692653656  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.4310073852539
Mean Now:  68.6825692653656  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.4310073852539
Mean Now:  68.6825692653656  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.4310073852539
Mean Now:  68.6825692653656  Best Mean Before:  69.44918 --------------------
Train Epoch: [73][0/8]	Loss 0.7712 (0.7712)	LossFusion 0.7712 (0.7712)	
Train Epoch: [73][0/8]	Loss 0.7712 (0.7712)	LossFusion 0.7712 (0.7712)	
Train Epoch: [73][0/8]	Loss 0.7712 (0.7712)	LossFusion 0.7712 (0.7712)	
Train Epoch: [73][0/8]	Loss 0.7712 (0.7712)	LossFusion 0.7712 (0.7712)	
Train Epoch: [73][0/8]	Loss 0.7712 (0.7712)	LossFusion 0.7712 (0.7712)	
Train Epoch: [73][0/8]	Loss 0.7712 (0.7712)	LossFusion 0.7712 (0.7712)	
Train Epoch: [73][0/8]	Loss 0.7712 (0.7712)	LossFusion 0.7712 (0.7712)	
Train Epoch: [73][0/8]	Loss 0.7712 (0.7712)	LossFusion 0.7712 (0.7712)	
Train Epoch: [73][7/8]	Loss 0.4298 (0.5951)	LossFusion 0.4298 (0.5951)	
Train Epoch: [73][7/8]	Loss 0.4298 (0.5951)	LossFusion 0.4298 (0.5951)	
Train Epoch: [73][7/8]	Loss 0.4298 (0.5951)	LossFusion 0.4298 (0.5951)	
Train Epoch: [73][7/8]	Loss 0.4298 (0.5951)	LossFusion 0.4298 (0.5951)	
Train Epoch: [73][7/8]	Loss 0.4298 (0.5951)	LossFusion 0.4298 (0.5951)	
Train Epoch: [73][7/8]	Loss 0.4298 (0.5951)	LossFusion 0.4298 (0.5951)	
Train Epoch: [73][7/8]	Loss 0.4298 (0.5951)	LossFusion 0.4298 (0.5951)	
Train Epoch: [73][7/8]	Loss 0.4298 (0.5951)	LossFusion 0.4298 (0.5951)	
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
Train Epoch: [74][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [74][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [74][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [74][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	Train Epoch: [74][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	

Train Epoch: [74][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [74][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [74][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [74][7/8]	Loss 0.4320 (0.5940)	LossFusion 0.4320 (0.5940)	
Train Epoch: [74][7/8]	Loss 0.4320 (0.5940)	LossFusion 0.4320 (0.5940)	
Train Epoch: [74][7/8]	Loss 0.4320 (0.5940)	LossFusion 0.4320 (0.5940)	
Train Epoch: [74][7/8]	Loss 0.4320 (0.5940)	LossFusion 0.4320 (0.5940)	
Train Epoch: [74][7/8]	Loss 0.4320 (0.5940)	LossFusion 0.4320 (0.5940)	
Train Epoch: [74][7/8]	Loss 0.4320 (0.5940)	LossFusion 0.4320 (0.5940)	
Train Epoch: [74][7/8]	Loss 0.4320 (0.5940)	LossFusion 0.4320 (0.5940)	
Train Epoch: [74][7/8]	Loss 0.4320 (0.5940)	LossFusion 0.4320 (0.5940)	
R@10:  55.59341311454773     R@50:  81.60136342048645
Mean Now:  68.59738826751709  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.60136342048645
Mean Now:  68.59738826751709  Best Mean Before:  69.44918 --------------------
R@10: R@10:   55.5934131145477355.59341311454773      R@50:     R@50:   81.6013634204864581.60136342048645

Mean Now: Mean Now:   68.5973882675170968.59738826751709   Best Mean Before:  Best Mean Before:   69.4491869.44918  ----------------------------------------

R@10:  55.59341311454773     R@50:  81.60136342048645
Mean Now:  68.59738826751709  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.60136342048645
Mean Now:  68.59738826751709  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.60136342048645
Mean Now:  68.59738826751709  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.60136342048645
Mean Now:  68.59738826751709  Best Mean Before:  69.44918 --------------------
Train Epoch: [75][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [75][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [75][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [75][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [75][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [75][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	Train Epoch: [75][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	

Train Epoch: [75][0/8]	Loss 0.7896 (0.7896)	LossFusion 0.7896 (0.7896)	
Train Epoch: [75][7/8]	Loss 0.4321 (0.5979)	LossFusion 0.4321 (0.5979)	
Train Epoch: [75][7/8]	Loss 0.4321 (0.5979)	LossFusion 0.4321 (0.5979)	
Train Epoch: [75][7/8]	Loss 0.4321 (0.5979)	LossFusion 0.4321 (0.5979)	
Train Epoch: [75][7/8]	Loss 0.4321 (0.5979)	LossFusion 0.4321 (0.5979)	
Train Epoch: [75][7/8]	Loss 0.4321 (0.5979)	LossFusion 0.4321 (0.5979)	
Train Epoch: [75][7/8]	Loss 0.4321 (0.5979)	LossFusion 0.4321 (0.5979)	
Train Epoch: [75][7/8]	Loss 0.4321 (0.5979)	LossFusion 0.4321 (0.5979)	
Train Epoch: [75][7/8]	Loss 0.4321 (0.5979)	LossFusion 0.4321 (0.5979)	
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.48779273033142
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
Train Epoch: [76][0/8]	Loss 0.7780 (0.7780)	LossFusion 0.7780 (0.7780)	
Train Epoch: [76][0/8]	Loss 0.7780 (0.7780)	LossFusion 0.7780 (0.7780)	
Train Epoch: [76][0/8]	Loss 0.7780 (0.7780)	LossFusion 0.7780 (0.7780)	
Train Epoch: [76][0/8]	Loss 0.7780 (0.7780)	LossFusion 0.7780 (0.7780)	
Train Epoch: [76][0/8]	Loss 0.7780 (0.7780)	LossFusion 0.7780 (0.7780)	
Train Epoch: [76][0/8]	Loss 0.7780 (0.7780)	LossFusion 0.7780 (0.7780)	
Train Epoch: [76][0/8]	Loss 0.7780 (0.7780)	LossFusion 0.7780 (0.7780)	
Train Epoch: [76][0/8]	Loss 0.7780 (0.7780)	LossFusion 0.7780 (0.7780)	
Train Epoch: [76][7/8]	Loss 0.4208 (0.6043)	LossFusion 0.4208 (0.6043)	
Train Epoch: [76][7/8]	Loss 0.4208 (0.6043)	LossFusion 0.4208 (0.6043)	
Train Epoch: [76][7/8]	Loss 0.4208 (0.6043)	LossFusion 0.4208 (0.6043)	
Train Epoch: [76][7/8]	Loss 0.4208 (0.6043)	LossFusion 0.4208 (0.6043)	
Train Epoch: [76][7/8]	Loss 0.4208 (0.6043)	LossFusion 0.4208 (0.6043)	
Train Epoch: [76][7/8]	Loss 0.4208 (0.6043)	LossFusion 0.4208 (0.6043)	
Train Epoch: [76][7/8]	Loss 0.4208 (0.6043)	LossFusion 0.4208 (0.6043)	
Train Epoch: [76][7/8]	Loss 0.4208 (0.6043)	LossFusion 0.4208 (0.6043)	
R@10:  55.99091649055481     R@50:  81.65814876556396
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.65814876556396
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.65814876556396
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.65814876556396
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.65814876556396
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.65814876556396
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.65814876556396
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.65814876556396
Mean Now:  68.82453262805939  Best Mean Before:  69.44918 --------------------
Train Epoch: [77][0/8]	Loss 0.7679 (0.7679)	LossFusion 0.7679 (0.7679)	
Train Epoch: [77][0/8]	Loss 0.7679 (0.7679)	LossFusion 0.7679 (0.7679)	
Train Epoch: [77][0/8]	Loss 0.7679 (0.7679)	LossFusion 0.7679 (0.7679)	
Train Epoch: [77][0/8]	Loss 0.7679 (0.7679)	LossFusion 0.7679 (0.7679)	
Train Epoch: [77][0/8]	Loss 0.7679 (0.7679)	LossFusion 0.7679 (0.7679)	
Train Epoch: [77][0/8]	Loss 0.7679 (0.7679)	LossFusion 0.7679 (0.7679)	
Train Epoch: [77][0/8]	Loss 0.7679 (0.7679)	LossFusion 0.7679 (0.7679)	
Train Epoch: [77][0/8]	Loss 0.7679 (0.7679)	LossFusion 0.7679 (0.7679)	
Train Epoch: [77][7/8]	Loss 0.4263 (0.5952)	LossFusion 0.4263 (0.5952)	
Train Epoch: [77][7/8]	Loss 0.4263 (0.5952)	LossFusion 0.4263 (0.5952)	
Train Epoch: [77][7/8]	Loss 0.4263 (0.5952)	LossFusion 0.4263 (0.5952)	
Train Epoch: [77][7/8]	Loss 0.4263 (0.5952)	LossFusion 0.4263 (0.5952)	
Train Epoch: [77][7/8]	Loss 0.4263 (0.5952)	LossFusion 0.4263 (0.5952)	
Train Epoch: [77][7/8]	Loss 0.4263 (0.5952)	LossFusion 0.4263 (0.5952)	
Train Epoch: [77][7/8]	Loss 0.4263 (0.5952)	LossFusion 0.4263 (0.5952)	
Train Epoch: [77][7/8]	Loss 0.4263 (0.5952)	LossFusion 0.4263 (0.5952)	
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [78][0/8]	Loss 0.7732 (0.7732)	LossFusion 0.7732 (0.7732)	
Train Epoch: [78][0/8]	Loss 0.7732 (0.7732)	LossFusion 0.7732 (0.7732)	
Train Epoch: [78][0/8]	Loss 0.7732 (0.7732)	LossFusion 0.7732 (0.7732)	
Train Epoch: [78][0/8]	Loss 0.7732 (0.7732)	LossFusion 0.7732 (0.7732)	
Train Epoch: [78][0/8]	Loss 0.7732 (0.7732)	LossFusion 0.7732 (0.7732)	
Train Epoch: [78][0/8]	Loss 0.7732 (0.7732)	LossFusion 0.7732 (0.7732)	
Train Epoch: [78][0/8]	Loss 0.7732 (0.7732)	LossFusion 0.7732 (0.7732)	
Train Epoch: [78][0/8]	Loss 0.7732 (0.7732)	LossFusion 0.7732 (0.7732)	
Train Epoch: [78][7/8]	Loss 0.3922 (0.5798)	LossFusion 0.3922 (0.5798)	
Train Epoch: [78][7/8]	Loss 0.3922 (0.5798)	LossFusion 0.3922 (0.5798)	
Train Epoch: [78][7/8]	Loss 0.3922 (0.5798)	LossFusion 0.3922 (0.5798)	
Train Epoch: [78][7/8]	Loss 0.3922 (0.5798)	LossFusion 0.3922 (0.5798)	
Train Epoch: [78][7/8]	Loss 0.3922 (0.5798)	LossFusion 0.3922 (0.5798)	Train Epoch: [78][7/8]	Loss 0.3922 (0.5798)	LossFusion 0.3922 (0.5798)	

Train Epoch: [78][7/8]	Loss 0.3922 (0.5798)	LossFusion 0.3922 (0.5798)	
Train Epoch: [78][7/8]	Loss 0.3922 (0.5798)	LossFusion 0.3922 (0.5798)	
R@10:  56.047701835632324     R@50:  81.71493411064148
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.71493411064148
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.71493411064148
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.71493411064148
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.71493411064148
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.71493411064148
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.71493411064148
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.71493411064148
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
Train Epoch: [79][0/8]	Loss 0.7444 (0.7444)	LossFusion 0.7444 (0.7444)	
Train Epoch: [79][0/8]	Loss 0.7444 (0.7444)	LossFusion 0.7444 (0.7444)	
Train Epoch: [79][0/8]	Loss 0.7444 (0.7444)	LossFusion 0.7444 (0.7444)	
Train Epoch: [79][0/8]	Loss 0.7444 (0.7444)	LossFusion 0.7444 (0.7444)	
Train Epoch: [79][0/8]	Loss 0.7444 (0.7444)	LossFusion 0.7444 (0.7444)	
Train Epoch: [79][0/8]	Loss 0.7444 (0.7444)	LossFusion 0.7444 (0.7444)	
Train Epoch: [79][0/8]	Loss 0.7444 (0.7444)	LossFusion 0.7444 (0.7444)	
Train Epoch: [79][0/8]	Loss 0.7444 (0.7444)	LossFusion 0.7444 (0.7444)	
Train Epoch: [79][7/8]	Loss 0.3734 (0.5746)	LossFusion 0.3734 (0.5746)	
Train Epoch: [79][7/8]	Loss 0.3734 (0.5746)	LossFusion 0.3734 (0.5746)	
Train Epoch: [79][7/8]	Loss 0.3734 (0.5746)	LossFusion 0.3734 (0.5746)	
Train Epoch: [79][7/8]	Loss 0.3734 (0.5746)	LossFusion 0.3734 (0.5746)	
Train Epoch: [79][7/8]	Loss 0.3734 (0.5746)	LossFusion 0.3734 (0.5746)	
Train Epoch: [79][7/8]	Loss 0.3734 (0.5746)	LossFusion 0.3734 (0.5746)	
Train Epoch: [79][7/8]	Loss 0.3734 (0.5746)	LossFusion 0.3734 (0.5746)	
Train Epoch: [79][7/8]	Loss 0.3734 (0.5746)	LossFusion 0.3734 (0.5746)	
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
Train Epoch: [80][0/8]	Loss 0.7604 (0.7604)	LossFusion 0.7604 (0.7604)	
Train Epoch: [80][0/8]	Loss 0.7604 (0.7604)	LossFusion 0.7604 (0.7604)	
Train Epoch: [80][0/8]	Loss 0.7604 (0.7604)	LossFusion 0.7604 (0.7604)	
Train Epoch: [80][0/8]	Loss 0.7604 (0.7604)	LossFusion 0.7604 (0.7604)	
Train Epoch: [80][0/8]	Loss 0.7604 (0.7604)	LossFusion 0.7604 (0.7604)	
Train Epoch: [80][0/8]	Loss 0.7604 (0.7604)	LossFusion 0.7604 (0.7604)	
Train Epoch: [80][0/8]	Loss 0.7604 (0.7604)	LossFusion 0.7604 (0.7604)	
Train Epoch: [80][0/8]	Loss 0.7604 (0.7604)	LossFusion 0.7604 (0.7604)	
Train Epoch: [80][7/8]	Loss 0.4463 (0.5913)	LossFusion 0.4463 (0.5913)	
Train Epoch: [80][7/8]	Loss 0.4463 (0.5913)	LossFusion 0.4463 (0.5913)	
Train Epoch: [80][7/8]	Loss 0.4463 (0.5913)	LossFusion 0.4463 (0.5913)	
Train Epoch: [80][7/8]	Loss 0.4463 (0.5913)	LossFusion 0.4463 (0.5913)	
Train Epoch: [80][7/8]	Loss 0.4463 (0.5913)	LossFusion 0.4463 (0.5913)	
Train Epoch: [80][7/8]	Loss 0.4463 (0.5913)	LossFusion 0.4463 (0.5913)	
Train Epoch: [80][7/8]	Loss 0.4463 (0.5913)	LossFusion 0.4463 (0.5913)	
Train Epoch: [80][7/8]	Loss 0.4463 (0.5913)	LossFusion 0.4463 (0.5913)	
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
Train Epoch: [81][0/8]	Loss 0.7437 (0.7437)	LossFusion 0.7437 (0.7437)	
Train Epoch: [81][0/8]	Loss 0.7437 (0.7437)	LossFusion 0.7437 (0.7437)	
Train Epoch: [81][0/8]	Loss 0.7437 (0.7437)	LossFusion 0.7437 (0.7437)	
Train Epoch: [81][0/8]	Loss 0.7437 (0.7437)	LossFusion 0.7437 (0.7437)	
Train Epoch: [81][0/8]	Loss 0.7437 (0.7437)	LossFusion 0.7437 (0.7437)	
Train Epoch: [81][0/8]	Loss 0.7437 (0.7437)	LossFusion 0.7437 (0.7437)	
Train Epoch: [81][0/8]	Loss 0.7437 (0.7437)	LossFusion 0.7437 (0.7437)	
Train Epoch: [81][0/8]	Loss 0.7437 (0.7437)	LossFusion 0.7437 (0.7437)	
Train Epoch: [81][7/8]	Loss 0.4111 (0.5755)	LossFusion 0.4111 (0.5755)	
Train Epoch: [81][7/8]	Loss 0.4111 (0.5755)	LossFusion 0.4111 (0.5755)	
Train Epoch: [81][7/8]	Loss 0.4111 (0.5755)	LossFusion 0.4111 (0.5755)	
Train Epoch: [81][7/8]	Loss 0.4111 (0.5755)	LossFusion 0.4111 (0.5755)	
Train Epoch: [81][7/8]	Loss 0.4111 (0.5755)	LossFusion 0.4111 (0.5755)	
Train Epoch: [81][7/8]	Loss 0.4111 (0.5755)	LossFusion 0.4111 (0.5755)	
Train Epoch: [81][7/8]	Loss 0.4111 (0.5755)	LossFusion 0.4111 (0.5755)	
Train Epoch: [81][7/8]	Loss 0.4111 (0.5755)	LossFusion 0.4111 (0.5755)	
R@10:  55.8773398399353     R@50:  81.54457807540894
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.54457807540894
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.54457807540894
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.54457807540894
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.54457807540894
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.54457807540894
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.54457807540894
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.8773398399353     R@50:  81.54457807540894
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
Train Epoch: [82][0/8]	Loss 0.7493 (0.7493)	LossFusion 0.7493 (0.7493)	
Train Epoch: [82][0/8]	Loss 0.7493 (0.7493)	LossFusion 0.7493 (0.7493)	
Train Epoch: [82][0/8]	Loss 0.7493 (0.7493)	LossFusion 0.7493 (0.7493)	
Train Epoch: [82][0/8]	Loss 0.7493 (0.7493)	LossFusion 0.7493 (0.7493)	
Train Epoch: [82][0/8]	Loss 0.7493 (0.7493)	LossFusion 0.7493 (0.7493)	
Train Epoch: [82][0/8]	Loss 0.7493 (0.7493)	LossFusion 0.7493 (0.7493)	
Train Epoch: [82][0/8]	Loss 0.7493 (0.7493)	LossFusion 0.7493 (0.7493)	
Train Epoch: [82][0/8]	Loss 0.7493 (0.7493)	LossFusion 0.7493 (0.7493)	
Train Epoch: [82][7/8]	Loss 0.3935 (0.5602)	LossFusion 0.3935 (0.5602)	
Train Epoch: [82][7/8]	Loss 0.3935 (0.5602)	LossFusion 0.3935 (0.5602)	
Train Epoch: [82][7/8]	Loss 0.3935 (0.5602)	LossFusion 0.3935 (0.5602)	
Train Epoch: [82][7/8]	Loss 0.3935 (0.5602)	LossFusion 0.3935 (0.5602)	
Train Epoch: [82][7/8]	Loss 0.3935 (0.5602)	LossFusion 0.3935 (0.5602)	
Train Epoch: [82][7/8]	Loss 0.3935 (0.5602)	LossFusion 0.3935 (0.5602)	
Train Epoch: [82][7/8]	Loss 0.3935 (0.5602)	LossFusion 0.3935 (0.5602)	
Train Epoch: [82][7/8]	Loss 0.3935 (0.5602)	LossFusion 0.3935 (0.5602)	
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
Train Epoch: [83][0/8]	Loss 0.7630 (0.7630)	LossFusion 0.7630 (0.7630)	
Train Epoch: [83][0/8]	Loss 0.7630 (0.7630)	LossFusion 0.7630 (0.7630)	
Train Epoch: [83][0/8]	Loss 0.7630 (0.7630)	LossFusion 0.7630 (0.7630)	
Train Epoch: [83][0/8]	Loss 0.7630 (0.7630)	LossFusion 0.7630 (0.7630)	
Train Epoch: [83][0/8]	Loss 0.7630 (0.7630)	LossFusion 0.7630 (0.7630)	
Train Epoch: [83][0/8]	Loss 0.7630 (0.7630)	LossFusion 0.7630 (0.7630)	
Train Epoch: [83][0/8]	Loss 0.7630 (0.7630)	LossFusion 0.7630 (0.7630)	
Train Epoch: [83][0/8]	Loss 0.7630 (0.7630)	LossFusion 0.7630 (0.7630)	
Train Epoch: [83][7/8]	Loss 0.3929 (0.5725)	LossFusion 0.3929 (0.5725)	
Train Epoch: [83][7/8]	Loss 0.3929 (0.5725)	LossFusion 0.3929 (0.5725)	
Train Epoch: [83][7/8]	Loss 0.3929 (0.5725)	LossFusion 0.3929 (0.5725)	
Train Epoch: [83][7/8]	Loss 0.3929 (0.5725)	LossFusion 0.3929 (0.5725)	
Train Epoch: [83][7/8]	Loss 0.3929 (0.5725)	LossFusion 0.3929 (0.5725)	
Train Epoch: [83][7/8]	Loss 0.3929 (0.5725)	LossFusion 0.3929 (0.5725)	
Train Epoch: [83][7/8]	Loss 0.3929 (0.5725)	LossFusion 0.3929 (0.5725)	
Train Epoch: [83][7/8]	Loss 0.3929 (0.5725)	LossFusion 0.3929 (0.5725)	
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
Train Epoch: [84][0/8]	Loss 0.7764 (0.7764)	LossFusion 0.7764 (0.7764)	
Train Epoch: [84][0/8]	Loss 0.7764 (0.7764)	LossFusion 0.7764 (0.7764)	
Train Epoch: [84][0/8]	Loss 0.7764 (0.7764)	LossFusion 0.7764 (0.7764)	
Train Epoch: [84][0/8]	Loss 0.7764 (0.7764)	LossFusion 0.7764 (0.7764)	
Train Epoch: [84][0/8]	Loss 0.7764 (0.7764)	LossFusion 0.7764 (0.7764)	
Train Epoch: [84][0/8]	Loss 0.7764 (0.7764)	LossFusion 0.7764 (0.7764)	
Train Epoch: [84][0/8]	Loss 0.7764 (0.7764)	LossFusion 0.7764 (0.7764)	
Train Epoch: [84][0/8]	Loss 0.7764 (0.7764)	LossFusion 0.7764 (0.7764)	
Train Epoch: [84][7/8]	Loss 0.4017 (0.5782)	LossFusion 0.4017 (0.5782)	
Train Epoch: [84][7/8]	Loss 0.4017 (0.5782)	LossFusion 0.4017 (0.5782)	
Train Epoch: [84][7/8]	Loss 0.4017 (0.5782)	LossFusion 0.4017 (0.5782)	
Train Epoch: [84][7/8]	Loss 0.4017 (0.5782)	LossFusion 0.4017 (0.5782)	
Train Epoch: [84][7/8]	Loss 0.4017 (0.5782)	LossFusion 0.4017 (0.5782)	
Train Epoch: [84][7/8]	Loss 0.4017 (0.5782)	LossFusion 0.4017 (0.5782)	
Train Epoch: [84][7/8]	Loss 0.4017 (0.5782)	LossFusion 0.4017 (0.5782)	
Train Epoch: [84][7/8]	Loss 0.4017 (0.5782)	LossFusion 0.4017 (0.5782)	
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [85][0/8]	Loss 0.7657 (0.7657)	LossFusion 0.7657 (0.7657)	
Train Epoch: [85][0/8]	Loss 0.7657 (0.7657)	LossFusion 0.7657 (0.7657)	
Train Epoch: [85][0/8]	Loss 0.7657 (0.7657)	LossFusion 0.7657 (0.7657)	
Train Epoch: [85][0/8]	Loss 0.7657 (0.7657)	LossFusion 0.7657 (0.7657)	
Train Epoch: [85][0/8]	Loss 0.7657 (0.7657)	LossFusion 0.7657 (0.7657)	
Train Epoch: [85][0/8]	Loss 0.7657 (0.7657)	LossFusion 0.7657 (0.7657)	
Train Epoch: [85][0/8]	Loss 0.7657 (0.7657)	LossFusion 0.7657 (0.7657)	
Train Epoch: [85][0/8]	Loss 0.7657 (0.7657)	LossFusion 0.7657 (0.7657)	
Train Epoch: [85][7/8]	Loss 0.4134 (0.5684)	LossFusion 0.4134 (0.5684)	
Train Epoch: [85][7/8]	Loss 0.4134 (0.5684)	LossFusion 0.4134 (0.5684)	
Train Epoch: [85][7/8]	Loss 0.4134 (0.5684)	LossFusion 0.4134 (0.5684)	
Train Epoch: [85][7/8]	Loss 0.4134 (0.5684)	LossFusion 0.4134 (0.5684)	
Train Epoch: [85][7/8]	Loss 0.4134 (0.5684)	LossFusion 0.4134 (0.5684)	
Train Epoch: [85][7/8]	Loss 0.4134 (0.5684)	LossFusion 0.4134 (0.5684)	
Train Epoch: [85][7/8]	Loss 0.4134 (0.5684)	LossFusion 0.4134 (0.5684)	
Train Epoch: [85][7/8]	Loss 0.4134 (0.5684)	LossFusion 0.4134 (0.5684)	
R@10:  55.934131145477295     R@50:  81.94207549095154
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.94207549095154
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.94207549095154
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.94207549095154
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.94207549095154
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.94207549095154
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.94207549095154
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.94207549095154
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
Train Epoch: [86][0/8]	Loss 0.7398 (0.7398)	LossFusion 0.7398 (0.7398)	
Train Epoch: [86][0/8]	Loss 0.7398 (0.7398)	LossFusion 0.7398 (0.7398)	Train Epoch: [86][0/8]	Loss 0.7398 (0.7398)	LossFusion 0.7398 (0.7398)	

Train Epoch: [86][0/8]	Loss 0.7398 (0.7398)	LossFusion 0.7398 (0.7398)	
Train Epoch: [86][0/8]	Loss 0.7398 (0.7398)	LossFusion 0.7398 (0.7398)	
Train Epoch: [86][0/8]	Loss 0.7398 (0.7398)	LossFusion 0.7398 (0.7398)	
Train Epoch: [86][0/8]	Loss 0.7398 (0.7398)	LossFusion 0.7398 (0.7398)	
Train Epoch: [86][0/8]	Loss 0.7398 (0.7398)	LossFusion 0.7398 (0.7398)	
Train Epoch: [86][7/8]	Loss 0.4175 (0.5756)	LossFusion 0.4175 (0.5756)	
Train Epoch: [86][7/8]	Loss 0.4175 (0.5756)	LossFusion 0.4175 (0.5756)	
Train Epoch: [86][7/8]	Loss 0.4175 (0.5756)	LossFusion 0.4175 (0.5756)	Train Epoch: [86][7/8]	Loss 0.4175 (0.5756)	LossFusion 0.4175 (0.5756)	

Train Epoch: [86][7/8]	Loss 0.4175 (0.5756)	LossFusion 0.4175 (0.5756)	
Train Epoch: [86][7/8]	Loss 0.4175 (0.5756)	LossFusion 0.4175 (0.5756)	
Train Epoch: [86][7/8]	Loss 0.4175 (0.5756)	LossFusion 0.4175 (0.5756)	
Train Epoch: [86][7/8]	Loss 0.4175 (0.5756)	LossFusion 0.4175 (0.5756)	
R@10:  56.047701835632324     R@50:  81.82850480079651
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.82850480079651
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.82850480079651
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.82850480079651
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.82850480079651
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.82850480079651
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.82850480079651
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.82850480079651
Mean Now:  68.93810331821442  Best Mean Before:  69.44918 --------------------
Train Epoch: [87][0/8]	Loss 0.7574 (0.7574)	LossFusion 0.7574 (0.7574)	
Train Epoch: [87][0/8]	Loss 0.7574 (0.7574)	LossFusion 0.7574 (0.7574)	
Train Epoch: [87][0/8]	Loss 0.7574 (0.7574)	LossFusion 0.7574 (0.7574)	
Train Epoch: [87][0/8]	Loss 0.7574 (0.7574)	LossFusion 0.7574 (0.7574)	
Train Epoch: [87][0/8]	Loss 0.7574 (0.7574)	LossFusion 0.7574 (0.7574)	
Train Epoch: [87][0/8]	Loss 0.7574 (0.7574)	LossFusion 0.7574 (0.7574)	Train Epoch: [87][0/8]	Loss 0.7574 (0.7574)	LossFusion 0.7574 (0.7574)	

Train Epoch: [87][0/8]	Loss 0.7574 (0.7574)	LossFusion 0.7574 (0.7574)	
Train Epoch: [87][7/8]	Loss 0.4277 (0.5659)	LossFusion 0.4277 (0.5659)	
Train Epoch: [87][7/8]	Loss 0.4277 (0.5659)	LossFusion 0.4277 (0.5659)	
Train Epoch: [87][7/8]	Loss 0.4277 (0.5659)	LossFusion 0.4277 (0.5659)	
Train Epoch: [87][7/8]	Loss 0.4277 (0.5659)	LossFusion 0.4277 (0.5659)	
Train Epoch: [87][7/8]	Loss 0.4277 (0.5659)	LossFusion 0.4277 (0.5659)	
Train Epoch: [87][7/8]	Loss 0.4277 (0.5659)	LossFusion 0.4277 (0.5659)	
Train Epoch: [87][7/8]	Loss 0.4277 (0.5659)	LossFusion 0.4277 (0.5659)	
Train Epoch: [87][7/8]	Loss 0.4277 (0.5659)	LossFusion 0.4277 (0.5659)	
R@10:  55.82055449485779     R@50:  81.94207549095154
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.94207549095154
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.94207549095154
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.94207549095154
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.94207549095154
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.94207549095154
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.94207549095154
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.94207549095154
Mean Now:  68.88131499290466  Best Mean Before:  69.44918 --------------------
Train Epoch: [88][0/8]	Loss 0.7880 (0.7880)	LossFusion 0.7880 (0.7880)	
Train Epoch: [88][0/8]	Loss 0.7880 (0.7880)	LossFusion 0.7880 (0.7880)	
Train Epoch: [88][0/8]	Loss 0.7880 (0.7880)	LossFusion 0.7880 (0.7880)	
Train Epoch: [88][0/8]	Loss 0.7880 (0.7880)	LossFusion 0.7880 (0.7880)	
Train Epoch: [88][0/8]	Loss 0.7880 (0.7880)	LossFusion 0.7880 (0.7880)	
Train Epoch: [88][0/8]	Loss 0.7880 (0.7880)	LossFusion 0.7880 (0.7880)	
Train Epoch: [88][0/8]	Loss 0.7880 (0.7880)	LossFusion 0.7880 (0.7880)	
Train Epoch: [88][0/8]	Loss 0.7880 (0.7880)	LossFusion 0.7880 (0.7880)	
Train Epoch: [88][7/8]	Loss 0.4189 (0.5938)	LossFusion 0.4189 (0.5938)	
Train Epoch: [88][7/8]	Loss 0.4189 (0.5938)	LossFusion 0.4189 (0.5938)	
Train Epoch: [88][7/8]	Loss 0.4189 (0.5938)	LossFusion 0.4189 (0.5938)	
Train Epoch: [88][7/8]	Loss 0.4189 (0.5938)	LossFusion 0.4189 (0.5938)	
Train Epoch: [88][7/8]	Loss 0.4189 (0.5938)	LossFusion 0.4189 (0.5938)	
Train Epoch: [88][7/8]	Loss 0.4189 (0.5938)	LossFusion 0.4189 (0.5938)	
Train Epoch: [88][7/8]	Loss 0.4189 (0.5938)	LossFusion 0.4189 (0.5938)	
Train Epoch: [88][7/8]	Loss 0.4189 (0.5938)	LossFusion 0.4189 (0.5938)	
R@10:  55.59341311454773     R@50:  81.771719455719
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.771719455719
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.771719455719
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.771719455719
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.771719455719
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.771719455719
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.771719455719
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.771719455719
Mean Now:  68.68256628513336  Best Mean Before:  69.44918 --------------------
Train Epoch: [89][0/8]	Loss 0.7909 (0.7909)	LossFusion 0.7909 (0.7909)	
Train Epoch: [89][0/8]	Loss 0.7909 (0.7909)	LossFusion 0.7909 (0.7909)	
Train Epoch: [89][0/8]	Loss 0.7909 (0.7909)	LossFusion 0.7909 (0.7909)	
Train Epoch: [89][0/8]	Loss 0.7909 (0.7909)	LossFusion 0.7909 (0.7909)	
Train Epoch: [89][0/8]	Loss 0.7909 (0.7909)	LossFusion 0.7909 (0.7909)	
Train Epoch: [89][0/8]	Loss 0.7909 (0.7909)	LossFusion 0.7909 (0.7909)	
Train Epoch: [89][0/8]	Loss 0.7909 (0.7909)	LossFusion 0.7909 (0.7909)	
Train Epoch: [89][0/8]	Loss 0.7909 (0.7909)	LossFusion 0.7909 (0.7909)	
Train Epoch: [89][7/8]	Loss 0.4112 (0.5805)	LossFusion 0.4112 (0.5805)	
Train Epoch: [89][7/8]	Loss 0.4112 (0.5805)	LossFusion 0.4112 (0.5805)	
Train Epoch: [89][7/8]	Loss 0.4112 (0.5805)	LossFusion 0.4112 (0.5805)	
Train Epoch: [89][7/8]	Loss 0.4112 (0.5805)	LossFusion 0.4112 (0.5805)	
Train Epoch: [89][7/8]	Loss 0.4112 (0.5805)	LossFusion 0.4112 (0.5805)	
Train Epoch: [89][7/8]	Loss 0.4112 (0.5805)	LossFusion 0.4112 (0.5805)	
Train Epoch: [89][7/8]	Loss 0.4112 (0.5805)	LossFusion 0.4112 (0.5805)	
Train Epoch: [89][7/8]	Loss 0.4112 (0.5805)	LossFusion 0.4112 (0.5805)	
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [90][0/8]	Loss 0.7197 (0.7197)	LossFusion 0.7197 (0.7197)	
Train Epoch: [90][0/8]	Loss 0.7197 (0.7197)	LossFusion 0.7197 (0.7197)	
Train Epoch: [90][0/8]	Loss 0.7197 (0.7197)	LossFusion 0.7197 (0.7197)	
Train Epoch: [90][0/8]	Loss 0.7197 (0.7197)	LossFusion 0.7197 (0.7197)	
Train Epoch: [90][0/8]	Loss 0.7197 (0.7197)	LossFusion 0.7197 (0.7197)	
Train Epoch: [90][0/8]	Loss 0.7197 (0.7197)	LossFusion 0.7197 (0.7197)	
Train Epoch: [90][0/8]	Loss 0.7197 (0.7197)	LossFusion 0.7197 (0.7197)	
Train Epoch: [90][0/8]	Loss 0.7197 (0.7197)	LossFusion 0.7197 (0.7197)	
Train Epoch: [90][7/8]	Loss 0.3967 (0.5689)	LossFusion 0.3967 (0.5689)	
Train Epoch: [90][7/8]	Loss 0.3967 (0.5689)	LossFusion 0.3967 (0.5689)	
Train Epoch: [90][7/8]	Loss 0.3967 (0.5689)	LossFusion 0.3967 (0.5689)	
Train Epoch: [90][7/8]	Loss 0.3967 (0.5689)	LossFusion 0.3967 (0.5689)	
Train Epoch: [90][7/8]	Loss 0.3967 (0.5689)	LossFusion 0.3967 (0.5689)	
Train Epoch: [90][7/8]	Loss 0.3967 (0.5689)	LossFusion 0.3967 (0.5689)	
Train Epoch: [90][7/8]	Loss 0.3967 (0.5689)	LossFusion 0.3967 (0.5689)	
Train Epoch: [90][7/8]	Loss 0.3967 (0.5689)	LossFusion 0.3967 (0.5689)	
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.82850480079651
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
Train Epoch: [91][0/8]	Loss 0.7271 (0.7271)	LossFusion 0.7271 (0.7271)	
Train Epoch: [91][0/8]	Loss 0.7271 (0.7271)	LossFusion 0.7271 (0.7271)	
Train Epoch: [91][0/8]	Loss 0.7271 (0.7271)	LossFusion 0.7271 (0.7271)	
Train Epoch: [91][0/8]	Loss 0.7271 (0.7271)	LossFusion 0.7271 (0.7271)	
Train Epoch: [91][0/8]	Loss 0.7271 (0.7271)	LossFusion 0.7271 (0.7271)	
Train Epoch: [91][0/8]	Loss 0.7271 (0.7271)	LossFusion 0.7271 (0.7271)	
Train Epoch: [91][0/8]	Loss 0.7271 (0.7271)	LossFusion 0.7271 (0.7271)	
Train Epoch: [91][0/8]	Loss 0.7271 (0.7271)	LossFusion 0.7271 (0.7271)	
Train Epoch: [91][7/8]	Loss 0.4134 (0.5722)	LossFusion 0.4134 (0.5722)	
Train Epoch: [91][7/8]	Loss 0.4134 (0.5722)	LossFusion 0.4134 (0.5722)	
Train Epoch: [91][7/8]	Loss 0.4134 (0.5722)	LossFusion 0.4134 (0.5722)	
Train Epoch: [91][7/8]	Loss 0.4134 (0.5722)	LossFusion 0.4134 (0.5722)	
Train Epoch: [91][7/8]	Loss 0.4134 (0.5722)	LossFusion 0.4134 (0.5722)	
Train Epoch: [91][7/8]	Loss 0.4134 (0.5722)	LossFusion 0.4134 (0.5722)	
Train Epoch: [91][7/8]	Loss 0.4134 (0.5722)	LossFusion 0.4134 (0.5722)	
Train Epoch: [91][7/8]	Loss 0.4134 (0.5722)	LossFusion 0.4134 (0.5722)	
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
Train Epoch: [92][0/8]	Loss 0.7542 (0.7542)	LossFusion 0.7542 (0.7542)	
Train Epoch: [92][0/8]	Loss 0.7542 (0.7542)	LossFusion 0.7542 (0.7542)	
Train Epoch: [92][0/8]	Loss 0.7542 (0.7542)	LossFusion 0.7542 (0.7542)	
Train Epoch: [92][0/8]	Loss 0.7542 (0.7542)	LossFusion 0.7542 (0.7542)	
Train Epoch: [92][0/8]	Loss 0.7542 (0.7542)	LossFusion 0.7542 (0.7542)	
Train Epoch: [92][0/8]	Loss 0.7542 (0.7542)	LossFusion 0.7542 (0.7542)	
Train Epoch: [92][0/8]	Loss 0.7542 (0.7542)	LossFusion 0.7542 (0.7542)	
Train Epoch: [92][0/8]	Loss 0.7542 (0.7542)	LossFusion 0.7542 (0.7542)	
Train Epoch: [92][7/8]	Loss 0.3821 (0.5685)	LossFusion 0.3821 (0.5685)	
Train Epoch: [92][7/8]	Loss 0.3821 (0.5685)	LossFusion 0.3821 (0.5685)	
Train Epoch: [92][7/8]	Loss 0.3821 (0.5685)	LossFusion 0.3821 (0.5685)	
Train Epoch: [92][7/8]	Loss 0.3821 (0.5685)	LossFusion 0.3821 (0.5685)	
Train Epoch: [92][7/8]	Loss 0.3821 (0.5685)	LossFusion 0.3821 (0.5685)	
Train Epoch: [92][7/8]	Loss 0.3821 (0.5685)	LossFusion 0.3821 (0.5685)	
Train Epoch: [92][7/8]	Loss 0.3821 (0.5685)	LossFusion 0.3821 (0.5685)	
Train Epoch: [92][7/8]	Loss 0.3821 (0.5685)	LossFusion 0.3821 (0.5685)	
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.94207549095154
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
Train Epoch: [93][0/8]	Loss 0.7418 (0.7418)	LossFusion 0.7418 (0.7418)	
Train Epoch: [93][0/8]	Loss 0.7418 (0.7418)	LossFusion 0.7418 (0.7418)	
Train Epoch: [93][0/8]	Loss 0.7418 (0.7418)	LossFusion 0.7418 (0.7418)	
Train Epoch: [93][0/8]	Loss 0.7418 (0.7418)	LossFusion 0.7418 (0.7418)	
Train Epoch: [93][0/8]	Loss 0.7418 (0.7418)	LossFusion 0.7418 (0.7418)	
Train Epoch: [93][0/8]	Loss 0.7418 (0.7418)	LossFusion 0.7418 (0.7418)	
Train Epoch: [93][0/8]	Loss 0.7418 (0.7418)	LossFusion 0.7418 (0.7418)	
Train Epoch: [93][0/8]	Loss 0.7418 (0.7418)	LossFusion 0.7418 (0.7418)	
Train Epoch: [93][7/8]	Loss 0.4018 (0.5661)	LossFusion 0.4018 (0.5661)	
Train Epoch: [93][7/8]	Loss 0.4018 (0.5661)	LossFusion 0.4018 (0.5661)	
Train Epoch: [93][7/8]	Loss 0.4018 (0.5661)	LossFusion 0.4018 (0.5661)	
Train Epoch: [93][7/8]	Loss 0.4018 (0.5661)	LossFusion 0.4018 (0.5661)	
Train Epoch: [93][7/8]	Loss 0.4018 (0.5661)	LossFusion 0.4018 (0.5661)	
Train Epoch: [93][7/8]	Loss 0.4018 (0.5661)	LossFusion 0.4018 (0.5661)	
Train Epoch: [93][7/8]	Loss 0.4018 (0.5661)	LossFusion 0.4018 (0.5661)	
Train Epoch: [93][7/8]	Loss 0.4018 (0.5661)	LossFusion 0.4018 (0.5661)	
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [94][0/8]	Loss 0.6974 (0.6974)	LossFusion 0.6974 (0.6974)	
Train Epoch: [94][0/8]	Loss 0.6974 (0.6974)	LossFusion 0.6974 (0.6974)	
Train Epoch: [94][0/8]	Loss 0.6974 (0.6974)	LossFusion 0.6974 (0.6974)	
Train Epoch: [94][0/8]	Loss 0.6974 (0.6974)	LossFusion 0.6974 (0.6974)	
Train Epoch: [94][0/8]	Loss 0.6974 (0.6974)	LossFusion 0.6974 (0.6974)	
Train Epoch: [94][0/8]	Loss 0.6974 (0.6974)	LossFusion 0.6974 (0.6974)	
Train Epoch: [94][0/8]	Loss 0.6974 (0.6974)	LossFusion 0.6974 (0.6974)	
Train Epoch: [94][0/8]	Loss 0.6974 (0.6974)	LossFusion 0.6974 (0.6974)	
Train Epoch: [94][7/8]	Loss 0.3890 (0.5615)	LossFusion 0.3890 (0.5615)	
Train Epoch: [94][7/8]	Loss 0.3890 (0.5615)	LossFusion 0.3890 (0.5615)	
Train Epoch: [94][7/8]	Loss 0.3890 (0.5615)	LossFusion 0.3890 (0.5615)	
Train Epoch: [94][7/8]	Loss 0.3890 (0.5615)	LossFusion 0.3890 (0.5615)	
Train Epoch: [94][7/8]	Loss 0.3890 (0.5615)	LossFusion 0.3890 (0.5615)	
Train Epoch: [94][7/8]	Loss 0.3890 (0.5615)	LossFusion 0.3890 (0.5615)	
Train Epoch: [94][7/8]	Loss 0.3890 (0.5615)	LossFusion 0.3890 (0.5615)	
Train Epoch: [94][7/8]	Loss 0.3890 (0.5615)	LossFusion 0.3890 (0.5615)	
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.94207549095154
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
Train Epoch: [95][0/8]	Loss 0.7676 (0.7676)	LossFusion 0.7676 (0.7676)	
Train Epoch: [95][0/8]	Loss 0.7676 (0.7676)	LossFusion 0.7676 (0.7676)	
Train Epoch: [95][0/8]	Loss 0.7676 (0.7676)	LossFusion 0.7676 (0.7676)	
Train Epoch: [95][0/8]	Loss 0.7676 (0.7676)	LossFusion 0.7676 (0.7676)	
Train Epoch: [95][0/8]	Loss 0.7676 (0.7676)	LossFusion 0.7676 (0.7676)	
Train Epoch: [95][0/8]	Loss 0.7676 (0.7676)	LossFusion 0.7676 (0.7676)	
Train Epoch: [95][0/8]	Loss 0.7676 (0.7676)	LossFusion 0.7676 (0.7676)	
Train Epoch: [95][0/8]	Loss 0.7676 (0.7676)	LossFusion 0.7676 (0.7676)	
Train Epoch: [95][7/8]	Loss 0.4203 (0.5706)	LossFusion 0.4203 (0.5706)	
Train Epoch: [95][7/8]	Loss 0.4203 (0.5706)	LossFusion 0.4203 (0.5706)	
Train Epoch: [95][7/8]	Loss 0.4203 (0.5706)	LossFusion 0.4203 (0.5706)	
Train Epoch: [95][7/8]	Loss 0.4203 (0.5706)	LossFusion 0.4203 (0.5706)	
Train Epoch: [95][7/8]	Loss 0.4203 (0.5706)	LossFusion 0.4203 (0.5706)	
Train Epoch: [95][7/8]	Loss 0.4203 (0.5706)	LossFusion 0.4203 (0.5706)	
Train Epoch: [95][7/8]	Loss 0.4203 (0.5706)	LossFusion 0.4203 (0.5706)	
Train Epoch: [95][7/8]	Loss 0.4203 (0.5706)	LossFusion 0.4203 (0.5706)	
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [96][0/8]	Loss 0.7421 (0.7421)	LossFusion 0.7421 (0.7421)	
Train Epoch: [96][0/8]	Loss 0.7421 (0.7421)	LossFusion 0.7421 (0.7421)	
Train Epoch: [96][0/8]	Loss 0.7421 (0.7421)	LossFusion 0.7421 (0.7421)	
Train Epoch: [96][0/8]	Loss 0.7421 (0.7421)	LossFusion 0.7421 (0.7421)	
Train Epoch: [96][0/8]	Loss 0.7421 (0.7421)	LossFusion 0.7421 (0.7421)	
Train Epoch: [96][0/8]	Loss 0.7421 (0.7421)	LossFusion 0.7421 (0.7421)	
Train Epoch: [96][0/8]	Loss 0.7421 (0.7421)	LossFusion 0.7421 (0.7421)	
Train Epoch: [96][0/8]	Loss 0.7421 (0.7421)	LossFusion 0.7421 (0.7421)	
Train Epoch: [96][7/8]	Loss 0.3830 (0.5622)	LossFusion 0.3830 (0.5622)	
Train Epoch: [96][7/8]	Loss 0.3830 (0.5622)	LossFusion 0.3830 (0.5622)	
Train Epoch: [96][7/8]	Loss 0.3830 (0.5622)	LossFusion 0.3830 (0.5622)	
Train Epoch: [96][7/8]	Loss 0.3830 (0.5622)	LossFusion 0.3830 (0.5622)	
Train Epoch: [96][7/8]	Loss 0.3830 (0.5622)	LossFusion 0.3830 (0.5622)	
Train Epoch: [96][7/8]	Loss 0.3830 (0.5622)	LossFusion 0.3830 (0.5622)	
Train Epoch: [96][7/8]	Loss 0.3830 (0.5622)	LossFusion 0.3830 (0.5622)	
Train Epoch: [96][7/8]	Loss 0.3830 (0.5622)	LossFusion 0.3830 (0.5622)	
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
Train Epoch: [97][0/8]	Loss 0.7299 (0.7299)	LossFusion 0.7299 (0.7299)	
Train Epoch: [97][0/8]	Loss 0.7299 (0.7299)	LossFusion 0.7299 (0.7299)	
Train Epoch: [97][0/8]	Loss 0.7299 (0.7299)	LossFusion 0.7299 (0.7299)	
Train Epoch: [97][0/8]	Loss 0.7299 (0.7299)	LossFusion 0.7299 (0.7299)	
Train Epoch: [97][0/8]	Loss 0.7299 (0.7299)	LossFusion 0.7299 (0.7299)	
Train Epoch: [97][0/8]	Loss 0.7299 (0.7299)	LossFusion 0.7299 (0.7299)	
Train Epoch: [97][0/8]	Loss 0.7299 (0.7299)	LossFusion 0.7299 (0.7299)	
Train Epoch: [97][0/8]	Loss 0.7299 (0.7299)	LossFusion 0.7299 (0.7299)	
Train Epoch: [97][7/8]	Loss 0.4150 (0.5648)	LossFusion 0.4150 (0.5648)	
Train Epoch: [97][7/8]	Loss 0.4150 (0.5648)	LossFusion 0.4150 (0.5648)	
Train Epoch: [97][7/8]	Loss 0.4150 (0.5648)	LossFusion 0.4150 (0.5648)	
Train Epoch: [97][7/8]	Loss 0.4150 (0.5648)	LossFusion 0.4150 (0.5648)	
Train Epoch: [97][7/8]	Loss 0.4150 (0.5648)	LossFusion 0.4150 (0.5648)	
Train Epoch: [97][7/8]	Loss 0.4150 (0.5648)	LossFusion 0.4150 (0.5648)	
Train Epoch: [97][7/8]	Loss 0.4150 (0.5648)	LossFusion 0.4150 (0.5648)	
Train Epoch: [97][7/8]	Loss 0.4150 (0.5648)	LossFusion 0.4150 (0.5648)	
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [98][0/8]	Loss 0.7594 (0.7594)	LossFusion 0.7594 (0.7594)	
Train Epoch: [98][0/8]	Loss 0.7594 (0.7594)	LossFusion 0.7594 (0.7594)	
Train Epoch: [98][0/8]	Loss 0.7594 (0.7594)	LossFusion 0.7594 (0.7594)	
Train Epoch: [98][0/8]	Loss 0.7594 (0.7594)	LossFusion 0.7594 (0.7594)	
Train Epoch: [98][0/8]	Loss 0.7594 (0.7594)	LossFusion 0.7594 (0.7594)	
Train Epoch: [98][0/8]	Loss 0.7594 (0.7594)	LossFusion 0.7594 (0.7594)	
Train Epoch: [98][0/8]	Loss 0.7594 (0.7594)	LossFusion 0.7594 (0.7594)	
Train Epoch: [98][0/8]	Loss 0.7594 (0.7594)	LossFusion 0.7594 (0.7594)	
Train Epoch: [98][7/8]	Loss 0.3859 (0.5721)	LossFusion 0.3859 (0.5721)	
Train Epoch: [98][7/8]	Loss 0.3859 (0.5721)	LossFusion 0.3859 (0.5721)	
Train Epoch: [98][7/8]	Loss 0.3859 (0.5721)	LossFusion 0.3859 (0.5721)	Train Epoch: [98][7/8]	Loss 0.3859 (0.5721)	LossFusion 0.3859 (0.5721)	

Train Epoch: [98][7/8]	Loss 0.3859 (0.5721)	LossFusion 0.3859 (0.5721)	
Train Epoch: [98][7/8]	Loss 0.3859 (0.5721)	LossFusion 0.3859 (0.5721)	
Train Epoch: [98][7/8]	Loss 0.3859 (0.5721)	LossFusion 0.3859 (0.5721)	
Train Epoch: [98][7/8]	Loss 0.3859 (0.5721)	LossFusion 0.3859 (0.5721)	
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [99][0/8]	Loss 0.7462 (0.7462)	LossFusion 0.7462 (0.7462)	
Train Epoch: [99][0/8]	Loss 0.7462 (0.7462)	LossFusion 0.7462 (0.7462)	
Train Epoch: [99][0/8]	Loss 0.7462 (0.7462)	LossFusion 0.7462 (0.7462)	
Train Epoch: [99][0/8]	Loss 0.7462 (0.7462)	LossFusion 0.7462 (0.7462)	
Train Epoch: [99][0/8]	Loss 0.7462 (0.7462)	LossFusion 0.7462 (0.7462)	
Train Epoch: [99][0/8]	Loss 0.7462 (0.7462)	LossFusion 0.7462 (0.7462)	
Train Epoch: [99][0/8]	Loss 0.7462 (0.7462)	LossFusion 0.7462 (0.7462)	
Train Epoch: [99][0/8]	Loss 0.7462 (0.7462)	LossFusion 0.7462 (0.7462)	
Train Epoch: [99][7/8]	Loss 0.4216 (0.5735)	LossFusion 0.4216 (0.5735)	
Train Epoch: [99][7/8]	Loss 0.4216 (0.5735)	LossFusion 0.4216 (0.5735)	
Train Epoch: [99][7/8]	Loss 0.4216 (0.5735)	LossFusion 0.4216 (0.5735)	
Train Epoch: [99][7/8]	Loss 0.4216 (0.5735)	LossFusion 0.4216 (0.5735)	
Train Epoch: [99][7/8]	Loss 0.4216 (0.5735)	LossFusion 0.4216 (0.5735)	
Train Epoch: [99][7/8]	Loss 0.4216 (0.5735)	LossFusion 0.4216 (0.5735)	
Train Epoch: [99][7/8]	Loss 0.4216 (0.5735)	LossFusion 0.4216 (0.5735)	
Train Epoch: [99][7/8]	Loss 0.4216 (0.5735)	LossFusion 0.4216 (0.5735)	
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [100][0/8]	Loss 0.7460 (0.7460)	LossFusion 0.7460 (0.7460)	
Train Epoch: [100][0/8]	Loss 0.7460 (0.7460)	LossFusion 0.7460 (0.7460)	
Train Epoch: [100][0/8]	Loss 0.7460 (0.7460)	LossFusion 0.7460 (0.7460)	
Train Epoch: [100][0/8]	Loss 0.7460 (0.7460)	LossFusion 0.7460 (0.7460)	
Train Epoch: [100][0/8]	Loss 0.7460 (0.7460)	LossFusion 0.7460 (0.7460)	
Train Epoch: [100][0/8]	Loss 0.7460 (0.7460)	LossFusion 0.7460 (0.7460)	
Train Epoch: [100][0/8]	Loss 0.7460 (0.7460)	LossFusion 0.7460 (0.7460)	
Train Epoch: [100][0/8]	Loss 0.7460 (0.7460)	LossFusion 0.7460 (0.7460)	
Train Epoch: [100][7/8]	Loss 0.4019 (0.5609)	LossFusion 0.4019 (0.5609)	
Train Epoch: [100][7/8]	Loss 0.4019 (0.5609)	LossFusion 0.4019 (0.5609)	
Train Epoch: [100][7/8]	Loss 0.4019 (0.5609)	LossFusion 0.4019 (0.5609)	
Train Epoch: [100][7/8]	Loss 0.4019 (0.5609)	LossFusion 0.4019 (0.5609)	
Train Epoch: [100][7/8]	Loss 0.4019 (0.5609)	LossFusion 0.4019 (0.5609)	
Train Epoch: [100][7/8]	Loss 0.4019 (0.5609)	LossFusion 0.4019 (0.5609)	
Train Epoch: [100][7/8]	Loss 0.4019 (0.5609)	LossFusion 0.4019 (0.5609)	
Train Epoch: [100][7/8]	Loss 0.4019 (0.5609)	LossFusion 0.4019 (0.5609)	
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [101][0/8]	Loss 0.7578 (0.7578)	LossFusion 0.7578 (0.7578)	
Train Epoch: [101][0/8]	Loss 0.7578 (0.7578)	LossFusion 0.7578 (0.7578)	
Train Epoch: [101][0/8]	Loss 0.7578 (0.7578)	LossFusion 0.7578 (0.7578)	
Train Epoch: [101][0/8]	Loss 0.7578 (0.7578)	LossFusion 0.7578 (0.7578)	
Train Epoch: [101][0/8]	Loss 0.7578 (0.7578)	LossFusion 0.7578 (0.7578)	
Train Epoch: [101][0/8]	Loss 0.7578 (0.7578)	LossFusion 0.7578 (0.7578)	
Train Epoch: [101][0/8]	Loss 0.7578 (0.7578)	LossFusion 0.7578 (0.7578)	
Train Epoch: [101][0/8]	Loss 0.7578 (0.7578)	LossFusion 0.7578 (0.7578)	
Train Epoch: [101][7/8]	Loss 0.3653 (0.5660)	LossFusion 0.3653 (0.5660)	
Train Epoch: [101][7/8]	Loss 0.3653 (0.5660)	LossFusion 0.3653 (0.5660)	
Train Epoch: [101][7/8]	Loss 0.3653 (0.5660)	LossFusion 0.3653 (0.5660)	
Train Epoch: [101][7/8]	Loss 0.3653 (0.5660)	LossFusion 0.3653 (0.5660)	
Train Epoch: [101][7/8]	Loss 0.3653 (0.5660)	LossFusion 0.3653 (0.5660)	
Train Epoch: [101][7/8]	Loss 0.3653 (0.5660)	LossFusion 0.3653 (0.5660)	
Train Epoch: [101][7/8]	Loss 0.3653 (0.5660)	LossFusion 0.3653 (0.5660)	
Train Epoch: [101][7/8]	Loss 0.3653 (0.5660)	LossFusion 0.3653 (0.5660)	
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
Train Epoch: [102][0/8]	Loss 0.7531 (0.7531)	LossFusion 0.7531 (0.7531)	
Train Epoch: [102][0/8]	Loss 0.7531 (0.7531)	LossFusion 0.7531 (0.7531)	
Train Epoch: [102][0/8]	Loss 0.7531 (0.7531)	LossFusion 0.7531 (0.7531)	
Train Epoch: [102][0/8]	Loss 0.7531 (0.7531)	LossFusion 0.7531 (0.7531)	
Train Epoch: [102][0/8]	Loss 0.7531 (0.7531)	LossFusion 0.7531 (0.7531)	
Train Epoch: [102][0/8]	Loss 0.7531 (0.7531)	LossFusion 0.7531 (0.7531)	
Train Epoch: [102][0/8]	Loss 0.7531 (0.7531)	LossFusion 0.7531 (0.7531)	
Train Epoch: [102][0/8]	Loss 0.7531 (0.7531)	LossFusion 0.7531 (0.7531)	
Train Epoch: [102][7/8]	Loss 0.4003 (0.5754)	LossFusion 0.4003 (0.5754)	
Train Epoch: [102][7/8]	Loss 0.4003 (0.5754)	LossFusion 0.4003 (0.5754)	
Train Epoch: [102][7/8]	Loss 0.4003 (0.5754)	LossFusion 0.4003 (0.5754)	
Train Epoch: [102][7/8]	Loss 0.4003 (0.5754)	LossFusion 0.4003 (0.5754)	
Train Epoch: [102][7/8]	Loss 0.4003 (0.5754)	LossFusion 0.4003 (0.5754)	
Train Epoch: [102][7/8]	Loss 0.4003 (0.5754)	LossFusion 0.4003 (0.5754)	
Train Epoch: [102][7/8]	Loss 0.4003 (0.5754)	LossFusion 0.4003 (0.5754)	
Train Epoch: [102][7/8]	Loss 0.4003 (0.5754)	LossFusion 0.4003 (0.5754)	
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10: R@10:   55.76376914978027 55.76376914978027    R@50:       R@50: 81.82850480079651 81.82850480079651

Mean Now:  Mean Now: 68.79613697528839  68.79613697528839 Best Mean Before:    Best Mean Before:  69.4491869.44918  ----------------------------------------

Train Epoch: [103][0/8]	Loss 0.7580 (0.7580)	LossFusion 0.7580 (0.7580)	
Train Epoch: [103][0/8]	Loss 0.7580 (0.7580)	LossFusion 0.7580 (0.7580)	
Train Epoch: [103][0/8]	Loss 0.7580 (0.7580)	LossFusion 0.7580 (0.7580)	
Train Epoch: [103][0/8]	Loss 0.7580 (0.7580)	LossFusion 0.7580 (0.7580)	
Train Epoch: [103][0/8]	Loss 0.7580 (0.7580)	LossFusion 0.7580 (0.7580)	
Train Epoch: [103][0/8]	Loss 0.7580 (0.7580)	LossFusion 0.7580 (0.7580)	
Train Epoch: [103][0/8]	Loss 0.7580 (0.7580)	LossFusion 0.7580 (0.7580)	
Train Epoch: [103][0/8]	Loss 0.7580 (0.7580)	LossFusion 0.7580 (0.7580)	
Train Epoch: [103][7/8]	Loss 0.3847 (0.5735)	LossFusion 0.3847 (0.5735)	
Train Epoch: [103][7/8]	Loss 0.3847 (0.5735)	LossFusion 0.3847 (0.5735)	
Train Epoch: [103][7/8]	Loss 0.3847 (0.5735)	LossFusion 0.3847 (0.5735)	
Train Epoch: [103][7/8]	Loss 0.3847 (0.5735)	LossFusion 0.3847 (0.5735)	
Train Epoch: [103][7/8]	Loss 0.3847 (0.5735)	LossFusion 0.3847 (0.5735)	
Train Epoch: [103][7/8]	Loss 0.3847 (0.5735)	LossFusion 0.3847 (0.5735)	
Train Epoch: [103][7/8]	Loss 0.3847 (0.5735)	LossFusion 0.3847 (0.5735)	
Train Epoch: [103][7/8]	Loss 0.3847 (0.5735)	LossFusion 0.3847 (0.5735)	
R@10:  55.82055449485779     R@50:  81.771719455719
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.771719455719
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.771719455719
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.771719455719
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.771719455719
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.771719455719
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.771719455719
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.771719455719
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [104][0/8]	Loss 0.7806 (0.7806)	LossFusion 0.7806 (0.7806)	
Train Epoch: [104][0/8]	Loss 0.7806 (0.7806)	LossFusion 0.7806 (0.7806)	
Train Epoch: [104][0/8]	Loss 0.7806 (0.7806)	LossFusion 0.7806 (0.7806)	
Train Epoch: [104][0/8]	Loss 0.7806 (0.7806)	LossFusion 0.7806 (0.7806)	
Train Epoch: [104][0/8]	Loss 0.7806 (0.7806)	LossFusion 0.7806 (0.7806)	
Train Epoch: [104][0/8]	Loss 0.7806 (0.7806)	LossFusion 0.7806 (0.7806)	
Train Epoch: [104][0/8]	Loss 0.7806 (0.7806)	LossFusion 0.7806 (0.7806)	
Train Epoch: [104][0/8]	Loss 0.7806 (0.7806)	LossFusion 0.7806 (0.7806)	
Train Epoch: [104][7/8]	Loss 0.4150 (0.5742)	LossFusion 0.4150 (0.5742)	
Train Epoch: [104][7/8]	Loss 0.4150 (0.5742)	LossFusion 0.4150 (0.5742)	
Train Epoch: [104][7/8]	Loss 0.4150 (0.5742)	LossFusion 0.4150 (0.5742)	
Train Epoch: [104][7/8]	Loss 0.4150 (0.5742)	LossFusion 0.4150 (0.5742)	
Train Epoch: [104][7/8]	Loss 0.4150 (0.5742)	LossFusion 0.4150 (0.5742)	
Train Epoch: [104][7/8]	Loss 0.4150 (0.5742)	LossFusion 0.4150 (0.5742)	
Train Epoch: [104][7/8]	Loss 0.4150 (0.5742)	LossFusion 0.4150 (0.5742)	
Train Epoch: [104][7/8]	Loss 0.4150 (0.5742)	LossFusion 0.4150 (0.5742)	
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10: R@10:   55.7637691497802755.76376914978027      R@50:     R@50:   81.77171945571981.771719455719

Mean Now: Mean Now:   68.7677443027496368.76774430274963   Best Mean Before:  Best Mean Before:   69.4491869.44918  ----------------------------------------

R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
Train Epoch: [105][0/8]	Loss 0.7704 (0.7704)	LossFusion 0.7704 (0.7704)	
Train Epoch: [105][0/8]	Loss 0.7704 (0.7704)	LossFusion 0.7704 (0.7704)	
Train Epoch: [105][0/8]	Loss 0.7704 (0.7704)	LossFusion 0.7704 (0.7704)	
Train Epoch: [105][0/8]	Loss 0.7704 (0.7704)	LossFusion 0.7704 (0.7704)	
Train Epoch: [105][0/8]	Loss 0.7704 (0.7704)	LossFusion 0.7704 (0.7704)	
Train Epoch: [105][0/8]	Loss 0.7704 (0.7704)	LossFusion 0.7704 (0.7704)	
Train Epoch: [105][0/8]	Loss 0.7704 (0.7704)	LossFusion 0.7704 (0.7704)	
Train Epoch: [105][0/8]	Loss 0.7704 (0.7704)	LossFusion 0.7704 (0.7704)	
Train Epoch: [105][7/8]	Loss 0.4332 (0.5908)	LossFusion 0.4332 (0.5908)	
Train Epoch: [105][7/8]	Loss 0.4332 (0.5908)	LossFusion 0.4332 (0.5908)	
Train Epoch: [105][7/8]	Loss 0.4332 (0.5908)	LossFusion 0.4332 (0.5908)	
Train Epoch: [105][7/8]	Loss 0.4332 (0.5908)	LossFusion 0.4332 (0.5908)	
Train Epoch: [105][7/8]	Loss 0.4332 (0.5908)	LossFusion 0.4332 (0.5908)	
Train Epoch: [105][7/8]	Loss 0.4332 (0.5908)	LossFusion 0.4332 (0.5908)	
Train Epoch: [105][7/8]	Loss 0.4332 (0.5908)	LossFusion 0.4332 (0.5908)	
Train Epoch: [105][7/8]	Loss 0.4332 (0.5908)	LossFusion 0.4332 (0.5908)	
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.82850480079651
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [106][0/8]	Loss 0.7547 (0.7547)	LossFusion 0.7547 (0.7547)	
Train Epoch: [106][0/8]	Loss 0.7547 (0.7547)	LossFusion 0.7547 (0.7547)	
Train Epoch: [106][0/8]	Loss 0.7547 (0.7547)	LossFusion 0.7547 (0.7547)	
Train Epoch: [106][0/8]	Loss 0.7547 (0.7547)	LossFusion 0.7547 (0.7547)	
Train Epoch: [106][0/8]	Loss 0.7547 (0.7547)	LossFusion 0.7547 (0.7547)	
Train Epoch: [106][0/8]	Loss 0.7547 (0.7547)	LossFusion 0.7547 (0.7547)	
Train Epoch: [106][0/8]	Loss 0.7547 (0.7547)	LossFusion 0.7547 (0.7547)	
Train Epoch: [106][0/8]	Loss 0.7547 (0.7547)	LossFusion 0.7547 (0.7547)	
Train Epoch: [106][7/8]	Loss 0.4416 (0.5812)	LossFusion 0.4416 (0.5812)	
Train Epoch: [106][7/8]	Loss 0.4416 (0.5812)	LossFusion 0.4416 (0.5812)	
Train Epoch: [106][7/8]	Loss 0.4416 (0.5812)	LossFusion 0.4416 (0.5812)	
Train Epoch: [106][7/8]	Loss 0.4416 (0.5812)	LossFusion 0.4416 (0.5812)	
Train Epoch: [106][7/8]	Loss 0.4416 (0.5812)	LossFusion 0.4416 (0.5812)	
Train Epoch: [106][7/8]	Loss 0.4416 (0.5812)	LossFusion 0.4416 (0.5812)	
Train Epoch: [106][7/8]	Loss 0.4416 (0.5812)	LossFusion 0.4416 (0.5812)	
Train Epoch: [106][7/8]	Loss 0.4416 (0.5812)	LossFusion 0.4416 (0.5812)	
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
Train Epoch: [107][0/8]	Loss 0.6994 (0.6994)	LossFusion 0.6994 (0.6994)	
Train Epoch: [107][0/8]	Loss 0.6994 (0.6994)	LossFusion 0.6994 (0.6994)	
Train Epoch: [107][0/8]	Loss 0.6994 (0.6994)	LossFusion 0.6994 (0.6994)	
Train Epoch: [107][0/8]	Loss 0.6994 (0.6994)	LossFusion 0.6994 (0.6994)	
Train Epoch: [107][0/8]	Loss 0.6994 (0.6994)	LossFusion 0.6994 (0.6994)	
Train Epoch: [107][0/8]	Loss 0.6994 (0.6994)	LossFusion 0.6994 (0.6994)	
Train Epoch: [107][0/8]	Loss 0.6994 (0.6994)	LossFusion 0.6994 (0.6994)	
Train Epoch: [107][0/8]	Loss 0.6994 (0.6994)	LossFusion 0.6994 (0.6994)	
Train Epoch: [107][7/8]	Loss 0.4103 (0.5568)	LossFusion 0.4103 (0.5568)	
Train Epoch: [107][7/8]	Loss 0.4103 (0.5568)	LossFusion 0.4103 (0.5568)	
Train Epoch: [107][7/8]	Loss 0.4103 (0.5568)	LossFusion 0.4103 (0.5568)	
Train Epoch: [107][7/8]	Loss 0.4103 (0.5568)	LossFusion 0.4103 (0.5568)	
Train Epoch: [107][7/8]	Loss 0.4103 (0.5568)	LossFusion 0.4103 (0.5568)	
Train Epoch: [107][7/8]	Loss 0.4103 (0.5568)	LossFusion 0.4103 (0.5568)	
Train Epoch: [107][7/8]	Loss 0.4103 (0.5568)	LossFusion 0.4103 (0.5568)	
Train Epoch: [107][7/8]	Loss 0.4103 (0.5568)	LossFusion 0.4103 (0.5568)	
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [108][0/8]	Loss 0.7314 (0.7314)	LossFusion 0.7314 (0.7314)	
Train Epoch: [108][0/8]	Loss 0.7314 (0.7314)	LossFusion 0.7314 (0.7314)	
Train Epoch: [108][0/8]	Loss 0.7314 (0.7314)	LossFusion 0.7314 (0.7314)	
Train Epoch: [108][0/8]	Loss 0.7314 (0.7314)	LossFusion 0.7314 (0.7314)	
Train Epoch: [108][0/8]	Loss 0.7314 (0.7314)	LossFusion 0.7314 (0.7314)	
Train Epoch: [108][0/8]	Loss 0.7314 (0.7314)	LossFusion 0.7314 (0.7314)	
Train Epoch: [108][0/8]	Loss 0.7314 (0.7314)	LossFusion 0.7314 (0.7314)	
Train Epoch: [108][0/8]	Loss 0.7314 (0.7314)	LossFusion 0.7314 (0.7314)	
Train Epoch: [108][7/8]	Loss 0.4050 (0.5720)	LossFusion 0.4050 (0.5720)	
Train Epoch: [108][7/8]	Loss 0.4050 (0.5720)	LossFusion 0.4050 (0.5720)	
Train Epoch: [108][7/8]	Loss 0.4050 (0.5720)	LossFusion 0.4050 (0.5720)	
Train Epoch: [108][7/8]	Loss 0.4050 (0.5720)	LossFusion 0.4050 (0.5720)	
Train Epoch: [108][7/8]	Loss 0.4050 (0.5720)	LossFusion 0.4050 (0.5720)	
Train Epoch: [108][7/8]	Loss 0.4050 (0.5720)	LossFusion 0.4050 (0.5720)	
Train Epoch: [108][7/8]	Loss 0.4050 (0.5720)	LossFusion 0.4050 (0.5720)	
Train Epoch: [108][7/8]	Loss 0.4050 (0.5720)	LossFusion 0.4050 (0.5720)	
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 R@10: -------------------- 
55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.771719455719
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
Train Epoch: [109][0/8]	Loss 0.7606 (0.7606)	LossFusion 0.7606 (0.7606)	
Train Epoch: [109][0/8]	Loss 0.7606 (0.7606)	LossFusion 0.7606 (0.7606)	
Train Epoch: [109][0/8]	Loss 0.7606 (0.7606)	LossFusion 0.7606 (0.7606)	
Train Epoch: [109][0/8]	Loss 0.7606 (0.7606)	LossFusion 0.7606 (0.7606)	
Train Epoch: [109][0/8]	Loss 0.7606 (0.7606)	LossFusion 0.7606 (0.7606)	
Train Epoch: [109][0/8]	Loss 0.7606 (0.7606)	LossFusion 0.7606 (0.7606)	
Train Epoch: [109][0/8]	Loss 0.7606 (0.7606)	LossFusion 0.7606 (0.7606)	
Train Epoch: [109][0/8]	Loss 0.7606 (0.7606)	LossFusion 0.7606 (0.7606)	
Train Epoch: [109][7/8]	Loss 0.4064 (0.5700)	LossFusion 0.4064 (0.5700)	
Train Epoch: [109][7/8]	Loss 0.4064 (0.5700)	LossFusion 0.4064 (0.5700)	
Train Epoch: [109][7/8]	Loss 0.4064 (0.5700)	LossFusion 0.4064 (0.5700)	
Train Epoch: [109][7/8]	Loss 0.4064 (0.5700)	LossFusion 0.4064 (0.5700)	
Train Epoch: [109][7/8]	Loss 0.4064 (0.5700)	LossFusion 0.4064 (0.5700)	
Train Epoch: [109][7/8]	Loss 0.4064 (0.5700)	LossFusion 0.4064 (0.5700)	
Train Epoch: [109][7/8]	Loss 0.4064 (0.5700)	LossFusion 0.4064 (0.5700)	
Train Epoch: [109][7/8]	Loss 0.4064 (0.5700)	LossFusion 0.4064 (0.5700)	
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
Train Epoch: [110][0/8]	Loss 0.7176 (0.7176)	LossFusion 0.7176 (0.7176)	
Train Epoch: [110][0/8]	Loss 0.7176 (0.7176)	LossFusion 0.7176 (0.7176)	
Train Epoch: [110][0/8]	Loss 0.7176 (0.7176)	LossFusion 0.7176 (0.7176)	
Train Epoch: [110][0/8]	Loss 0.7176 (0.7176)	LossFusion 0.7176 (0.7176)	
Train Epoch: [110][0/8]	Loss 0.7176 (0.7176)	LossFusion 0.7176 (0.7176)	
Train Epoch: [110][0/8]	Loss 0.7176 (0.7176)	LossFusion 0.7176 (0.7176)	
Train Epoch: [110][0/8]	Loss 0.7176 (0.7176)	LossFusion 0.7176 (0.7176)	
Train Epoch: [110][0/8]	Loss 0.7176 (0.7176)	LossFusion 0.7176 (0.7176)	
Train Epoch: [110][7/8]	Loss 0.3997 (0.5671)	LossFusion 0.3997 (0.5671)	
Train Epoch: [110][7/8]	Loss 0.3997 (0.5671)	LossFusion 0.3997 (0.5671)	
Train Epoch: [110][7/8]	Loss 0.3997 (0.5671)	LossFusion 0.3997 (0.5671)	
Train Epoch: [110][7/8]	Loss 0.3997 (0.5671)	LossFusion 0.3997 (0.5671)	
Train Epoch: [110][7/8]	Loss 0.3997 (0.5671)	LossFusion 0.3997 (0.5671)	
Train Epoch: [110][7/8]	Loss 0.3997 (0.5671)	LossFusion 0.3997 (0.5671)	
Train Epoch: [110][7/8]	Loss 0.3997 (0.5671)	LossFusion 0.3997 (0.5671)	
Train Epoch: [110][7/8]	Loss 0.3997 (0.5671)	LossFusion 0.3997 (0.5671)	
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.771719455719
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
Train Epoch: [111][0/8]	Loss 0.7520 (0.7520)	LossFusion 0.7520 (0.7520)	
Train Epoch: [111][0/8]	Loss 0.7520 (0.7520)	LossFusion 0.7520 (0.7520)	
Train Epoch: [111][0/8]	Loss 0.7520 (0.7520)	LossFusion 0.7520 (0.7520)	
Train Epoch: [111][0/8]	Loss 0.7520 (0.7520)	LossFusion 0.7520 (0.7520)	
Train Epoch: [111][0/8]	Loss 0.7520 (0.7520)	LossFusion 0.7520 (0.7520)	
Train Epoch: [111][0/8]	Loss 0.7520 (0.7520)	LossFusion 0.7520 (0.7520)	
Train Epoch: [111][0/8]	Loss 0.7520 (0.7520)	LossFusion 0.7520 (0.7520)	
Train Epoch: [111][0/8]	Loss 0.7520 (0.7520)	LossFusion 0.7520 (0.7520)	
Train Epoch: [111][7/8]	Loss 0.3977 (0.5652)	LossFusion 0.3977 (0.5652)	
Train Epoch: [111][7/8]	Loss 0.3977 (0.5652)	LossFusion 0.3977 (0.5652)	
Train Epoch: [111][7/8]	Loss 0.3977 (0.5652)	LossFusion 0.3977 (0.5652)	
Train Epoch: [111][7/8]	Loss 0.3977 (0.5652)	LossFusion 0.3977 (0.5652)	
Train Epoch: [111][7/8]	Loss 0.3977 (0.5652)	LossFusion 0.3977 (0.5652)	
Train Epoch: [111][7/8]	Loss 0.3977 (0.5652)	LossFusion 0.3977 (0.5652)	
Train Epoch: [111][7/8]	Loss 0.3977 (0.5652)	LossFusion 0.3977 (0.5652)	
Train Epoch: [111][7/8]	Loss 0.3977 (0.5652)	LossFusion 0.3977 (0.5652)	
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.88529014587402
Mean Now:  68.79613697528839  Best Mean Before:  69.44918 --------------------
Train Epoch: [112][0/8]	Loss 0.7825 (0.7825)	LossFusion 0.7825 (0.7825)	
Train Epoch: [112][0/8]	Loss 0.7825 (0.7825)	LossFusion 0.7825 (0.7825)	
Train Epoch: [112][0/8]	Loss 0.7825 (0.7825)	LossFusion 0.7825 (0.7825)	
Train Epoch: [112][0/8]	Loss 0.7825 (0.7825)	LossFusion 0.7825 (0.7825)	
Train Epoch: [112][0/8]	Loss 0.7825 (0.7825)	LossFusion 0.7825 (0.7825)	
Train Epoch: [112][0/8]	Loss 0.7825 (0.7825)	LossFusion 0.7825 (0.7825)	
Train Epoch: [112][0/8]	Loss 0.7825 (0.7825)	LossFusion 0.7825 (0.7825)	
Train Epoch: [112][0/8]	Loss 0.7825 (0.7825)	LossFusion 0.7825 (0.7825)	
Train Epoch: [112][7/8]	Loss 0.3872 (0.5704)	LossFusion 0.3872 (0.5704)	
Train Epoch: [112][7/8]	Loss 0.3872 (0.5704)	LossFusion 0.3872 (0.5704)	
Train Epoch: [112][7/8]	Loss 0.3872 (0.5704)	LossFusion 0.3872 (0.5704)	
Train Epoch: [112][7/8]	Loss 0.3872 (0.5704)	LossFusion 0.3872 (0.5704)	
Train Epoch: [112][7/8]	Loss 0.3872 (0.5704)	LossFusion 0.3872 (0.5704)	
Train Epoch: [112][7/8]	Loss 0.3872 (0.5704)	LossFusion 0.3872 (0.5704)	
Train Epoch: [112][7/8]	Loss 0.3872 (0.5704)	LossFusion 0.3872 (0.5704)	
Train Epoch: [112][7/8]	Loss 0.3872 (0.5704)	LossFusion 0.3872 (0.5704)	
R@10:  55.650198459625244     R@50:  81.88529014587402
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.88529014587402
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.88529014587402
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.88529014587402
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.88529014587402
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.88529014587402
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.88529014587402
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.88529014587402
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
Train Epoch: [113][0/8]	Loss 0.7387 (0.7387)	LossFusion 0.7387 (0.7387)	
Train Epoch: [113][0/8]	Loss 0.7387 (0.7387)	LossFusion 0.7387 (0.7387)	
Train Epoch: [113][0/8]	Loss 0.7387 (0.7387)	LossFusion 0.7387 (0.7387)	
Train Epoch: [113][0/8]	Loss 0.7387 (0.7387)	LossFusion 0.7387 (0.7387)	
Train Epoch: [113][0/8]	Loss 0.7387 (0.7387)	LossFusion 0.7387 (0.7387)	
Train Epoch: [113][0/8]	Loss 0.7387 (0.7387)	LossFusion 0.7387 (0.7387)	
Train Epoch: [113][0/8]	Loss 0.7387 (0.7387)	LossFusion 0.7387 (0.7387)	
Train Epoch: [113][0/8]	Loss 0.7387 (0.7387)	LossFusion 0.7387 (0.7387)	
Train Epoch: [113][7/8]	Loss 0.4056 (0.5608)	LossFusion 0.4056 (0.5608)	
Train Epoch: [113][7/8]	Loss 0.4056 (0.5608)	LossFusion 0.4056 (0.5608)	
Train Epoch: [113][7/8]	Loss 0.4056 (0.5608)	LossFusion 0.4056 (0.5608)	
Train Epoch: [113][7/8]	Loss 0.4056 (0.5608)	LossFusion 0.4056 (0.5608)	
Train Epoch: [113][7/8]	Loss 0.4056 (0.5608)	LossFusion 0.4056 (0.5608)	
Train Epoch: [113][7/8]	Loss 0.4056 (0.5608)	LossFusion 0.4056 (0.5608)	
Train Epoch: [113][7/8]	Loss 0.4056 (0.5608)	LossFusion 0.4056 (0.5608)	
Train Epoch: [113][7/8]	Loss 0.4056 (0.5608)	LossFusion 0.4056 (0.5608)	
R@10:  55.59341311454773     R@50:  81.88529014587402
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.88529014587402
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.88529014587402
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.88529014587402
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.88529014587402
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.88529014587402
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.88529014587402
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.88529014587402
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
Train Epoch: [114][0/8]	Loss 0.7553 (0.7553)	LossFusion 0.7553 (0.7553)	
Train Epoch: [114][0/8]	Loss 0.7553 (0.7553)	LossFusion 0.7553 (0.7553)	
Train Epoch: [114][0/8]	Loss 0.7553 (0.7553)	LossFusion 0.7553 (0.7553)	
Train Epoch: [114][0/8]	Loss 0.7553 (0.7553)	LossFusion 0.7553 (0.7553)	
Train Epoch: [114][0/8]	Loss 0.7553 (0.7553)	LossFusion 0.7553 (0.7553)	
Train Epoch: [114][0/8]	Loss 0.7553 (0.7553)	LossFusion 0.7553 (0.7553)	
Train Epoch: [114][0/8]	Loss 0.7553 (0.7553)	LossFusion 0.7553 (0.7553)	
Train Epoch: [114][0/8]	Loss 0.7553 (0.7553)	LossFusion 0.7553 (0.7553)	
Train Epoch: [114][7/8]	Loss 0.4267 (0.5814)	LossFusion 0.4267 (0.5814)	
Train Epoch: [114][7/8]	Loss 0.4267 (0.5814)	LossFusion 0.4267 (0.5814)	
Train Epoch: [114][7/8]	Loss 0.4267 (0.5814)	LossFusion 0.4267 (0.5814)	
Train Epoch: [114][7/8]	Loss 0.4267 (0.5814)	LossFusion 0.4267 (0.5814)	
Train Epoch: [114][7/8]	Loss 0.4267 (0.5814)	LossFusion 0.4267 (0.5814)	Train Epoch: [114][7/8]	Loss 0.4267 (0.5814)	LossFusion 0.4267 (0.5814)	

Train Epoch: [114][7/8]	Loss 0.4267 (0.5814)	LossFusion 0.4267 (0.5814)	
Train Epoch: [114][7/8]	Loss 0.4267 (0.5814)	LossFusion 0.4267 (0.5814)	
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
Train Epoch: [115][0/8]	Loss 0.7646 (0.7646)	LossFusion 0.7646 (0.7646)	
Train Epoch: [115][0/8]	Loss 0.7646 (0.7646)	LossFusion 0.7646 (0.7646)	
Train Epoch: [115][0/8]	Loss 0.7646 (0.7646)	LossFusion 0.7646 (0.7646)	
Train Epoch: [115][0/8]	Loss 0.7646 (0.7646)	LossFusion 0.7646 (0.7646)	
Train Epoch: [115][0/8]	Loss 0.7646 (0.7646)	LossFusion 0.7646 (0.7646)	
Train Epoch: [115][0/8]	Loss 0.7646 (0.7646)	LossFusion 0.7646 (0.7646)	
Train Epoch: [115][0/8]	Loss 0.7646 (0.7646)	LossFusion 0.7646 (0.7646)	
Train Epoch: [115][0/8]	Loss 0.7646 (0.7646)	LossFusion 0.7646 (0.7646)	
Train Epoch: [115][7/8]	Loss 0.4067 (0.5654)	LossFusion 0.4067 (0.5654)	
Train Epoch: [115][7/8]	Loss 0.4067 (0.5654)	LossFusion 0.4067 (0.5654)	
Train Epoch: [115][7/8]	Loss 0.4067 (0.5654)	LossFusion 0.4067 (0.5654)	
Train Epoch: [115][7/8]	Loss 0.4067 (0.5654)	LossFusion 0.4067 (0.5654)	
Train Epoch: [115][7/8]	Loss 0.4067 (0.5654)	LossFusion 0.4067 (0.5654)	
Train Epoch: [115][7/8]	Loss 0.4067 (0.5654)	LossFusion 0.4067 (0.5654)	
Train Epoch: [115][7/8]	Loss 0.4067 (0.5654)	LossFusion 0.4067 (0.5654)	
Train Epoch: [115][7/8]	Loss 0.4067 (0.5654)	LossFusion 0.4067 (0.5654)	
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
Train Epoch: [116][0/8]	Loss 0.7141 (0.7141)	LossFusion 0.7141 (0.7141)	
Train Epoch: [116][0/8]	Loss 0.7141 (0.7141)	LossFusion 0.7141 (0.7141)	
Train Epoch: [116][0/8]	Loss 0.7141 (0.7141)	LossFusion 0.7141 (0.7141)	
Train Epoch: [116][0/8]	Loss 0.7141 (0.7141)	LossFusion 0.7141 (0.7141)	
Train Epoch: [116][0/8]	Loss 0.7141 (0.7141)	LossFusion 0.7141 (0.7141)	
Train Epoch: [116][0/8]	Loss 0.7141 (0.7141)	LossFusion 0.7141 (0.7141)	
Train Epoch: [116][0/8]	Loss 0.7141 (0.7141)	LossFusion 0.7141 (0.7141)	
Train Epoch: [116][0/8]	Loss 0.7141 (0.7141)	LossFusion 0.7141 (0.7141)	
Train Epoch: [116][7/8]	Loss 0.4101 (0.5730)	LossFusion 0.4101 (0.5730)	
Train Epoch: [116][7/8]	Loss 0.4101 (0.5730)	LossFusion 0.4101 (0.5730)	
Train Epoch: [116][7/8]	Loss 0.4101 (0.5730)	LossFusion 0.4101 (0.5730)	
Train Epoch: [116][7/8]	Loss 0.4101 (0.5730)	LossFusion 0.4101 (0.5730)	
Train Epoch: [116][7/8]	Loss 0.4101 (0.5730)	LossFusion 0.4101 (0.5730)	
Train Epoch: [116][7/8]	Loss 0.4101 (0.5730)	LossFusion 0.4101 (0.5730)	
Train Epoch: [116][7/8]	Loss 0.4101 (0.5730)	LossFusion 0.4101 (0.5730)	
Train Epoch: [116][7/8]	Loss 0.4101 (0.5730)	LossFusion 0.4101 (0.5730)	
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
Train Epoch: [117][0/8]	Loss 0.7684 (0.7684)	LossFusion 0.7684 (0.7684)	
Train Epoch: [117][0/8]	Loss 0.7684 (0.7684)	LossFusion 0.7684 (0.7684)	
Train Epoch: [117][0/8]	Loss 0.7684 (0.7684)	LossFusion 0.7684 (0.7684)	
Train Epoch: [117][0/8]	Loss 0.7684 (0.7684)	LossFusion 0.7684 (0.7684)	
Train Epoch: [117][0/8]	Loss 0.7684 (0.7684)	LossFusion 0.7684 (0.7684)	
Train Epoch: [117][0/8]	Loss 0.7684 (0.7684)	LossFusion 0.7684 (0.7684)	
Train Epoch: [117][0/8]	Loss 0.7684 (0.7684)	LossFusion 0.7684 (0.7684)	
Train Epoch: [117][0/8]	Loss 0.7684 (0.7684)	LossFusion 0.7684 (0.7684)	
Train Epoch: [117][7/8]	Loss 0.3936 (0.5636)	LossFusion 0.3936 (0.5636)	
Train Epoch: [117][7/8]	Loss 0.3936 (0.5636)	LossFusion 0.3936 (0.5636)	
Train Epoch: [117][7/8]	Loss 0.3936 (0.5636)	LossFusion 0.3936 (0.5636)	
Train Epoch: [117][7/8]	Loss 0.3936 (0.5636)	LossFusion 0.3936 (0.5636)	
Train Epoch: [117][7/8]	Loss 0.3936 (0.5636)	LossFusion 0.3936 (0.5636)	
Train Epoch: [117][7/8]	Loss 0.3936 (0.5636)	LossFusion 0.3936 (0.5636)	
Train Epoch: [117][7/8]	Loss 0.3936 (0.5636)	LossFusion 0.3936 (0.5636)	
Train Epoch: [117][7/8]	Loss 0.3936 (0.5636)	LossFusion 0.3936 (0.5636)	
R@10:  55.76376914978027     R@50:  81.71493411064148
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.71493411064148
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.71493411064148
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.71493411064148
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.71493411064148
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.71493411064148
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.71493411064148
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.71493411064148
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
Train Epoch: [118][0/8]	Loss 0.7380 (0.7380)	LossFusion 0.7380 (0.7380)	
Train Epoch: [118][0/8]	Loss 0.7380 (0.7380)	LossFusion 0.7380 (0.7380)	
Train Epoch: [118][0/8]	Loss 0.7380 (0.7380)	LossFusion 0.7380 (0.7380)	
Train Epoch: [118][0/8]	Loss 0.7380 (0.7380)	LossFusion 0.7380 (0.7380)	
Train Epoch: [118][0/8]	Loss 0.7380 (0.7380)	LossFusion 0.7380 (0.7380)	
Train Epoch: [118][0/8]	Loss 0.7380 (0.7380)	LossFusion 0.7380 (0.7380)	
Train Epoch: [118][0/8]	Loss 0.7380 (0.7380)	LossFusion 0.7380 (0.7380)	
Train Epoch: [118][0/8]	Loss 0.7380 (0.7380)	LossFusion 0.7380 (0.7380)	
Train Epoch: [118][7/8]	Loss 0.4007 (0.5723)	LossFusion 0.4007 (0.5723)	
Train Epoch: [118][7/8]	Loss 0.4007 (0.5723)	LossFusion 0.4007 (0.5723)	
Train Epoch: [118][7/8]	Loss 0.4007 (0.5723)	LossFusion 0.4007 (0.5723)	
Train Epoch: [118][7/8]	Loss 0.4007 (0.5723)	LossFusion 0.4007 (0.5723)	
Train Epoch: [118][7/8]	Loss 0.4007 (0.5723)	LossFusion 0.4007 (0.5723)	
Train Epoch: [118][7/8]	Loss 0.4007 (0.5723)	LossFusion 0.4007 (0.5723)	
Train Epoch: [118][7/8]	Loss 0.4007 (0.5723)	LossFusion 0.4007 (0.5723)	
Train Epoch: [118][7/8]	Loss 0.4007 (0.5723)	LossFusion 0.4007 (0.5723)	
R@10:  56.047701835632324     R@50:  81.94207549095154
Mean Now:  68.99488866329193  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.94207549095154
Mean Now:  68.99488866329193  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.94207549095154
Mean Now:  68.99488866329193  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.94207549095154
Mean Now:  68.99488866329193  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.94207549095154
Mean Now:  68.99488866329193  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.94207549095154
Mean Now:  68.99488866329193  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.94207549095154
Mean Now:  68.99488866329193  Best Mean Before:  69.44918 --------------------
R@10:  56.047701835632324     R@50:  81.94207549095154
Mean Now:  68.99488866329193  Best Mean Before:  69.44918 --------------------
Train Epoch: [119][0/8]	Loss 0.7296 (0.7296)	LossFusion 0.7296 (0.7296)	
Train Epoch: [119][0/8]	Loss 0.7296 (0.7296)	LossFusion 0.7296 (0.7296)	
Train Epoch: [119][0/8]	Loss 0.7296 (0.7296)	LossFusion 0.7296 (0.7296)	
Train Epoch: [119][0/8]	Loss 0.7296 (0.7296)	LossFusion 0.7296 (0.7296)	
Train Epoch: [119][0/8]	Loss 0.7296 (0.7296)	LossFusion 0.7296 (0.7296)	
Train Epoch: [119][0/8]	Loss 0.7296 (0.7296)	LossFusion 0.7296 (0.7296)	
Train Epoch: [119][0/8]	Loss 0.7296 (0.7296)	LossFusion 0.7296 (0.7296)	
Train Epoch: [119][0/8]	Loss 0.7296 (0.7296)	LossFusion 0.7296 (0.7296)	
Train Epoch: [119][7/8]	Loss 0.4287 (0.5574)	LossFusion 0.4287 (0.5574)	
Train Epoch: [119][7/8]	Loss 0.4287 (0.5574)	LossFusion 0.4287 (0.5574)	
Train Epoch: [119][7/8]	Loss 0.4287 (0.5574)	LossFusion 0.4287 (0.5574)	
Train Epoch: [119][7/8]	Loss 0.4287 (0.5574)	LossFusion 0.4287 (0.5574)	
Train Epoch: [119][7/8]	Loss 0.4287 (0.5574)	LossFusion 0.4287 (0.5574)	
Train Epoch: [119][7/8]	Loss 0.4287 (0.5574)	LossFusion 0.4287 (0.5574)	
Train Epoch: [119][7/8]	Loss 0.4287 (0.5574)	LossFusion 0.4287 (0.5574)	
Train Epoch: [119][7/8]	Loss 0.4287 (0.5574)	LossFusion 0.4287 (0.5574)	
R@10:  56.38841390609741     R@50:  81.99886679649353
Mean Now:  69.19364035129547  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.99886679649353
Mean Now:  69.19364035129547  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.99886679649353
Mean Now:  69.19364035129547  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.99886679649353
Mean Now:  69.19364035129547  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.99886679649353
Mean Now:  69.19364035129547  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.99886679649353
Mean Now:  69.19364035129547  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.99886679649353
Mean Now:  69.19364035129547  Best Mean Before:  69.44918 --------------------
R@10:  56.38841390609741     R@50:  81.99886679649353
Mean Now:  69.19364035129547  Best Mean Before:  69.44918 --------------------
Train Epoch: [120][0/8]	Loss 0.7143 (0.7143)	LossFusion 0.7143 (0.7143)	
Train Epoch: [120][0/8]	Loss 0.7143 (0.7143)	LossFusion 0.7143 (0.7143)	
Train Epoch: [120][0/8]	Loss 0.7143 (0.7143)	LossFusion 0.7143 (0.7143)	
Train Epoch: [120][0/8]	Loss 0.7143 (0.7143)	LossFusion 0.7143 (0.7143)	
Train Epoch: [120][0/8]	Loss 0.7143 (0.7143)	LossFusion 0.7143 (0.7143)	
Train Epoch: [120][0/8]	Loss 0.7143 (0.7143)	LossFusion 0.7143 (0.7143)	
Train Epoch: [120][0/8]	Loss 0.7143 (0.7143)	LossFusion 0.7143 (0.7143)	
Train Epoch: [120][0/8]	Loss 0.7143 (0.7143)	LossFusion 0.7143 (0.7143)	
Train Epoch: [120][7/8]	Loss 0.4307 (0.5610)	LossFusion 0.4307 (0.5610)	
Train Epoch: [120][7/8]	Loss 0.4307 (0.5610)	LossFusion 0.4307 (0.5610)	
Train Epoch: [120][7/8]	Loss 0.4307 (0.5610)	LossFusion 0.4307 (0.5610)	
Train Epoch: [120][7/8]	Loss 0.4307 (0.5610)	LossFusion 0.4307 (0.5610)	
Train Epoch: [120][7/8]	Loss 0.4307 (0.5610)	LossFusion 0.4307 (0.5610)	
Train Epoch: [120][7/8]	Loss 0.4307 (0.5610)	LossFusion 0.4307 (0.5610)	
Train Epoch: [120][7/8]	Loss 0.4307 (0.5610)	LossFusion 0.4307 (0.5610)	
Train Epoch: [120][7/8]	Loss 0.4307 (0.5610)	LossFusion 0.4307 (0.5610)	
R@10:  55.70698380470276     R@50:  81.71493411064148
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.71493411064148
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.71493411064148
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.71493411064148
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.71493411064148
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.71493411064148
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.71493411064148
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.71493411064148
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
Train Epoch: [121][0/8]	Loss 0.7459 (0.7459)	LossFusion 0.7459 (0.7459)	
Train Epoch: [121][0/8]	Loss 0.7459 (0.7459)	LossFusion 0.7459 (0.7459)	
Train Epoch: [121][0/8]	Loss 0.7459 (0.7459)	LossFusion 0.7459 (0.7459)	
Train Epoch: [121][0/8]	Loss 0.7459 (0.7459)	LossFusion 0.7459 (0.7459)	
Train Epoch: [121][0/8]	Loss 0.7459 (0.7459)	LossFusion 0.7459 (0.7459)	
Train Epoch: [121][0/8]	Loss 0.7459 (0.7459)	LossFusion 0.7459 (0.7459)	
Train Epoch: [121][0/8]	Loss 0.7459 (0.7459)	LossFusion 0.7459 (0.7459)	
Train Epoch: [121][0/8]	Loss 0.7459 (0.7459)	LossFusion 0.7459 (0.7459)	
Train Epoch: [121][7/8]	Loss 0.3691 (0.5552)	LossFusion 0.3691 (0.5552)	
Train Epoch: [121][7/8]	Loss 0.3691 (0.5552)	LossFusion 0.3691 (0.5552)	
Train Epoch: [121][7/8]	Loss 0.3691 (0.5552)	LossFusion 0.3691 (0.5552)	
Train Epoch: [121][7/8]	Loss 0.3691 (0.5552)	LossFusion 0.3691 (0.5552)	
Train Epoch: [121][7/8]	Loss 0.3691 (0.5552)	LossFusion 0.3691 (0.5552)	
Train Epoch: [121][7/8]	Loss 0.3691 (0.5552)	LossFusion 0.3691 (0.5552)	
Train Epoch: [121][7/8]	Loss 0.3691 (0.5552)	LossFusion 0.3691 (0.5552)	
Train Epoch: [121][7/8]	Loss 0.3691 (0.5552)	LossFusion 0.3691 (0.5552)	
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.82850480079651
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
Train Epoch: [122][0/8]	Loss 0.7489 (0.7489)	LossFusion 0.7489 (0.7489)	
Train Epoch: [122][0/8]	Loss 0.7489 (0.7489)	LossFusion 0.7489 (0.7489)	
Train Epoch: [122][0/8]	Loss 0.7489 (0.7489)	LossFusion 0.7489 (0.7489)	
Train Epoch: [122][0/8]	Loss 0.7489 (0.7489)	LossFusion 0.7489 (0.7489)	
Train Epoch: [122][0/8]	Loss 0.7489 (0.7489)	LossFusion 0.7489 (0.7489)	
Train Epoch: [122][0/8]	Loss 0.7489 (0.7489)	LossFusion 0.7489 (0.7489)	
Train Epoch: [122][0/8]	Loss 0.7489 (0.7489)	LossFusion 0.7489 (0.7489)	
Train Epoch: [122][0/8]	Loss 0.7489 (0.7489)	LossFusion 0.7489 (0.7489)	
Train Epoch: [122][7/8]	Loss 0.3938 (0.5594)	LossFusion 0.3938 (0.5594)	
Train Epoch: [122][7/8]	Loss 0.3938 (0.5594)	LossFusion 0.3938 (0.5594)	
Train Epoch: [122][7/8]	Loss 0.3938 (0.5594)	LossFusion 0.3938 (0.5594)	
Train Epoch: [122][7/8]	Loss 0.3938 (0.5594)	LossFusion 0.3938 (0.5594)	
Train Epoch: [122][7/8]	Loss 0.3938 (0.5594)	LossFusion 0.3938 (0.5594)	
Train Epoch: [122][7/8]	Loss 0.3938 (0.5594)	LossFusion 0.3938 (0.5594)	
Train Epoch: [122][7/8]	Loss 0.3938 (0.5594)	LossFusion 0.3938 (0.5594)	
Train Epoch: [122][7/8]	Loss 0.3938 (0.5594)	LossFusion 0.3938 (0.5594)	
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.88529014587402
Mean Now:  68.8529223203659  Best Mean Before:  69.44918 --------------------
Train Epoch: [123][0/8]	Loss 0.7338 (0.7338)	LossFusion 0.7338 (0.7338)	
Train Epoch: [123][0/8]	Loss 0.7338 (0.7338)	LossFusion 0.7338 (0.7338)	
Train Epoch: [123][0/8]	Loss 0.7338 (0.7338)	LossFusion 0.7338 (0.7338)	
Train Epoch: [123][0/8]	Loss 0.7338 (0.7338)	LossFusion 0.7338 (0.7338)	
Train Epoch: [123][0/8]	Loss 0.7338 (0.7338)	LossFusion 0.7338 (0.7338)	
Train Epoch: [123][0/8]	Loss 0.7338 (0.7338)	LossFusion 0.7338 (0.7338)	
Train Epoch: [123][0/8]	Loss 0.7338 (0.7338)	LossFusion 0.7338 (0.7338)	
Train Epoch: [123][0/8]	Loss 0.7338 (0.7338)	LossFusion 0.7338 (0.7338)	
Train Epoch: [123][7/8]	Loss 0.3909 (0.5504)	LossFusion 0.3909 (0.5504)	Train Epoch: [123][7/8]	Loss 0.3909 (0.5504)	LossFusion 0.3909 (0.5504)	

Train Epoch: [123][7/8]	Loss 0.3909 (0.5504)	LossFusion 0.3909 (0.5504)	
Train Epoch: [123][7/8]	Loss 0.3909 (0.5504)	LossFusion 0.3909 (0.5504)	
Train Epoch: [123][7/8]	Loss 0.3909 (0.5504)	LossFusion 0.3909 (0.5504)	
Train Epoch: [123][7/8]	Loss 0.3909 (0.5504)	LossFusion 0.3909 (0.5504)	
Train Epoch: [123][7/8]	Loss 0.3909 (0.5504)	LossFusion 0.3909 (0.5504)	
Train Epoch: [123][7/8]	Loss 0.3909 (0.5504)	LossFusion 0.3909 (0.5504)	
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
R@10:  55.76376914978027     R@50:  81.88529014587402
Mean Now:  68.82452964782715  Best Mean Before:  69.44918 --------------------
Train Epoch: [124][0/8]	Loss 0.7258 (0.7258)	LossFusion 0.7258 (0.7258)	
Train Epoch: [124][0/8]	Loss 0.7258 (0.7258)	LossFusion 0.7258 (0.7258)	
Train Epoch: [124][0/8]	Loss 0.7258 (0.7258)	LossFusion 0.7258 (0.7258)	
Train Epoch: [124][0/8]	Loss 0.7258 (0.7258)	LossFusion 0.7258 (0.7258)	
Train Epoch: [124][0/8]	Loss 0.7258 (0.7258)	LossFusion 0.7258 (0.7258)	
Train Epoch: [124][0/8]	Loss 0.7258 (0.7258)	LossFusion 0.7258 (0.7258)	
Train Epoch: [124][0/8]	Loss 0.7258 (0.7258)	LossFusion 0.7258 (0.7258)	
Train Epoch: [124][0/8]	Loss 0.7258 (0.7258)	LossFusion 0.7258 (0.7258)	
Train Epoch: [124][7/8]	Loss 0.3690 (0.5524)	LossFusion 0.3690 (0.5524)	
Train Epoch: [124][7/8]	Loss 0.3690 (0.5524)	LossFusion 0.3690 (0.5524)	
Train Epoch: [124][7/8]	Loss 0.3690 (0.5524)	LossFusion 0.3690 (0.5524)	
Train Epoch: [124][7/8]	Loss 0.3690 (0.5524)	LossFusion 0.3690 (0.5524)	
Train Epoch: [124][7/8]	Loss 0.3690 (0.5524)	LossFusion 0.3690 (0.5524)	
Train Epoch: [124][7/8]	Loss 0.3690 (0.5524)	LossFusion 0.3690 (0.5524)	
Train Epoch: [124][7/8]	Loss 0.3690 (0.5524)	LossFusion 0.3690 (0.5524)	
Train Epoch: [124][7/8]	Loss 0.3690 (0.5524)	LossFusion 0.3690 (0.5524)	
R@10:  55.934131145477295     R@50:  81.60136342048645
Mean Now:  68.76774728298187  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.60136342048645
Mean Now:  68.76774728298187  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.60136342048645
Mean Now:  68.76774728298187  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.60136342048645
Mean Now:  68.76774728298187  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.60136342048645
Mean Now:  68.76774728298187  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.60136342048645
Mean Now:  68.76774728298187  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.60136342048645
Mean Now:  68.76774728298187  Best Mean Before:  69.44918 --------------------
R@10:  55.934131145477295     R@50:  81.60136342048645
Mean Now:  68.76774728298187  Best Mean Before:  69.44918 --------------------
Train Epoch: [125][0/8]	Loss 0.6978 (0.6978)	LossFusion 0.6978 (0.6978)	
Train Epoch: [125][0/8]	Loss 0.6978 (0.6978)	LossFusion 0.6978 (0.6978)	
Train Epoch: [125][0/8]	Loss 0.6978 (0.6978)	LossFusion 0.6978 (0.6978)	
Train Epoch: [125][0/8]	Loss 0.6978 (0.6978)	LossFusion 0.6978 (0.6978)	
Train Epoch: [125][0/8]	Loss 0.6978 (0.6978)	LossFusion 0.6978 (0.6978)	
Train Epoch: [125][0/8]	Loss 0.6978 (0.6978)	LossFusion 0.6978 (0.6978)	
Train Epoch: [125][0/8]	Loss 0.6978 (0.6978)	LossFusion 0.6978 (0.6978)	
Train Epoch: [125][0/8]	Loss 0.6978 (0.6978)	LossFusion 0.6978 (0.6978)	
Train Epoch: [125][7/8]	Loss 0.4029 (0.5499)	LossFusion 0.4029 (0.5499)	
Train Epoch: [125][7/8]	Loss 0.4029 (0.5499)	LossFusion 0.4029 (0.5499)	
Train Epoch: [125][7/8]	Loss 0.4029 (0.5499)	LossFusion 0.4029 (0.5499)	
Train Epoch: [125][7/8]	Loss 0.4029 (0.5499)	LossFusion 0.4029 (0.5499)	
Train Epoch: [125][7/8]	Loss 0.4029 (0.5499)	LossFusion 0.4029 (0.5499)	
Train Epoch: [125][7/8]	Loss 0.4029 (0.5499)	LossFusion 0.4029 (0.5499)	
Train Epoch: [125][7/8]	Loss 0.4029 (0.5499)	LossFusion 0.4029 (0.5499)	
Train Epoch: [125][7/8]	Loss 0.4029 (0.5499)	LossFusion 0.4029 (0.5499)	
R@10:  55.82055449485779     R@50:  81.99886679649353
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.99886679649353
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.99886679649353
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.99886679649353
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.99886679649353
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.99886679649353
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.99886679649353
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.99886679649353
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
Train Epoch: [126][0/8]	Loss 0.7347 (0.7347)	LossFusion 0.7347 (0.7347)	
Train Epoch: [126][0/8]	Loss 0.7347 (0.7347)	LossFusion 0.7347 (0.7347)	
Train Epoch: [126][0/8]	Loss 0.7347 (0.7347)	LossFusion 0.7347 (0.7347)	
Train Epoch: [126][0/8]	Loss 0.7347 (0.7347)	LossFusion 0.7347 (0.7347)	
Train Epoch: [126][0/8]	Loss 0.7347 (0.7347)	LossFusion 0.7347 (0.7347)	
Train Epoch: [126][0/8]	Loss 0.7347 (0.7347)	LossFusion 0.7347 (0.7347)	
Train Epoch: [126][0/8]	Loss 0.7347 (0.7347)	LossFusion 0.7347 (0.7347)	
Train Epoch: [126][0/8]	Loss 0.7347 (0.7347)	LossFusion 0.7347 (0.7347)	
Train Epoch: [126][7/8]	Loss 0.3829 (0.5503)	LossFusion 0.3829 (0.5503)	
Train Epoch: [126][7/8]	Loss 0.3829 (0.5503)	LossFusion 0.3829 (0.5503)	
Train Epoch: [126][7/8]	Loss 0.3829 (0.5503)	LossFusion 0.3829 (0.5503)	
Train Epoch: [126][7/8]	Loss 0.3829 (0.5503)	LossFusion 0.3829 (0.5503)	
Train Epoch: [126][7/8]	Loss 0.3829 (0.5503)	LossFusion 0.3829 (0.5503)	
Train Epoch: [126][7/8]	Loss 0.3829 (0.5503)	LossFusion 0.3829 (0.5503)	
Train Epoch: [126][7/8]	Loss 0.3829 (0.5503)	LossFusion 0.3829 (0.5503)	
Train Epoch: [126][7/8]	Loss 0.3829 (0.5503)	LossFusion 0.3829 (0.5503)	
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.82850480079651
Mean Now:  68.90971064567566  Best Mean Before:  69.44918 --------------------
Train Epoch: [127][0/8]	Loss 0.7359 (0.7359)	LossFusion 0.7359 (0.7359)	
Train Epoch: [127][0/8]	Loss 0.7359 (0.7359)	LossFusion 0.7359 (0.7359)	
Train Epoch: [127][0/8]	Loss 0.7359 (0.7359)	LossFusion 0.7359 (0.7359)	
Train Epoch: [127][0/8]	Loss 0.7359 (0.7359)	LossFusion 0.7359 (0.7359)	
Train Epoch: [127][0/8]	Loss 0.7359 (0.7359)	LossFusion 0.7359 (0.7359)	
Train Epoch: [127][0/8]	Loss 0.7359 (0.7359)	LossFusion 0.7359 (0.7359)	
Train Epoch: [127][0/8]	Loss 0.7359 (0.7359)	LossFusion 0.7359 (0.7359)	
Train Epoch: [127][0/8]	Loss 0.7359 (0.7359)	LossFusion 0.7359 (0.7359)	
Train Epoch: [127][7/8]	Loss 0.4082 (0.5516)	LossFusion 0.4082 (0.5516)	
Train Epoch: [127][7/8]	Loss 0.4082 (0.5516)	LossFusion 0.4082 (0.5516)	
Train Epoch: [127][7/8]	Loss 0.4082 (0.5516)	LossFusion 0.4082 (0.5516)	
Train Epoch: [127][7/8]	Loss 0.4082 (0.5516)	LossFusion 0.4082 (0.5516)	
Train Epoch: [127][7/8]	Loss 0.4082 (0.5516)	LossFusion 0.4082 (0.5516)	
Train Epoch: [127][7/8]	Loss 0.4082 (0.5516)	LossFusion 0.4082 (0.5516)	
Train Epoch: [127][7/8]	Loss 0.4082 (0.5516)	LossFusion 0.4082 (0.5516)	
Train Epoch: [127][7/8]	Loss 0.4082 (0.5516)	LossFusion 0.4082 (0.5516)	
R@10:  56.27484321594238     R@50:  81.88529014587402
Mean Now:  69.0800666809082  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.88529014587402
Mean Now:  69.0800666809082  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.88529014587402
Mean Now:  69.0800666809082  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.88529014587402
Mean Now:  69.0800666809082  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.88529014587402
Mean Now:  69.0800666809082  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.88529014587402
Mean Now:  69.0800666809082  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.88529014587402
Mean Now:  69.0800666809082  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.88529014587402
Mean Now:  69.0800666809082  Best Mean Before:  69.44918 --------------------
Train Epoch: [128][0/8]	Loss 0.6919 (0.6919)	LossFusion 0.6919 (0.6919)	
Train Epoch: [128][0/8]	Loss 0.6919 (0.6919)	LossFusion 0.6919 (0.6919)	
Train Epoch: [128][0/8]	Loss 0.6919 (0.6919)	LossFusion 0.6919 (0.6919)	
Train Epoch: [128][0/8]	Loss 0.6919 (0.6919)	LossFusion 0.6919 (0.6919)	
Train Epoch: [128][0/8]	Loss 0.6919 (0.6919)	LossFusion 0.6919 (0.6919)	
Train Epoch: [128][0/8]	Loss 0.6919 (0.6919)	LossFusion 0.6919 (0.6919)	
Train Epoch: [128][0/8]	Loss 0.6919 (0.6919)	LossFusion 0.6919 (0.6919)	
Train Epoch: [128][0/8]	Loss 0.6919 (0.6919)	LossFusion 0.6919 (0.6919)	
Train Epoch: [128][7/8]	Loss 0.3937 (0.5392)	LossFusion 0.3937 (0.5392)	
Train Epoch: [128][7/8]	Loss 0.3937 (0.5392)	LossFusion 0.3937 (0.5392)	
Train Epoch: [128][7/8]	Loss 0.3937 (0.5392)	LossFusion 0.3937 (0.5392)	
Train Epoch: [128][7/8]	Loss 0.3937 (0.5392)	LossFusion 0.3937 (0.5392)	
Train Epoch: [128][7/8]	Loss 0.3937 (0.5392)	LossFusion 0.3937 (0.5392)	
Train Epoch: [128][7/8]	Loss 0.3937 (0.5392)	LossFusion 0.3937 (0.5392)	
Train Epoch: [128][7/8]	Loss 0.3937 (0.5392)	LossFusion 0.3937 (0.5392)	
Train Epoch: [128][7/8]	Loss 0.3937 (0.5392)	LossFusion 0.3937 (0.5392)	
R@10:  56.10448718070984     R@50:  81.65814876556396
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.65814876556396
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.65814876556396
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.65814876556396
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.65814876556396
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.65814876556396
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.65814876556396
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.65814876556396
Mean Now:  68.8813179731369  Best Mean Before:  69.44918 --------------------
Train Epoch: [129][0/8]	Loss 0.6952 (0.6952)	LossFusion 0.6952 (0.6952)	
Train Epoch: [129][0/8]	Loss 0.6952 (0.6952)	LossFusion 0.6952 (0.6952)	
Train Epoch: [129][0/8]	Loss 0.6952 (0.6952)	LossFusion 0.6952 (0.6952)	
Train Epoch: [129][0/8]	Loss 0.6952 (0.6952)	LossFusion 0.6952 (0.6952)	
Train Epoch: [129][0/8]	Loss 0.6952 (0.6952)	LossFusion 0.6952 (0.6952)	
Train Epoch: [129][0/8]	Loss 0.6952 (0.6952)	LossFusion 0.6952 (0.6952)	
Train Epoch: [129][0/8]	Loss 0.6952 (0.6952)	LossFusion 0.6952 (0.6952)	
Train Epoch: [129][0/8]	Loss 0.6952 (0.6952)	LossFusion 0.6952 (0.6952)	
Train Epoch: [129][7/8]	Loss 0.3923 (0.5355)	LossFusion 0.3923 (0.5355)	
Train Epoch: [129][7/8]	Loss 0.3923 (0.5355)	LossFusion 0.3923 (0.5355)	
Train Epoch: [129][7/8]	Loss 0.3923 (0.5355)	LossFusion 0.3923 (0.5355)	
Train Epoch: [129][7/8]	Loss 0.3923 (0.5355)	LossFusion 0.3923 (0.5355)	
Train Epoch: [129][7/8]	Loss 0.3923 (0.5355)	LossFusion 0.3923 (0.5355)	
Train Epoch: [129][7/8]	Loss 0.3923 (0.5355)	LossFusion 0.3923 (0.5355)	
Train Epoch: [129][7/8]	Loss 0.3923 (0.5355)	LossFusion 0.3923 (0.5355)	
Train Epoch: [129][7/8]	Loss 0.3923 (0.5355)	LossFusion 0.3923 (0.5355)	
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.82850480079651
Mean Now:  68.76774430274963  Best Mean Before:  69.44918 --------------------
Train Epoch: [130][0/8]	Loss 0.7035 (0.7035)	LossFusion 0.7035 (0.7035)	
Train Epoch: [130][0/8]	Loss 0.7035 (0.7035)	LossFusion 0.7035 (0.7035)	
Train Epoch: [130][0/8]	Loss 0.7035 (0.7035)	LossFusion 0.7035 (0.7035)	
Train Epoch: [130][0/8]	Loss 0.7035 (0.7035)	LossFusion 0.7035 (0.7035)	
Train Epoch: [130][0/8]	Loss 0.7035 (0.7035)	LossFusion 0.7035 (0.7035)	
Train Epoch: [130][0/8]	Loss 0.7035 (0.7035)	LossFusion 0.7035 (0.7035)	
Train Epoch: [130][0/8]	Loss 0.7035 (0.7035)	LossFusion 0.7035 (0.7035)	
Train Epoch: [130][0/8]	Loss 0.7035 (0.7035)	LossFusion 0.7035 (0.7035)	
Train Epoch: [130][7/8]	Loss 0.3808 (0.5465)	LossFusion 0.3808 (0.5465)	
Train Epoch: [130][7/8]	Loss 0.3808 (0.5465)	LossFusion 0.3808 (0.5465)	
Train Epoch: [130][7/8]	Loss 0.3808 (0.5465)	LossFusion 0.3808 (0.5465)	
Train Epoch: [130][7/8]	Loss 0.3808 (0.5465)	LossFusion 0.3808 (0.5465)	
Train Epoch: [130][7/8]	Loss 0.3808 (0.5465)	LossFusion 0.3808 (0.5465)	
Train Epoch: [130][7/8]	Loss 0.3808 (0.5465)	LossFusion 0.3808 (0.5465)	
Train Epoch: [130][7/8]	Loss 0.3808 (0.5465)	LossFusion 0.3808 (0.5465)	
Train Epoch: [130][7/8]	Loss 0.3808 (0.5465)	LossFusion 0.3808 (0.5465)	
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
R@10:  55.82055449485779     R@50:  81.65814876556396
Mean Now:  68.73935163021088  Best Mean Before:  69.44918 --------------------
Train Epoch: [131][0/8]	Loss 0.7481 (0.7481)	LossFusion 0.7481 (0.7481)	
Train Epoch: [131][0/8]	Loss 0.7481 (0.7481)	LossFusion 0.7481 (0.7481)	
Train Epoch: [131][0/8]	Loss 0.7481 (0.7481)	LossFusion 0.7481 (0.7481)	
Train Epoch: [131][0/8]	Loss 0.7481 (0.7481)	LossFusion 0.7481 (0.7481)	
Train Epoch: [131][0/8]	Loss 0.7481 (0.7481)	LossFusion 0.7481 (0.7481)	
Train Epoch: [131][0/8]	Loss 0.7481 (0.7481)	LossFusion 0.7481 (0.7481)	
Train Epoch: [131][0/8]	Loss 0.7481 (0.7481)	LossFusion 0.7481 (0.7481)	
Train Epoch: [131][0/8]	Loss 0.7481 (0.7481)	LossFusion 0.7481 (0.7481)	
Train Epoch: [131][7/8]	Loss 0.4056 (0.5446)	LossFusion 0.4056 (0.5446)	
Train Epoch: [131][7/8]	Loss 0.4056 (0.5446)	LossFusion 0.4056 (0.5446)	
Train Epoch: [131][7/8]	Loss 0.4056 (0.5446)	LossFusion 0.4056 (0.5446)	
Train Epoch: [131][7/8]	Loss 0.4056 (0.5446)	LossFusion 0.4056 (0.5446)	
Train Epoch: [131][7/8]	Loss 0.4056 (0.5446)	LossFusion 0.4056 (0.5446)	
Train Epoch: [131][7/8]	Loss 0.4056 (0.5446)	LossFusion 0.4056 (0.5446)	
Train Epoch: [131][7/8]	Loss 0.4056 (0.5446)	LossFusion 0.4056 (0.5446)	
Train Epoch: [131][7/8]	Loss 0.4056 (0.5446)	LossFusion 0.4056 (0.5446)	
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.65814876556396
Mean Now:  68.62578094005585  Best Mean Before:  69.44918 --------------------
Train Epoch: [132][0/8]	Loss 0.6934 (0.6934)	LossFusion 0.6934 (0.6934)	
Train Epoch: [132][0/8]	Loss 0.6934 (0.6934)	LossFusion 0.6934 (0.6934)	
Train Epoch: [132][0/8]	Loss 0.6934 (0.6934)	LossFusion 0.6934 (0.6934)	
Train Epoch: [132][0/8]	Loss 0.6934 (0.6934)	LossFusion 0.6934 (0.6934)	
Train Epoch: [132][0/8]	Loss 0.6934 (0.6934)	LossFusion 0.6934 (0.6934)	
Train Epoch: [132][0/8]	Loss 0.6934 (0.6934)	LossFusion 0.6934 (0.6934)	
Train Epoch: [132][0/8]	Loss 0.6934 (0.6934)	LossFusion 0.6934 (0.6934)	
Train Epoch: [132][0/8]	Loss 0.6934 (0.6934)	LossFusion 0.6934 (0.6934)	
Train Epoch: [132][7/8]	Loss 0.3915 (0.5346)	LossFusion 0.3915 (0.5346)	
Train Epoch: [132][7/8]	Loss 0.3915 (0.5346)	LossFusion 0.3915 (0.5346)	
Train Epoch: [132][7/8]	Loss 0.3915 (0.5346)	LossFusion 0.3915 (0.5346)	
Train Epoch: [132][7/8]	Loss 0.3915 (0.5346)	LossFusion 0.3915 (0.5346)	
Train Epoch: [132][7/8]	Loss 0.3915 (0.5346)	LossFusion 0.3915 (0.5346)	
Train Epoch: [132][7/8]	Loss 0.3915 (0.5346)	LossFusion 0.3915 (0.5346)	Train Epoch: [132][7/8]	Loss 0.3915 (0.5346)	LossFusion 0.3915 (0.5346)	

Train Epoch: [132][7/8]	Loss 0.3915 (0.5346)	LossFusion 0.3915 (0.5346)	
R@10:  56.27484321594238     R@50:  81.771719455719
Mean Now:  69.02328133583069  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.771719455719
Mean Now:  69.02328133583069  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.771719455719
Mean Now:  69.02328133583069  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.771719455719
Mean Now:  69.02328133583069  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.771719455719
Mean Now:  69.02328133583069  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.771719455719
Mean Now:  69.02328133583069  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.771719455719
Mean Now:  69.02328133583069  Best Mean Before:  69.44918 --------------------
R@10:  56.27484321594238     R@50:  81.771719455719
Mean Now:  69.02328133583069  Best Mean Before:  69.44918 --------------------
Train Epoch: [133][0/8]	Loss 0.7175 (0.7175)	LossFusion 0.7175 (0.7175)	
Train Epoch: [133][0/8]	Loss 0.7175 (0.7175)	LossFusion 0.7175 (0.7175)	
Train Epoch: [133][0/8]	Loss 0.7175 (0.7175)	LossFusion 0.7175 (0.7175)	
Train Epoch: [133][0/8]	Loss 0.7175 (0.7175)	LossFusion 0.7175 (0.7175)	
Train Epoch: [133][0/8]	Loss 0.7175 (0.7175)	LossFusion 0.7175 (0.7175)	
Train Epoch: [133][0/8]	Loss 0.7175 (0.7175)	LossFusion 0.7175 (0.7175)	
Train Epoch: [133][0/8]	Loss 0.7175 (0.7175)	LossFusion 0.7175 (0.7175)	
Train Epoch: [133][0/8]	Loss 0.7175 (0.7175)	LossFusion 0.7175 (0.7175)	
Train Epoch: [133][7/8]	Loss 0.3792 (0.5458)	LossFusion 0.3792 (0.5458)	
Train Epoch: [133][7/8]	Loss 0.3792 (0.5458)	LossFusion 0.3792 (0.5458)	
Train Epoch: [133][7/8]	Loss 0.3792 (0.5458)	LossFusion 0.3792 (0.5458)	
Train Epoch: [133][7/8]	Loss 0.3792 (0.5458)	LossFusion 0.3792 (0.5458)	
Train Epoch: [133][7/8]	Loss 0.3792 (0.5458)	LossFusion 0.3792 (0.5458)	
Train Epoch: [133][7/8]	Loss 0.3792 (0.5458)	LossFusion 0.3792 (0.5458)	
Train Epoch: [133][7/8]	Loss 0.3792 (0.5458)	LossFusion 0.3792 (0.5458)	
Train Epoch: [133][7/8]	Loss 0.3792 (0.5458)	LossFusion 0.3792 (0.5458)	
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.37422204017639
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
Train Epoch: [134][0/8]	Loss 0.7384 (0.7384)	LossFusion 0.7384 (0.7384)	
Train Epoch: [134][0/8]	Loss 0.7384 (0.7384)	LossFusion 0.7384 (0.7384)	
Train Epoch: [134][0/8]	Loss 0.7384 (0.7384)	LossFusion 0.7384 (0.7384)	
Train Epoch: [134][0/8]	Loss 0.7384 (0.7384)	LossFusion 0.7384 (0.7384)	
Train Epoch: [134][0/8]	Loss 0.7384 (0.7384)	LossFusion 0.7384 (0.7384)	
Train Epoch: [134][0/8]	Loss 0.7384 (0.7384)	LossFusion 0.7384 (0.7384)	
Train Epoch: [134][0/8]	Loss 0.7384 (0.7384)	LossFusion 0.7384 (0.7384)	
Train Epoch: [134][0/8]	Loss 0.7384 (0.7384)	LossFusion 0.7384 (0.7384)	
Train Epoch: [134][7/8]	Loss 0.4039 (0.5367)	LossFusion 0.4039 (0.5367)	
Train Epoch: [134][7/8]	Loss 0.4039 (0.5367)	LossFusion 0.4039 (0.5367)	
Train Epoch: [134][7/8]	Loss 0.4039 (0.5367)	LossFusion 0.4039 (0.5367)	
Train Epoch: [134][7/8]	Loss 0.4039 (0.5367)	LossFusion 0.4039 (0.5367)	
Train Epoch: [134][7/8]	Loss 0.4039 (0.5367)	LossFusion 0.4039 (0.5367)	
Train Epoch: [134][7/8]	Loss 0.4039 (0.5367)	LossFusion 0.4039 (0.5367)	
Train Epoch: [134][7/8]	Loss 0.4039 (0.5367)	LossFusion 0.4039 (0.5367)	
Train Epoch: [134][7/8]	Loss 0.4039 (0.5367)	LossFusion 0.4039 (0.5367)	
R@10:  56.10448718070984     R@50:  81.60136342048645
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.60136342048645
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.60136342048645
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.60136342048645
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.60136342048645
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.60136342048645
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.60136342048645
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
R@10:  56.10448718070984     R@50:  81.60136342048645
Mean Now:  68.85292530059814  Best Mean Before:  69.44918 --------------------
Train Epoch: [135][0/8]	Loss 0.6589 (0.6589)	LossFusion 0.6589 (0.6589)	
Train Epoch: [135][0/8]	Loss 0.6589 (0.6589)	LossFusion 0.6589 (0.6589)	
Train Epoch: [135][0/8]	Loss 0.6589 (0.6589)	LossFusion 0.6589 (0.6589)	
Train Epoch: [135][0/8]	Loss 0.6589 (0.6589)	LossFusion 0.6589 (0.6589)	
Train Epoch: [135][0/8]	Loss 0.6589 (0.6589)	LossFusion 0.6589 (0.6589)	
Train Epoch: [135][0/8]	Loss 0.6589 (0.6589)	LossFusion 0.6589 (0.6589)	
Train Epoch: [135][0/8]	Loss 0.6589 (0.6589)	LossFusion 0.6589 (0.6589)	
Train Epoch: [135][0/8]	Loss 0.6589 (0.6589)	LossFusion 0.6589 (0.6589)	
Train Epoch: [135][7/8]	Loss 0.4025 (0.5266)	LossFusion 0.4025 (0.5266)	
Train Epoch: [135][7/8]	Loss 0.4025 (0.5266)	LossFusion 0.4025 (0.5266)	
Train Epoch: [135][7/8]	Loss 0.4025 (0.5266)	LossFusion 0.4025 (0.5266)	
Train Epoch: [135][7/8]	Loss 0.4025 (0.5266)	LossFusion 0.4025 (0.5266)	
Train Epoch: [135][7/8]	Loss 0.4025 (0.5266)	LossFusion 0.4025 (0.5266)	
Train Epoch: [135][7/8]	Loss 0.4025 (0.5266)	LossFusion 0.4025 (0.5266)	
Train Epoch: [135][7/8]	Loss 0.4025 (0.5266)	LossFusion 0.4025 (0.5266)	
Train Epoch: [135][7/8]	Loss 0.4025 (0.5266)	LossFusion 0.4025 (0.5266)	
R@10:  55.536627769470215     R@50:  81.54457807540894
Mean Now:  68.54060292243958  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.54457807540894
Mean Now:  68.54060292243958  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.54457807540894
Mean Now:  68.54060292243958  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.54457807540894
Mean Now:  68.54060292243958  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.54457807540894
Mean Now:  68.54060292243958  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.54457807540894
Mean Now:  68.54060292243958  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.54457807540894
Mean Now:  68.54060292243958  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.54457807540894
Mean Now:  68.54060292243958  Best Mean Before:  69.44918 --------------------
Train Epoch: [136][0/8]	Loss 0.6962 (0.6962)	LossFusion 0.6962 (0.6962)	
Train Epoch: [136][0/8]	Loss 0.6962 (0.6962)	LossFusion 0.6962 (0.6962)	
Train Epoch: [136][0/8]	Loss 0.6962 (0.6962)	LossFusion 0.6962 (0.6962)	
Train Epoch: [136][0/8]	Loss 0.6962 (0.6962)	LossFusion 0.6962 (0.6962)	
Train Epoch: [136][0/8]	Loss 0.6962 (0.6962)	LossFusion 0.6962 (0.6962)	
Train Epoch: [136][0/8]	Loss 0.6962 (0.6962)	LossFusion 0.6962 (0.6962)	
Train Epoch: [136][0/8]	Loss 0.6962 (0.6962)	LossFusion 0.6962 (0.6962)	
Train Epoch: [136][0/8]	Loss 0.6962 (0.6962)	LossFusion 0.6962 (0.6962)	
Train Epoch: [136][7/8]	Loss 0.3714 (0.5151)	LossFusion 0.3714 (0.5151)	
Train Epoch: [136][7/8]	Loss 0.3714 (0.5151)	LossFusion 0.3714 (0.5151)	
Train Epoch: [136][7/8]	Loss 0.3714 (0.5151)	LossFusion 0.3714 (0.5151)	
Train Epoch: [136][7/8]	Loss 0.3714 (0.5151)	LossFusion 0.3714 (0.5151)	
Train Epoch: [136][7/8]	Loss 0.3714 (0.5151)	LossFusion 0.3714 (0.5151)	
Train Epoch: [136][7/8]	Loss 0.3714 (0.5151)	LossFusion 0.3714 (0.5151)	
Train Epoch: [136][7/8]	Loss 0.3714 (0.5151)	LossFusion 0.3714 (0.5151)	
Train Epoch: [136][7/8]	Loss 0.3714 (0.5151)	LossFusion 0.3714 (0.5151)	
R@10:  55.59341311454773     R@50:  81.54457807540894
Mean Now:  68.56899559497833  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.54457807540894
Mean Now:  68.56899559497833  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.54457807540894
Mean Now:  68.56899559497833  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.54457807540894
Mean Now:  68.56899559497833  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.54457807540894
Mean Now:  68.56899559497833  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.54457807540894
Mean Now:  68.56899559497833  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.54457807540894
Mean Now:  68.56899559497833  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.54457807540894
Mean Now:  68.56899559497833  Best Mean Before:  69.44918 --------------------
Train Epoch: [137][0/8]	Loss 0.7254 (0.7254)	LossFusion 0.7254 (0.7254)	
Train Epoch: [137][0/8]	Loss 0.7254 (0.7254)	LossFusion 0.7254 (0.7254)	
Train Epoch: [137][0/8]	Loss 0.7254 (0.7254)	LossFusion 0.7254 (0.7254)	
Train Epoch: [137][0/8]	Loss 0.7254 (0.7254)	LossFusion 0.7254 (0.7254)	
Train Epoch: [137][0/8]	Loss 0.7254 (0.7254)	LossFusion 0.7254 (0.7254)	
Train Epoch: [137][0/8]	Loss 0.7254 (0.7254)	LossFusion 0.7254 (0.7254)	
Train Epoch: [137][0/8]	Loss 0.7254 (0.7254)	LossFusion 0.7254 (0.7254)	
Train Epoch: [137][0/8]	Loss 0.7254 (0.7254)	LossFusion 0.7254 (0.7254)	
Train Epoch: [137][7/8]	Loss 0.3663 (0.5342)	LossFusion 0.3663 (0.5342)	
Train Epoch: [137][7/8]	Loss 0.3663 (0.5342)	LossFusion 0.3663 (0.5342)	
Train Epoch: [137][7/8]	Loss 0.3663 (0.5342)	LossFusion 0.3663 (0.5342)	
Train Epoch: [137][7/8]	Loss 0.3663 (0.5342)	LossFusion 0.3663 (0.5342)	
Train Epoch: [137][7/8]	Loss 0.3663 (0.5342)	LossFusion 0.3663 (0.5342)	
Train Epoch: [137][7/8]	Loss 0.3663 (0.5342)	LossFusion 0.3663 (0.5342)	
Train Epoch: [137][7/8]	Loss 0.3663 (0.5342)	LossFusion 0.3663 (0.5342)	
Train Epoch: [137][7/8]	Loss 0.3663 (0.5342)	LossFusion 0.3663 (0.5342)	
R@10:  55.139124393463135     R@50:  81.65814876556396
Mean Now:  68.39863657951355  Best Mean Before:  69.44918 --------------------
R@10:  55.139124393463135     R@50:  81.65814876556396
Mean Now:  68.39863657951355  Best Mean Before:  69.44918 --------------------
R@10:  55.139124393463135     R@50:  81.65814876556396
Mean Now:  68.39863657951355  Best Mean Before:  69.44918 --------------------
R@10:  55.139124393463135     R@50:  81.65814876556396
Mean Now:  68.39863657951355  Best Mean Before:  69.44918 --------------------
R@10:  55.139124393463135     R@50:  81.65814876556396
Mean Now:  68.39863657951355  Best Mean Before:  69.44918 --------------------
R@10:  55.139124393463135     R@50:  81.65814876556396
Mean Now:  68.39863657951355  Best Mean Before:  69.44918 --------------------
R@10:  55.139124393463135     R@50:  81.65814876556396
Mean Now:  68.39863657951355  Best Mean Before:  69.44918 --------------------
R@10:  55.139124393463135     R@50:  81.65814876556396
Mean Now:  68.39863657951355  Best Mean Before:  69.44918 --------------------
Train Epoch: [138][0/8]	Loss 0.6914 (0.6914)	LossFusion 0.6914 (0.6914)	
Train Epoch: [138][0/8]	Loss 0.6914 (0.6914)	LossFusion 0.6914 (0.6914)	
Train Epoch: [138][0/8]	Loss 0.6914 (0.6914)	LossFusion 0.6914 (0.6914)	
Train Epoch: [138][0/8]	Loss 0.6914 (0.6914)	LossFusion 0.6914 (0.6914)	
Train Epoch: [138][0/8]	Loss 0.6914 (0.6914)	LossFusion 0.6914 (0.6914)	
Train Epoch: [138][0/8]	Loss 0.6914 (0.6914)	LossFusion 0.6914 (0.6914)	
Train Epoch: [138][0/8]	Loss 0.6914 (0.6914)	LossFusion 0.6914 (0.6914)	
Train Epoch: [138][0/8]	Loss 0.6914 (0.6914)	LossFusion 0.6914 (0.6914)	
Train Epoch: [138][7/8]	Loss 0.3480 (0.5071)	LossFusion 0.3480 (0.5071)	
Train Epoch: [138][7/8]	Loss 0.3480 (0.5071)	LossFusion 0.3480 (0.5071)	
Train Epoch: [138][7/8]	Loss 0.3480 (0.5071)	LossFusion 0.3480 (0.5071)	
Train Epoch: [138][7/8]	Loss 0.3480 (0.5071)	LossFusion 0.3480 (0.5071)	
Train Epoch: [138][7/8]	Loss 0.3480 (0.5071)	LossFusion 0.3480 (0.5071)	
Train Epoch: [138][7/8]	Loss 0.3480 (0.5071)	LossFusion 0.3480 (0.5071)	
Train Epoch: [138][7/8]	Loss 0.3480 (0.5071)	LossFusion 0.3480 (0.5071)	
Train Epoch: [138][7/8]	Loss 0.3480 (0.5071)	LossFusion 0.3480 (0.5071)	
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.44918 --------------------
R@10:  55.99091649055481     R@50:  81.94207549095154
Mean Now:  68.96649599075317  Best Mean Before:  69.44918 --------------------
Train Epoch: [139][0/8]	Loss 0.6969 (0.6969)	LossFusion 0.6969 (0.6969)	
Train Epoch: [139][0/8]	Loss 0.6969 (0.6969)	LossFusion 0.6969 (0.6969)	
Train Epoch: [139][0/8]	Loss 0.6969 (0.6969)	LossFusion 0.6969 (0.6969)	Train Epoch: [139][0/8]	Loss 0.6969 (0.6969)	LossFusion 0.6969 (0.6969)	

Train Epoch: [139][0/8]	Loss 0.6969 (0.6969)	LossFusion 0.6969 (0.6969)	
Train Epoch: [139][0/8]	Loss 0.6969 (0.6969)	LossFusion 0.6969 (0.6969)	
Train Epoch: [139][0/8]	Loss 0.6969 (0.6969)	LossFusion 0.6969 (0.6969)	
Train Epoch: [139][0/8]	Loss 0.6969 (0.6969)	LossFusion 0.6969 (0.6969)	
Train Epoch: [139][7/8]	Loss 0.4065 (0.5219)	LossFusion 0.4065 (0.5219)	
Train Epoch: [139][7/8]	Loss 0.4065 (0.5219)	LossFusion 0.4065 (0.5219)	
Train Epoch: [139][7/8]	Loss 0.4065 (0.5219)	LossFusion 0.4065 (0.5219)	
Train Epoch: [139][7/8]	Loss 0.4065 (0.5219)	LossFusion 0.4065 (0.5219)	
Train Epoch: [139][7/8]	Loss 0.4065 (0.5219)	LossFusion 0.4065 (0.5219)	
Train Epoch: [139][7/8]	Loss 0.4065 (0.5219)	LossFusion 0.4065 (0.5219)	
Train Epoch: [139][7/8]	Loss 0.4065 (0.5219)	LossFusion 0.4065 (0.5219)	
Train Epoch: [139][7/8]	Loss 0.4065 (0.5219)	LossFusion 0.4065 (0.5219)	
R@10:  55.423057079315186     R@50:  81.54457807540894
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  81.54457807540894
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  81.54457807540894
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  81.54457807540894
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  81.54457807540894
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  81.54457807540894
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  81.54457807540894
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  81.54457807540894
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
Train Epoch: [140][0/8]	Loss 0.6960 (0.6960)	LossFusion 0.6960 (0.6960)	
Train Epoch: [140][0/8]	Loss 0.6960 (0.6960)	LossFusion 0.6960 (0.6960)	
Train Epoch: [140][0/8]	Loss 0.6960 (0.6960)	LossFusion 0.6960 (0.6960)	
Train Epoch: [140][0/8]	Loss 0.6960 (0.6960)	LossFusion 0.6960 (0.6960)	
Train Epoch: [140][0/8]	Loss 0.6960 (0.6960)	LossFusion 0.6960 (0.6960)	
Train Epoch: [140][0/8]	Loss 0.6960 (0.6960)	LossFusion 0.6960 (0.6960)	
Train Epoch: [140][0/8]	Loss 0.6960 (0.6960)	LossFusion 0.6960 (0.6960)	
Train Epoch: [140][0/8]	Loss 0.6960 (0.6960)	LossFusion 0.6960 (0.6960)	
Train Epoch: [140][7/8]	Loss 0.3541 (0.5047)	LossFusion 0.3541 (0.5047)	
Train Epoch: [140][7/8]	Loss 0.3541 (0.5047)	LossFusion 0.3541 (0.5047)	
Train Epoch: [140][7/8]	Loss 0.3541 (0.5047)	LossFusion 0.3541 (0.5047)	
Train Epoch: [140][7/8]	Loss 0.3541 (0.5047)	LossFusion 0.3541 (0.5047)	
Train Epoch: [140][7/8]	Loss 0.3541 (0.5047)	LossFusion 0.3541 (0.5047)	
Train Epoch: [140][7/8]	Loss 0.3541 (0.5047)	LossFusion 0.3541 (0.5047)	
Train Epoch: [140][7/8]	Loss 0.3541 (0.5047)	LossFusion 0.3541 (0.5047)	
Train Epoch: [140][7/8]	Loss 0.3541 (0.5047)	LossFusion 0.3541 (0.5047)	
R@10:  55.536627769470215     R@50:  81.37422204017639
Mean Now:  68.4554249048233  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.37422204017639
Mean Now:  68.4554249048233  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.37422204017639
Mean Now:  68.4554249048233  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.37422204017639
Mean Now:  68.4554249048233  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.37422204017639
Mean Now:  68.4554249048233  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.37422204017639
Mean Now:  68.4554249048233  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.37422204017639
Mean Now:  68.4554249048233  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.37422204017639
Mean Now:  68.4554249048233  Best Mean Before:  69.44918 --------------------
Train Epoch: [141][0/8]	Loss 0.7004 (0.7004)	LossFusion 0.7004 (0.7004)	
Train Epoch: [141][0/8]	Loss 0.7004 (0.7004)	LossFusion 0.7004 (0.7004)	
Train Epoch: [141][0/8]	Loss 0.7004 (0.7004)	LossFusion 0.7004 (0.7004)	
Train Epoch: [141][0/8]	Loss 0.7004 (0.7004)	LossFusion 0.7004 (0.7004)	
Train Epoch: [141][0/8]	Loss 0.7004 (0.7004)	LossFusion 0.7004 (0.7004)	
Train Epoch: [141][0/8]	Loss 0.7004 (0.7004)	LossFusion 0.7004 (0.7004)	
Train Epoch: [141][0/8]	Loss 0.7004 (0.7004)	LossFusion 0.7004 (0.7004)	
Train Epoch: [141][0/8]	Loss 0.7004 (0.7004)	LossFusion 0.7004 (0.7004)	
Train Epoch: [141][7/8]	Loss 0.3468 (0.5095)	LossFusion 0.3468 (0.5095)	
Train Epoch: [141][7/8]	Loss 0.3468 (0.5095)	LossFusion 0.3468 (0.5095)	
Train Epoch: [141][7/8]	Loss 0.3468 (0.5095)	LossFusion 0.3468 (0.5095)	
Train Epoch: [141][7/8]	Loss 0.3468 (0.5095)	LossFusion 0.3468 (0.5095)	
Train Epoch: [141][7/8]	Loss 0.3468 (0.5095)	LossFusion 0.3468 (0.5095)	
Train Epoch: [141][7/8]	Loss 0.3468 (0.5095)	LossFusion 0.3468 (0.5095)	
Train Epoch: [141][7/8]	Loss 0.3468 (0.5095)	LossFusion 0.3468 (0.5095)	
Train Epoch: [141][7/8]	Loss 0.3468 (0.5095)	LossFusion 0.3468 (0.5095)	
R@10:  55.650198459625244     R@50:  81.3174307346344
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.3174307346344
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.3174307346344
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.3174307346344
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.3174307346344
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.3174307346344
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.3174307346344
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.650198459625244     R@50:  81.3174307346344
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
Train Epoch: [142][0/8]	Loss 0.6290 (0.6290)	LossFusion 0.6290 (0.6290)	
Train Epoch: [142][0/8]	Loss 0.6290 (0.6290)	LossFusion 0.6290 (0.6290)	Train Epoch: [142][0/8]	Loss 0.6290 (0.6290)	LossFusion 0.6290 (0.6290)	

Train Epoch: [142][0/8]	Loss 0.6290 (0.6290)	LossFusion 0.6290 (0.6290)	
Train Epoch: [142][0/8]	Loss 0.6290 (0.6290)	LossFusion 0.6290 (0.6290)	
Train Epoch: [142][0/8]	Loss 0.6290 (0.6290)	LossFusion 0.6290 (0.6290)	
Train Epoch: [142][0/8]	Loss 0.6290 (0.6290)	LossFusion 0.6290 (0.6290)	
Train Epoch: [142][0/8]	Loss 0.6290 (0.6290)	LossFusion 0.6290 (0.6290)	
Train Epoch: [142][7/8]	Loss 0.3391 (0.5009)	LossFusion 0.3391 (0.5009)	
Train Epoch: [142][7/8]	Loss 0.3391 (0.5009)	LossFusion 0.3391 (0.5009)	
Train Epoch: [142][7/8]	Loss 0.3391 (0.5009)	LossFusion 0.3391 (0.5009)	
Train Epoch: [142][7/8]	Loss 0.3391 (0.5009)	LossFusion 0.3391 (0.5009)	
Train Epoch: [142][7/8]	Loss 0.3391 (0.5009)	LossFusion 0.3391 (0.5009)	
Train Epoch: [142][7/8]	Loss 0.3391 (0.5009)	LossFusion 0.3391 (0.5009)	
Train Epoch: [142][7/8]	Loss 0.3391 (0.5009)	LossFusion 0.3391 (0.5009)	
Train Epoch: [142][7/8]	Loss 0.3391 (0.5009)	LossFusion 0.3391 (0.5009)	
R@10:  55.70698380470276     R@50:  81.26064538955688
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.26064538955688
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.26064538955688
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.26064538955688
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.26064538955688
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.26064538955688
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.26064538955688
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
R@10:  55.70698380470276     R@50:  81.26064538955688
Mean Now:  68.48381459712982  Best Mean Before:  69.44918 --------------------
Train Epoch: [143][0/8]	Loss 0.6937 (0.6937)	LossFusion 0.6937 (0.6937)	
Train Epoch: [143][0/8]	Loss 0.6937 (0.6937)	LossFusion 0.6937 (0.6937)	
Train Epoch: [143][0/8]	Loss 0.6937 (0.6937)	LossFusion 0.6937 (0.6937)	
Train Epoch: [143][0/8]	Loss 0.6937 (0.6937)	LossFusion 0.6937 (0.6937)	
Train Epoch: [143][0/8]	Loss 0.6937 (0.6937)	LossFusion 0.6937 (0.6937)	
Train Epoch: [143][0/8]	Loss 0.6937 (0.6937)	LossFusion 0.6937 (0.6937)	
Train Epoch: [143][0/8]	Loss 0.6937 (0.6937)	LossFusion 0.6937 (0.6937)	
Train Epoch: [143][0/8]	Loss 0.6937 (0.6937)	LossFusion 0.6937 (0.6937)	
Train Epoch: [143][7/8]	Loss 0.3548 (0.5005)	LossFusion 0.3548 (0.5005)	
Train Epoch: [143][7/8]	Loss 0.3548 (0.5005)	LossFusion 0.3548 (0.5005)	
Train Epoch: [143][7/8]	Loss 0.3548 (0.5005)	LossFusion 0.3548 (0.5005)	
Train Epoch: [143][7/8]	Loss 0.3548 (0.5005)	LossFusion 0.3548 (0.5005)	
Train Epoch: [143][7/8]	Loss 0.3548 (0.5005)	LossFusion 0.3548 (0.5005)	
Train Epoch: [143][7/8]	Loss 0.3548 (0.5005)	LossFusion 0.3548 (0.5005)	
Train Epoch: [143][7/8]	Loss 0.3548 (0.5005)	LossFusion 0.3548 (0.5005)	
Train Epoch: [143][7/8]	Loss 0.3548 (0.5005)	LossFusion 0.3548 (0.5005)	
R@10:  55.423057079315186     R@50:  82.05565214157104
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  82.05565214157104
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  82.05565214157104
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  82.05565214157104
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  82.05565214157104
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  82.05565214157104
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  82.05565214157104
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
R@10:  55.423057079315186     R@50:  82.05565214157104
Mean Now:  68.73935461044312  Best Mean Before:  69.44918 --------------------
Train Epoch: [144][0/8]	Loss 0.6630 (0.6630)	LossFusion 0.6630 (0.6630)	
Train Epoch: [144][0/8]	Loss 0.6630 (0.6630)	LossFusion 0.6630 (0.6630)	
Train Epoch: [144][0/8]	Loss 0.6630 (0.6630)	LossFusion 0.6630 (0.6630)	
Train Epoch: [144][0/8]	Loss 0.6630 (0.6630)	LossFusion 0.6630 (0.6630)	
Train Epoch: [144][0/8]	Loss 0.6630 (0.6630)	LossFusion 0.6630 (0.6630)	
Train Epoch: [144][0/8]	Loss 0.6630 (0.6630)	LossFusion 0.6630 (0.6630)	
Train Epoch: [144][0/8]	Loss 0.6630 (0.6630)	LossFusion 0.6630 (0.6630)	
Train Epoch: [144][0/8]	Loss 0.6630 (0.6630)	LossFusion 0.6630 (0.6630)	
Train Epoch: [144][7/8]	Loss 0.3546 (0.4932)	LossFusion 0.3546 (0.4932)	
Train Epoch: [144][7/8]	Loss 0.3546 (0.4932)	LossFusion 0.3546 (0.4932)	
Train Epoch: [144][7/8]	Loss 0.3546 (0.4932)	LossFusion 0.3546 (0.4932)	
Train Epoch: [144][7/8]	Loss 0.3546 (0.4932)	LossFusion 0.3546 (0.4932)	
Train Epoch: [144][7/8]	Loss 0.3546 (0.4932)	LossFusion 0.3546 (0.4932)	
Train Epoch: [144][7/8]	Loss 0.3546 (0.4932)	LossFusion 0.3546 (0.4932)	
Train Epoch: [144][7/8]	Loss 0.3546 (0.4932)	LossFusion 0.3546 (0.4932)	
Train Epoch: [144][7/8]	Loss 0.3546 (0.4932)	LossFusion 0.3546 (0.4932)	
R@10:  55.30948042869568     R@50:  81.60136342048645
Mean Now:  68.45542192459106  Best Mean Before:  69.44918 --------------------
R@10:  55.30948042869568     R@50:  81.60136342048645
Mean Now:  68.45542192459106  Best Mean Before:  69.44918 --------------------
R@10:  55.30948042869568     R@50:  81.60136342048645
Mean Now:  68.45542192459106  Best Mean Before:  69.44918 --------------------
R@10:  55.30948042869568     R@50:  81.60136342048645
Mean Now:  68.45542192459106  Best Mean Before:  69.44918 --------------------
R@10:  55.30948042869568     R@50:  81.60136342048645
Mean Now:  68.45542192459106  Best Mean Before:  69.44918 --------------------
R@10:  55.30948042869568     R@50:  81.60136342048645
Mean Now:  68.45542192459106  Best Mean Before:  69.44918 --------------------
R@10:  55.30948042869568     R@50:  81.60136342048645
Mean Now:  68.45542192459106  Best Mean Before:  69.44918 --------------------
R@10:  55.30948042869568     R@50:  81.60136342048645
Mean Now:  68.45542192459106  Best Mean Before:  69.44918 --------------------
Train Epoch: [145][0/8]	Loss 0.6092 (0.6092)	LossFusion 0.6092 (0.6092)	
Train Epoch: [145][0/8]	Loss 0.6092 (0.6092)	LossFusion 0.6092 (0.6092)	
Train Epoch: [145][0/8]	Loss 0.6092 (0.6092)	LossFusion 0.6092 (0.6092)	
Train Epoch: [145][0/8]	Loss 0.6092 (0.6092)	LossFusion 0.6092 (0.6092)	
Train Epoch: [145][0/8]	Loss 0.6092 (0.6092)	LossFusion 0.6092 (0.6092)	
Train Epoch: [145][0/8]	Loss 0.6092 (0.6092)	LossFusion 0.6092 (0.6092)	
Train Epoch: [145][0/8]	Loss 0.6092 (0.6092)	LossFusion 0.6092 (0.6092)	
Train Epoch: [145][0/8]	Loss 0.6092 (0.6092)	LossFusion 0.6092 (0.6092)	
Train Epoch: [145][7/8]	Loss 0.3517 (0.4844)	LossFusion 0.3517 (0.4844)	
Train Epoch: [145][7/8]	Loss 0.3517 (0.4844)	LossFusion 0.3517 (0.4844)	
Train Epoch: [145][7/8]	Loss 0.3517 (0.4844)	LossFusion 0.3517 (0.4844)	
Train Epoch: [145][7/8]	Loss 0.3517 (0.4844)	LossFusion 0.3517 (0.4844)	
Train Epoch: [145][7/8]	Loss 0.3517 (0.4844)	LossFusion 0.3517 (0.4844)	
Train Epoch: [145][7/8]	Loss 0.3517 (0.4844)	LossFusion 0.3517 (0.4844)	
Train Epoch: [145][7/8]	Loss 0.3517 (0.4844)	LossFusion 0.3517 (0.4844)	
Train Epoch: [145][7/8]	Loss 0.3517 (0.4844)	LossFusion 0.3517 (0.4844)	
R@10:  54.911983013153076     R@50:  81.65814876556396
Mean Now:  68.28506588935852  Best Mean Before:  69.44918 --------------------
R@10:  54.911983013153076     R@50:  81.65814876556396
Mean Now:  68.28506588935852  Best Mean Before:  69.44918 --------------------
R@10:  54.911983013153076     R@50:  81.65814876556396
Mean Now:  68.28506588935852  Best Mean Before:  69.44918 --------------------
R@10:  54.911983013153076     R@50:  81.65814876556396
Mean Now:  68.28506588935852  Best Mean Before:  69.44918 --------------------
R@10:  54.911983013153076     R@50:  81.65814876556396
Mean Now:  68.28506588935852  Best Mean Before:  69.44918 --------------------
R@10:  54.911983013153076     R@50:  81.65814876556396
Mean Now:  68.28506588935852  Best Mean Before:  69.44918 --------------------
R@10:  54.911983013153076     R@50:  81.65814876556396
Mean Now:  68.28506588935852  Best Mean Before:  69.44918 --------------------
R@10:  54.911983013153076     R@50:  81.65814876556396
Mean Now:  68.28506588935852  Best Mean Before:  69.44918 --------------------
Train Epoch: [146][0/8]	Loss 0.6693 (0.6693)	LossFusion 0.6693 (0.6693)	
Train Epoch: [146][0/8]	Loss 0.6693 (0.6693)	LossFusion 0.6693 (0.6693)	
Train Epoch: [146][0/8]	Loss 0.6693 (0.6693)	LossFusion 0.6693 (0.6693)	
Train Epoch: [146][0/8]	Loss 0.6693 (0.6693)	LossFusion 0.6693 (0.6693)	
Train Epoch: [146][0/8]	Loss 0.6693 (0.6693)	LossFusion 0.6693 (0.6693)	
Train Epoch: [146][0/8]	Loss 0.6693 (0.6693)	LossFusion 0.6693 (0.6693)	Train Epoch: [146][0/8]	Loss 0.6693 (0.6693)	LossFusion 0.6693 (0.6693)	

Train Epoch: [146][0/8]	Loss 0.6693 (0.6693)	LossFusion 0.6693 (0.6693)	
Train Epoch: [146][7/8]	Loss 0.3423 (0.4875)	LossFusion 0.3423 (0.4875)	
Train Epoch: [146][7/8]	Loss 0.3423 (0.4875)	LossFusion 0.3423 (0.4875)	
Train Epoch: [146][7/8]	Loss 0.3423 (0.4875)	LossFusion 0.3423 (0.4875)	
Train Epoch: [146][7/8]	Loss 0.3423 (0.4875)	LossFusion 0.3423 (0.4875)	
Train Epoch: [146][7/8]	Loss 0.3423 (0.4875)	LossFusion 0.3423 (0.4875)	
Train Epoch: [146][7/8]	Loss 0.3423 (0.4875)	LossFusion 0.3423 (0.4875)	
Train Epoch: [146][7/8]	Loss 0.3423 (0.4875)	LossFusion 0.3423 (0.4875)	
Train Epoch: [146][7/8]	Loss 0.3423 (0.4875)	LossFusion 0.3423 (0.4875)	
R@10:  55.36627173423767     R@50:  81.60136342048645
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.60136342048645
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.60136342048645
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.60136342048645
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.60136342048645
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.60136342048645
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.60136342048645
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.60136342048645
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
Train Epoch: [147][0/8]	Loss 0.6433 (0.6433)	LossFusion 0.6433 (0.6433)	
Train Epoch: [147][0/8]	Loss 0.6433 (0.6433)	LossFusion 0.6433 (0.6433)	
Train Epoch: [147][0/8]	Loss 0.6433 (0.6433)	LossFusion 0.6433 (0.6433)	
Train Epoch: [147][0/8]	Loss 0.6433 (0.6433)	LossFusion 0.6433 (0.6433)	
Train Epoch: [147][0/8]	Loss 0.6433 (0.6433)	LossFusion 0.6433 (0.6433)	
Train Epoch: [147][0/8]	Loss 0.6433 (0.6433)	LossFusion 0.6433 (0.6433)	
Train Epoch: [147][0/8]	Loss 0.6433 (0.6433)	LossFusion 0.6433 (0.6433)	
Train Epoch: [147][0/8]	Loss 0.6433 (0.6433)	LossFusion 0.6433 (0.6433)	
Train Epoch: [147][7/8]	Loss 0.3539 (0.4807)	LossFusion 0.3539 (0.4807)	
Train Epoch: [147][7/8]	Loss 0.3539 (0.4807)	LossFusion 0.3539 (0.4807)	
Train Epoch: [147][7/8]	Loss 0.3539 (0.4807)	LossFusion 0.3539 (0.4807)	
Train Epoch: [147][7/8]	Loss 0.3539 (0.4807)	LossFusion 0.3539 (0.4807)	
Train Epoch: [147][7/8]	Loss 0.3539 (0.4807)	LossFusion 0.3539 (0.4807)	
Train Epoch: [147][7/8]	Loss 0.3539 (0.4807)	LossFusion 0.3539 (0.4807)	
Train Epoch: [147][7/8]	Loss 0.3539 (0.4807)	LossFusion 0.3539 (0.4807)	
Train Epoch: [147][7/8]	Loss 0.3539 (0.4807)	LossFusion 0.3539 (0.4807)	
R@10:  55.4798424243927     R@50:  81.37422204017639
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  81.37422204017639
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  81.37422204017639
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  81.37422204017639
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  81.37422204017639
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  81.37422204017639
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  81.37422204017639
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  81.37422204017639
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
Train Epoch: [148][0/8]	Loss 0.6020 (0.6020)	LossFusion 0.6020 (0.6020)	
Train Epoch: [148][0/8]	Loss 0.6020 (0.6020)	LossFusion 0.6020 (0.6020)	
Train Epoch: [148][0/8]	Loss 0.6020 (0.6020)	LossFusion 0.6020 (0.6020)	
Train Epoch: [148][0/8]	Loss 0.6020 (0.6020)	LossFusion 0.6020 (0.6020)	
Train Epoch: [148][0/8]	Loss 0.6020 (0.6020)	LossFusion 0.6020 (0.6020)	
Train Epoch: [148][0/8]	Loss 0.6020 (0.6020)	LossFusion 0.6020 (0.6020)	
Train Epoch: [148][0/8]	Loss 0.6020 (0.6020)	LossFusion 0.6020 (0.6020)	
Train Epoch: [148][0/8]	Loss 0.6020 (0.6020)	LossFusion 0.6020 (0.6020)	
Train Epoch: [148][7/8]	Loss 0.3824 (0.4859)	LossFusion 0.3824 (0.4859)	
Train Epoch: [148][7/8]	Loss 0.3824 (0.4859)	LossFusion 0.3824 (0.4859)	
Train Epoch: [148][7/8]	Loss 0.3824 (0.4859)	LossFusion 0.3824 (0.4859)	
Train Epoch: [148][7/8]	Loss 0.3824 (0.4859)	LossFusion 0.3824 (0.4859)	
Train Epoch: [148][7/8]	Loss 0.3824 (0.4859)	LossFusion 0.3824 (0.4859)	
Train Epoch: [148][7/8]	Loss 0.3824 (0.4859)	LossFusion 0.3824 (0.4859)	
Train Epoch: [148][7/8]	Loss 0.3824 (0.4859)	LossFusion 0.3824 (0.4859)	
Train Epoch: [148][7/8]	Loss 0.3824 (0.4859)	LossFusion 0.3824 (0.4859)	
R@10:  55.536627769470215     R@50:  81.88529014587402
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.88529014587402
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.88529014587402
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.88529014587402
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.88529014587402
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.88529014587402
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.88529014587402
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
R@10:  55.536627769470215     R@50:  81.88529014587402
Mean Now:  68.71095895767212  Best Mean Before:  69.44918 --------------------
Train Epoch: [149][0/8]	Loss 0.6254 (0.6254)	LossFusion 0.6254 (0.6254)	
Train Epoch: [149][0/8]	Loss 0.6254 (0.6254)	LossFusion 0.6254 (0.6254)	
Train Epoch: [149][0/8]	Loss 0.6254 (0.6254)	LossFusion 0.6254 (0.6254)	
Train Epoch: [149][0/8]	Loss 0.6254 (0.6254)	LossFusion 0.6254 (0.6254)	
Train Epoch: [149][0/8]	Loss 0.6254 (0.6254)	LossFusion 0.6254 (0.6254)	
Train Epoch: [149][0/8]	Loss 0.6254 (0.6254)	LossFusion 0.6254 (0.6254)	
Train Epoch: [149][0/8]	Loss 0.6254 (0.6254)	LossFusion 0.6254 (0.6254)	
Train Epoch: [149][0/8]	Loss 0.6254 (0.6254)	LossFusion 0.6254 (0.6254)	
Train Epoch: [149][7/8]	Loss 0.3447 (0.4765)	LossFusion 0.3447 (0.4765)	
Train Epoch: [149][7/8]	Loss 0.3447 (0.4765)	LossFusion 0.3447 (0.4765)	
Train Epoch: [149][7/8]	Loss 0.3447 (0.4765)	LossFusion 0.3447 (0.4765)	
Train Epoch: [149][7/8]	Loss 0.3447 (0.4765)	LossFusion 0.3447 (0.4765)	
Train Epoch: [149][7/8]	Loss 0.3447 (0.4765)	LossFusion 0.3447 (0.4765)	
Train Epoch: [149][7/8]	Loss 0.3447 (0.4765)	LossFusion 0.3447 (0.4765)	
Train Epoch: [149][7/8]	Loss 0.3447 (0.4765)	LossFusion 0.3447 (0.4765)	
Train Epoch: [149][7/8]	Loss 0.3447 (0.4765)	LossFusion 0.3447 (0.4765)	
R@10:  55.025553703308105     R@50:  80.97671866416931
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  80.97671866416931
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  80.97671866416931
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  80.97671866416931
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  80.97671866416931
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  80.97671866416931
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  80.97671866416931
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  80.97671866416931
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
Train Epoch: [150][0/8]	Loss 0.6401 (0.6401)	LossFusion 0.6401 (0.6401)	
Train Epoch: [150][0/8]	Loss 0.6401 (0.6401)	LossFusion 0.6401 (0.6401)	
Train Epoch: [150][0/8]	Loss 0.6401 (0.6401)	LossFusion 0.6401 (0.6401)	
Train Epoch: [150][0/8]	Loss 0.6401 (0.6401)	LossFusion 0.6401 (0.6401)	
Train Epoch: [150][0/8]	Loss 0.6401 (0.6401)	LossFusion 0.6401 (0.6401)	
Train Epoch: [150][0/8]	Loss 0.6401 (0.6401)	LossFusion 0.6401 (0.6401)	
Train Epoch: [150][0/8]	Loss 0.6401 (0.6401)	LossFusion 0.6401 (0.6401)	
Train Epoch: [150][0/8]	Loss 0.6401 (0.6401)	LossFusion 0.6401 (0.6401)	
Train Epoch: [150][7/8]	Loss 0.3395 (0.4613)	LossFusion 0.3395 (0.4613)	
Train Epoch: [150][7/8]	Loss 0.3395 (0.4613)	LossFusion 0.3395 (0.4613)	
Train Epoch: [150][7/8]	Loss 0.3395 (0.4613)	LossFusion 0.3395 (0.4613)	
Train Epoch: [150][7/8]	Loss 0.3395 (0.4613)	LossFusion 0.3395 (0.4613)	
Train Epoch: [150][7/8]	Loss 0.3395 (0.4613)	LossFusion 0.3395 (0.4613)	
Train Epoch: [150][7/8]	Loss 0.3395 (0.4613)	LossFusion 0.3395 (0.4613)	
Train Epoch: [150][7/8]	Loss 0.3395 (0.4613)	LossFusion 0.3395 (0.4613)	
Train Epoch: [150][7/8]	Loss 0.3395 (0.4613)	LossFusion 0.3395 (0.4613)	
R@10:  55.19590973854065     R@50:  81.14707469940186
Mean Now:  68.17149221897125  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  81.14707469940186
Mean Now:  68.17149221897125  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  81.14707469940186
Mean Now:  68.17149221897125  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  81.14707469940186
Mean Now:  68.17149221897125  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  81.14707469940186
Mean Now:  68.17149221897125  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  81.14707469940186
Mean Now:  68.17149221897125  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  81.14707469940186
Mean Now:  68.17149221897125  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  81.14707469940186
Mean Now:  68.17149221897125  Best Mean Before:  69.44918 --------------------
Train Epoch: [151][0/8]	Loss 0.6391 (0.6391)	LossFusion 0.6391 (0.6391)	
Train Epoch: [151][0/8]	Loss 0.6391 (0.6391)	LossFusion 0.6391 (0.6391)	
Train Epoch: [151][0/8]	Loss 0.6391 (0.6391)	LossFusion 0.6391 (0.6391)	
Train Epoch: [151][0/8]	Loss 0.6391 (0.6391)	LossFusion 0.6391 (0.6391)	
Train Epoch: [151][0/8]	Loss 0.6391 (0.6391)	LossFusion 0.6391 (0.6391)	
Train Epoch: [151][0/8]	Loss 0.6391 (0.6391)	LossFusion 0.6391 (0.6391)	
Train Epoch: [151][0/8]	Loss 0.6391 (0.6391)	LossFusion 0.6391 (0.6391)	
Train Epoch: [151][0/8]	Loss 0.6391 (0.6391)	LossFusion 0.6391 (0.6391)	
Train Epoch: [151][7/8]	Loss 0.3254 (0.4703)	LossFusion 0.3254 (0.4703)	
Train Epoch: [151][7/8]	Loss 0.3254 (0.4703)	LossFusion 0.3254 (0.4703)	
Train Epoch: [151][7/8]	Loss 0.3254 (0.4703)	LossFusion 0.3254 (0.4703)	
Train Epoch: [151][7/8]	Loss 0.3254 (0.4703)	LossFusion 0.3254 (0.4703)	
Train Epoch: [151][7/8]	Loss 0.3254 (0.4703)	LossFusion 0.3254 (0.4703)	
Train Epoch: [151][7/8]	Loss 0.3254 (0.4703)	LossFusion 0.3254 (0.4703)	
Train Epoch: [151][7/8]	Loss 0.3254 (0.4703)	LossFusion 0.3254 (0.4703)	
Train Epoch: [151][7/8]	Loss 0.3254 (0.4703)	LossFusion 0.3254 (0.4703)	
R@10:  54.79841232299805     R@50:  81.3174307346344
Mean Now:  68.05792152881622  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.3174307346344
Mean Now:  68.05792152881622  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.3174307346344
Mean Now:  68.05792152881622  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.3174307346344
Mean Now:  68.05792152881622  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.3174307346344
Mean Now:  68.05792152881622  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.3174307346344
Mean Now:  68.05792152881622  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.3174307346344
Mean Now:  68.05792152881622  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.3174307346344
Mean Now:  68.05792152881622  Best Mean Before:  69.44918 --------------------
Train Epoch: [152][0/8]	Loss 0.6062 (0.6062)	LossFusion 0.6062 (0.6062)	
Train Epoch: [152][0/8]	Loss 0.6062 (0.6062)	LossFusion 0.6062 (0.6062)	
Train Epoch: [152][0/8]	Loss 0.6062 (0.6062)	LossFusion 0.6062 (0.6062)	
Train Epoch: [152][0/8]	Loss 0.6062 (0.6062)	LossFusion 0.6062 (0.6062)	
Train Epoch: [152][0/8]	Loss 0.6062 (0.6062)	LossFusion 0.6062 (0.6062)	
Train Epoch: [152][0/8]	Loss 0.6062 (0.6062)	LossFusion 0.6062 (0.6062)	
Train Epoch: [152][0/8]	Loss 0.6062 (0.6062)	LossFusion 0.6062 (0.6062)	
Train Epoch: [152][0/8]	Loss 0.6062 (0.6062)	LossFusion 0.6062 (0.6062)	
Train Epoch: [152][7/8]	Loss 0.3270 (0.4504)	LossFusion 0.3270 (0.4504)	
Train Epoch: [152][7/8]	Loss 0.3270 (0.4504)	LossFusion 0.3270 (0.4504)	
Train Epoch: [152][7/8]	Loss 0.3270 (0.4504)	LossFusion 0.3270 (0.4504)	
Train Epoch: [152][7/8]	Loss 0.3270 (0.4504)	LossFusion 0.3270 (0.4504)	
Train Epoch: [152][7/8]	Loss 0.3270 (0.4504)	LossFusion 0.3270 (0.4504)	
Train Epoch: [152][7/8]	Loss 0.3270 (0.4504)	LossFusion 0.3270 (0.4504)	
Train Epoch: [152][7/8]	Loss 0.3270 (0.4504)	LossFusion 0.3270 (0.4504)	
Train Epoch: [152][7/8]	Loss 0.3270 (0.4504)	LossFusion 0.3270 (0.4504)	
R@10:  55.252695083618164     R@50:  80.97671866416931
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  80.97671866416931
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  80.97671866416931
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  80.97671866416931
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  80.97671866416931
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  80.97671866416931
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  80.97671866416931
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  80.97671866416931
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
Train Epoch: [153][0/8]	Loss 0.6069 (0.6069)	LossFusion 0.6069 (0.6069)	
Train Epoch: [153][0/8]	Loss 0.6069 (0.6069)	LossFusion 0.6069 (0.6069)	
Train Epoch: [153][0/8]	Loss 0.6069 (0.6069)	LossFusion 0.6069 (0.6069)	
Train Epoch: [153][0/8]	Loss 0.6069 (0.6069)	LossFusion 0.6069 (0.6069)	
Train Epoch: [153][0/8]	Loss 0.6069 (0.6069)	LossFusion 0.6069 (0.6069)	
Train Epoch: [153][0/8]	Loss 0.6069 (0.6069)	LossFusion 0.6069 (0.6069)	
Train Epoch: [153][0/8]	Loss 0.6069 (0.6069)	LossFusion 0.6069 (0.6069)	
Train Epoch: [153][0/8]	Loss 0.6069 (0.6069)	LossFusion 0.6069 (0.6069)	
Train Epoch: [153][7/8]	Loss 0.3300 (0.4447)	LossFusion 0.3300 (0.4447)	
Train Epoch: [153][7/8]	Loss 0.3300 (0.4447)	LossFusion 0.3300 (0.4447)	
Train Epoch: [153][7/8]	Loss 0.3300 (0.4447)	LossFusion 0.3300 (0.4447)	
Train Epoch: [153][7/8]	Loss 0.3300 (0.4447)	LossFusion 0.3300 (0.4447)	
Train Epoch: [153][7/8]	Loss 0.3300 (0.4447)	LossFusion 0.3300 (0.4447)	
Train Epoch: [153][7/8]	Loss 0.3300 (0.4447)	LossFusion 0.3300 (0.4447)	
Train Epoch: [153][7/8]	Loss 0.3300 (0.4447)	LossFusion 0.3300 (0.4447)	
Train Epoch: [153][7/8]	Loss 0.3300 (0.4447)	LossFusion 0.3300 (0.4447)	
R@10:  55.252695083618164     R@50:  81.26064538955688
Mean Now:  68.25667023658752  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.26064538955688
Mean Now:  68.25667023658752  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.26064538955688
Mean Now:  68.25667023658752  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.26064538955688
Mean Now:  68.25667023658752  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.26064538955688
Mean Now:  68.25667023658752  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.26064538955688
Mean Now:  68.25667023658752  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.26064538955688
Mean Now:  68.25667023658752  Best Mean Before:  69.44918 --------------------
R@10:  55.252695083618164     R@50:  81.26064538955688
Mean Now:  68.25667023658752  Best Mean Before:  69.44918 --------------------
Train Epoch: [154][0/8]	Loss 0.6029 (0.6029)	LossFusion 0.6029 (0.6029)	
Train Epoch: [154][0/8]	Loss 0.6029 (0.6029)	LossFusion 0.6029 (0.6029)	
Train Epoch: [154][0/8]	Loss 0.6029 (0.6029)	LossFusion 0.6029 (0.6029)	
Train Epoch: [154][0/8]	Loss 0.6029 (0.6029)	LossFusion 0.6029 (0.6029)	
Train Epoch: [154][0/8]	Loss 0.6029 (0.6029)	LossFusion 0.6029 (0.6029)	
Train Epoch: [154][0/8]	Loss 0.6029 (0.6029)	LossFusion 0.6029 (0.6029)	
Train Epoch: [154][0/8]	Loss 0.6029 (0.6029)	LossFusion 0.6029 (0.6029)	
Train Epoch: [154][0/8]	Loss 0.6029 (0.6029)	LossFusion 0.6029 (0.6029)	
Train Epoch: [154][7/8]	Loss 0.3404 (0.4408)	LossFusion 0.3404 (0.4408)	
Train Epoch: [154][7/8]	Loss 0.3404 (0.4408)	LossFusion 0.3404 (0.4408)	
Train Epoch: [154][7/8]	Loss 0.3404 (0.4408)	LossFusion 0.3404 (0.4408)	
Train Epoch: [154][7/8]	Loss 0.3404 (0.4408)	LossFusion 0.3404 (0.4408)	
Train Epoch: [154][7/8]	Loss 0.3404 (0.4408)	LossFusion 0.3404 (0.4408)	
Train Epoch: [154][7/8]	Loss 0.3404 (0.4408)	LossFusion 0.3404 (0.4408)	
Train Epoch: [154][7/8]	Loss 0.3404 (0.4408)	LossFusion 0.3404 (0.4408)	
Train Epoch: [154][7/8]	Loss 0.3404 (0.4408)	LossFusion 0.3404 (0.4408)	
R@10:  55.36627173423767     R@50:  81.48779273033142
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.48779273033142
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.48779273033142
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.48779273033142
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.48779273033142
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.48779273033142
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.48779273033142
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.48779273033142
Mean Now:  68.42703223228455  Best Mean Before:  69.44918 --------------------
Train Epoch: [155][0/8]	Loss 0.6164 (0.6164)	LossFusion 0.6164 (0.6164)	
Train Epoch: [155][0/8]	Loss 0.6164 (0.6164)	LossFusion 0.6164 (0.6164)	
Train Epoch: [155][0/8]	Loss 0.6164 (0.6164)	LossFusion 0.6164 (0.6164)	
Train Epoch: [155][0/8]	Loss 0.6164 (0.6164)	LossFusion 0.6164 (0.6164)	
Train Epoch: [155][0/8]	Loss 0.6164 (0.6164)	LossFusion 0.6164 (0.6164)	
Train Epoch: [155][0/8]	Loss 0.6164 (0.6164)	LossFusion 0.6164 (0.6164)	
Train Epoch: [155][0/8]	Loss 0.6164 (0.6164)	LossFusion 0.6164 (0.6164)	
Train Epoch: [155][0/8]	Loss 0.6164 (0.6164)	LossFusion 0.6164 (0.6164)	
Train Epoch: [155][7/8]	Loss 0.3119 (0.4474)	LossFusion 0.3119 (0.4474)	
Train Epoch: [155][7/8]	Loss 0.3119 (0.4474)	LossFusion 0.3119 (0.4474)	
Train Epoch: [155][7/8]	Loss 0.3119 (0.4474)	LossFusion 0.3119 (0.4474)	
Train Epoch: [155][7/8]	Loss 0.3119 (0.4474)	LossFusion 0.3119 (0.4474)	
Train Epoch: [155][7/8]	Loss 0.3119 (0.4474)	LossFusion 0.3119 (0.4474)	
Train Epoch: [155][7/8]	Loss 0.3119 (0.4474)	LossFusion 0.3119 (0.4474)	
Train Epoch: [155][7/8]	Loss 0.3119 (0.4474)	LossFusion 0.3119 (0.4474)	
Train Epoch: [155][7/8]	Loss 0.3119 (0.4474)	LossFusion 0.3119 (0.4474)	
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  81.03350400924683
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
Train Epoch: [156][0/8]	Loss 0.6054 (0.6054)	LossFusion 0.6054 (0.6054)	
Train Epoch: [156][0/8]	Loss 0.6054 (0.6054)	LossFusion 0.6054 (0.6054)	
Train Epoch: [156][0/8]	Loss 0.6054 (0.6054)	LossFusion 0.6054 (0.6054)	
Train Epoch: [156][0/8]	Loss 0.6054 (0.6054)	LossFusion 0.6054 (0.6054)	
Train Epoch: [156][0/8]	Loss 0.6054 (0.6054)	LossFusion 0.6054 (0.6054)	
Train Epoch: [156][0/8]	Loss 0.6054 (0.6054)	LossFusion 0.6054 (0.6054)	
Train Epoch: [156][0/8]	Loss 0.6054 (0.6054)	LossFusion 0.6054 (0.6054)	
Train Epoch: [156][0/8]	Loss 0.6054 (0.6054)	LossFusion 0.6054 (0.6054)	
Train Epoch: [156][7/8]	Loss 0.3008 (0.4285)	LossFusion 0.3008 (0.4285)	
Train Epoch: [156][7/8]	Loss 0.3008 (0.4285)	LossFusion 0.3008 (0.4285)	
Train Epoch: [156][7/8]	Loss 0.3008 (0.4285)	LossFusion 0.3008 (0.4285)	
Train Epoch: [156][7/8]	Loss 0.3008 (0.4285)	LossFusion 0.3008 (0.4285)	
Train Epoch: [156][7/8]	Loss 0.3008 (0.4285)	LossFusion 0.3008 (0.4285)	
Train Epoch: [156][7/8]	Loss 0.3008 (0.4285)	LossFusion 0.3008 (0.4285)	
Train Epoch: [156][7/8]	Loss 0.3008 (0.4285)	LossFusion 0.3008 (0.4285)	
Train Epoch: [156][7/8]	Loss 0.3008 (0.4285)	LossFusion 0.3008 (0.4285)	
R@10:  54.79841232299805     R@50:  81.26064538955688
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.26064538955688
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.26064538955688
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.26064538955688
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.26064538955688
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.26064538955688
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.26064538955688
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.26064538955688
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
Train Epoch: [157][0/8]	Loss 0.6452 (0.6452)	LossFusion 0.6452 (0.6452)	
Train Epoch: [157][0/8]	Loss 0.6452 (0.6452)	LossFusion 0.6452 (0.6452)	
Train Epoch: [157][0/8]	Loss 0.6452 (0.6452)	LossFusion 0.6452 (0.6452)	
Train Epoch: [157][0/8]	Loss 0.6452 (0.6452)	LossFusion 0.6452 (0.6452)	
Train Epoch: [157][0/8]	Loss 0.6452 (0.6452)	LossFusion 0.6452 (0.6452)	
Train Epoch: [157][0/8]	Loss 0.6452 (0.6452)	LossFusion 0.6452 (0.6452)	
Train Epoch: [157][0/8]	Loss 0.6452 (0.6452)	LossFusion 0.6452 (0.6452)	
Train Epoch: [157][0/8]	Loss 0.6452 (0.6452)	LossFusion 0.6452 (0.6452)	
Train Epoch: [157][7/8]	Loss 0.3086 (0.4416)	LossFusion 0.3086 (0.4416)	
Train Epoch: [157][7/8]	Loss 0.3086 (0.4416)	LossFusion 0.3086 (0.4416)	
Train Epoch: [157][7/8]	Loss 0.3086 (0.4416)	LossFusion 0.3086 (0.4416)	
Train Epoch: [157][7/8]	Loss 0.3086 (0.4416)	LossFusion 0.3086 (0.4416)	
Train Epoch: [157][7/8]	Loss 0.3086 (0.4416)	LossFusion 0.3086 (0.4416)	
Train Epoch: [157][7/8]	Loss 0.3086 (0.4416)	LossFusion 0.3086 (0.4416)	
Train Epoch: [157][7/8]	Loss 0.3086 (0.4416)	LossFusion 0.3086 (0.4416)	
Train Epoch: [157][7/8]	Loss 0.3086 (0.4416)	LossFusion 0.3086 (0.4416)	
R@10:  55.36627173423767     R@50:  81.3174307346344
Mean Now:  68.34185123443604  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.3174307346344
Mean Now:  68.34185123443604  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.3174307346344
Mean Now:  68.34185123443604  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.3174307346344
Mean Now:  68.34185123443604  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.3174307346344
Mean Now:  68.34185123443604  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.3174307346344
Mean Now:  68.34185123443604  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.3174307346344
Mean Now:  68.34185123443604  Best Mean Before:  69.44918 --------------------
R@10:  55.36627173423767     R@50:  81.3174307346344
Mean Now:  68.34185123443604  Best Mean Before:  69.44918 --------------------
Train Epoch: [158][0/8]	Loss 0.6246 (0.6246)	LossFusion 0.6246 (0.6246)	
Train Epoch: [158][0/8]	Loss 0.6246 (0.6246)	LossFusion 0.6246 (0.6246)	
Train Epoch: [158][0/8]	Loss 0.6246 (0.6246)	LossFusion 0.6246 (0.6246)	
Train Epoch: [158][0/8]	Loss 0.6246 (0.6246)	LossFusion 0.6246 (0.6246)	
Train Epoch: [158][0/8]	Loss 0.6246 (0.6246)	LossFusion 0.6246 (0.6246)	
Train Epoch: [158][0/8]	Loss 0.6246 (0.6246)	LossFusion 0.6246 (0.6246)	
Train Epoch: [158][0/8]	Loss 0.6246 (0.6246)	LossFusion 0.6246 (0.6246)	
Train Epoch: [158][0/8]	Loss 0.6246 (0.6246)	LossFusion 0.6246 (0.6246)	
Train Epoch: [158][7/8]	Loss 0.3088 (0.4350)	LossFusion 0.3088 (0.4350)	
Train Epoch: [158][7/8]	Loss 0.3088 (0.4350)	LossFusion 0.3088 (0.4350)	
Train Epoch: [158][7/8]	Loss 0.3088 (0.4350)	LossFusion 0.3088 (0.4350)	
Train Epoch: [158][7/8]	Loss 0.3088 (0.4350)	LossFusion 0.3088 (0.4350)	
Train Epoch: [158][7/8]	Loss 0.3088 (0.4350)	LossFusion 0.3088 (0.4350)	
Train Epoch: [158][7/8]	Loss 0.3088 (0.4350)	LossFusion 0.3088 (0.4350)	
Train Epoch: [158][7/8]	Loss 0.3088 (0.4350)	LossFusion 0.3088 (0.4350)	
Train Epoch: [158][7/8]	Loss 0.3088 (0.4350)	LossFusion 0.3088 (0.4350)	
R@10:  55.025553703308105     R@50:  81.20386004447937
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.20386004447937
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.20386004447937
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.20386004447937
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.20386004447937
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.20386004447937
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.20386004447937
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.20386004447937
Mean Now:  68.11470687389374  Best Mean Before:  69.44918 --------------------
Train Epoch: [159][0/8]	Loss 0.6019 (0.6019)	LossFusion 0.6019 (0.6019)	
Train Epoch: [159][0/8]	Loss 0.6019 (0.6019)	LossFusion 0.6019 (0.6019)	
Train Epoch: [159][0/8]	Loss 0.6019 (0.6019)	LossFusion 0.6019 (0.6019)	
Train Epoch: [159][0/8]	Loss 0.6019 (0.6019)	LossFusion 0.6019 (0.6019)	
Train Epoch: [159][0/8]	Loss 0.6019 (0.6019)	LossFusion 0.6019 (0.6019)	
Train Epoch: [159][0/8]	Loss 0.6019 (0.6019)	LossFusion 0.6019 (0.6019)	
Train Epoch: [159][0/8]	Loss 0.6019 (0.6019)	LossFusion 0.6019 (0.6019)	
Train Epoch: [159][0/8]	Loss 0.6019 (0.6019)	LossFusion 0.6019 (0.6019)	
Train Epoch: [159][7/8]	Loss 0.3145 (0.4306)	LossFusion 0.3145 (0.4306)	
Train Epoch: [159][7/8]	Loss 0.3145 (0.4306)	LossFusion 0.3145 (0.4306)	Train Epoch: [159][7/8]	Loss 0.3145 (0.4306)	LossFusion 0.3145 (0.4306)	

Train Epoch: [159][7/8]	Loss 0.3145 (0.4306)	LossFusion 0.3145 (0.4306)	
Train Epoch: [159][7/8]	Loss 0.3145 (0.4306)	LossFusion 0.3145 (0.4306)	
Train Epoch: [159][7/8]	Loss 0.3145 (0.4306)	LossFusion 0.3145 (0.4306)	
Train Epoch: [159][7/8]	Loss 0.3145 (0.4306)	LossFusion 0.3145 (0.4306)	
Train Epoch: [159][7/8]	Loss 0.3145 (0.4306)	LossFusion 0.3145 (0.4306)	
R@10:  54.34412360191345     R@50:  81.20386004447937
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  81.20386004447937
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  81.20386004447937
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  81.20386004447937
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  81.20386004447937
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  81.20386004447937
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  81.20386004447937
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  81.20386004447937
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
Train Epoch: [160][0/8]	Loss 0.6136 (0.6136)	LossFusion 0.6136 (0.6136)	
Train Epoch: [160][0/8]	Loss 0.6136 (0.6136)	LossFusion 0.6136 (0.6136)	
Train Epoch: [160][0/8]	Loss 0.6136 (0.6136)	LossFusion 0.6136 (0.6136)	
Train Epoch: [160][0/8]	Loss 0.6136 (0.6136)	LossFusion 0.6136 (0.6136)	
Train Epoch: [160][0/8]	Loss 0.6136 (0.6136)	LossFusion 0.6136 (0.6136)	
Train Epoch: [160][0/8]	Loss 0.6136 (0.6136)	LossFusion 0.6136 (0.6136)	
Train Epoch: [160][0/8]	Loss 0.6136 (0.6136)	LossFusion 0.6136 (0.6136)	
Train Epoch: [160][0/8]	Loss 0.6136 (0.6136)	LossFusion 0.6136 (0.6136)	
Train Epoch: [160][7/8]	Loss 0.3180 (0.4193)	LossFusion 0.3180 (0.4193)	
Train Epoch: [160][7/8]	Loss 0.3180 (0.4193)	LossFusion 0.3180 (0.4193)	
Train Epoch: [160][7/8]	Loss 0.3180 (0.4193)	LossFusion 0.3180 (0.4193)	
Train Epoch: [160][7/8]	Loss 0.3180 (0.4193)	LossFusion 0.3180 (0.4193)	
Train Epoch: [160][7/8]	Loss 0.3180 (0.4193)	LossFusion 0.3180 (0.4193)	
Train Epoch: [160][7/8]	Loss 0.3180 (0.4193)	LossFusion 0.3180 (0.4193)	
Train Epoch: [160][7/8]	Loss 0.3180 (0.4193)	LossFusion 0.3180 (0.4193)	
Train Epoch: [160][7/8]	Loss 0.3180 (0.4193)	LossFusion 0.3180 (0.4193)	
R@10:  54.79841232299805     R@50:  80.9199333190918
Mean Now:  67.85917282104492  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  80.9199333190918
Mean Now:  67.85917282104492  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  80.9199333190918
Mean Now:  67.85917282104492  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  80.9199333190918
Mean Now:  67.85917282104492  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  80.9199333190918
Mean Now:  67.85917282104492  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  80.9199333190918
Mean Now:  67.85917282104492  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  80.9199333190918
Mean Now:  67.85917282104492  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  80.9199333190918
Mean Now:  67.85917282104492  Best Mean Before:  69.44918 --------------------
Train Epoch: [161][0/8]	Loss 0.5696 (0.5696)	LossFusion 0.5696 (0.5696)	
Train Epoch: [161][0/8]	Loss 0.5696 (0.5696)	LossFusion 0.5696 (0.5696)	
Train Epoch: [161][0/8]	Loss 0.5696 (0.5696)	LossFusion 0.5696 (0.5696)	
Train Epoch: [161][0/8]	Loss 0.5696 (0.5696)	LossFusion 0.5696 (0.5696)	
Train Epoch: [161][0/8]	Loss 0.5696 (0.5696)	LossFusion 0.5696 (0.5696)	
Train Epoch: [161][0/8]	Loss 0.5696 (0.5696)	LossFusion 0.5696 (0.5696)	
Train Epoch: [161][0/8]	Loss 0.5696 (0.5696)	LossFusion 0.5696 (0.5696)	
Train Epoch: [161][0/8]	Loss 0.5696 (0.5696)	LossFusion 0.5696 (0.5696)	
Train Epoch: [161][7/8]	Loss 0.2996 (0.4072)	LossFusion 0.2996 (0.4072)	
Train Epoch: [161][7/8]	Loss 0.2996 (0.4072)	LossFusion 0.2996 (0.4072)	
Train Epoch: [161][7/8]	Loss 0.2996 (0.4072)	LossFusion 0.2996 (0.4072)	
Train Epoch: [161][7/8]	Loss 0.2996 (0.4072)	LossFusion 0.2996 (0.4072)	
Train Epoch: [161][7/8]	Loss 0.2996 (0.4072)	LossFusion 0.2996 (0.4072)	
Train Epoch: [161][7/8]	Loss 0.2996 (0.4072)	LossFusion 0.2996 (0.4072)	
Train Epoch: [161][7/8]	Loss 0.2996 (0.4072)	LossFusion 0.2996 (0.4072)	
Train Epoch: [161][7/8]	Loss 0.2996 (0.4072)	LossFusion 0.2996 (0.4072)	
R@10:  55.59341311454773     R@50:  81.37422204017639
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.37422204017639
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.37422204017639
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.37422204017639
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.37422204017639
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.37422204017639
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.37422204017639
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.37422204017639
Mean Now:  68.48381757736206  Best Mean Before:  69.44918 --------------------
Train Epoch: [162][0/8]	Loss 0.5848 (0.5848)	LossFusion 0.5848 (0.5848)	
Train Epoch: [162][0/8]	Loss 0.5848 (0.5848)	LossFusion 0.5848 (0.5848)	
Train Epoch: [162][0/8]	Loss 0.5848 (0.5848)	LossFusion 0.5848 (0.5848)	
Train Epoch: [162][0/8]	Loss 0.5848 (0.5848)	LossFusion 0.5848 (0.5848)	
Train Epoch: [162][0/8]	Loss 0.5848 (0.5848)	LossFusion 0.5848 (0.5848)	
Train Epoch: [162][0/8]	Loss 0.5848 (0.5848)	LossFusion 0.5848 (0.5848)	
Train Epoch: [162][0/8]	Loss 0.5848 (0.5848)	LossFusion 0.5848 (0.5848)	
Train Epoch: [162][0/8]	Loss 0.5848 (0.5848)	LossFusion 0.5848 (0.5848)	
Train Epoch: [162][7/8]	Loss 0.2821 (0.4047)	LossFusion 0.2821 (0.4047)	
Train Epoch: [162][7/8]	Loss 0.2821 (0.4047)	LossFusion 0.2821 (0.4047)	
Train Epoch: [162][7/8]	Loss 0.2821 (0.4047)	LossFusion 0.2821 (0.4047)	
Train Epoch: [162][7/8]	Loss 0.2821 (0.4047)	LossFusion 0.2821 (0.4047)	
Train Epoch: [162][7/8]	Loss 0.2821 (0.4047)	LossFusion 0.2821 (0.4047)	
Train Epoch: [162][7/8]	Loss 0.2821 (0.4047)	LossFusion 0.2821 (0.4047)	
Train Epoch: [162][7/8]	Loss 0.2821 (0.4047)	LossFusion 0.2821 (0.4047)	
Train Epoch: [162][7/8]	Loss 0.2821 (0.4047)	LossFusion 0.2821 (0.4047)	
R@10:  54.85519766807556     R@50:  81.20386004447937
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  81.20386004447937
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  81.20386004447937
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  81.20386004447937
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  81.20386004447937
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  81.20386004447937
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  81.20386004447937
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  81.20386004447937
Mean Now:  68.02952885627747  Best Mean Before:  69.44918 --------------------
Train Epoch: [163][0/8]	Loss 0.5296 (0.5296)	LossFusion 0.5296 (0.5296)	
Train Epoch: [163][0/8]	Loss 0.5296 (0.5296)	LossFusion 0.5296 (0.5296)	
Train Epoch: [163][0/8]	Loss 0.5296 (0.5296)	LossFusion 0.5296 (0.5296)	
Train Epoch: [163][0/8]	Loss 0.5296 (0.5296)	LossFusion 0.5296 (0.5296)	
Train Epoch: [163][0/8]	Loss 0.5296 (0.5296)	LossFusion 0.5296 (0.5296)	
Train Epoch: [163][0/8]	Loss 0.5296 (0.5296)	LossFusion 0.5296 (0.5296)	
Train Epoch: [163][0/8]	Loss 0.5296 (0.5296)	LossFusion 0.5296 (0.5296)	
Train Epoch: [163][0/8]	Loss 0.5296 (0.5296)	LossFusion 0.5296 (0.5296)	
Train Epoch: [163][7/8]	Loss 0.2957 (0.4004)	LossFusion 0.2957 (0.4004)	
Train Epoch: [163][7/8]	Loss 0.2957 (0.4004)	LossFusion 0.2957 (0.4004)	
Train Epoch: [163][7/8]	Loss 0.2957 (0.4004)	LossFusion 0.2957 (0.4004)	
Train Epoch: [163][7/8]	Loss 0.2957 (0.4004)	LossFusion 0.2957 (0.4004)	
Train Epoch: [163][7/8]	Loss 0.2957 (0.4004)	LossFusion 0.2957 (0.4004)	
Train Epoch: [163][7/8]	Loss 0.2957 (0.4004)	LossFusion 0.2957 (0.4004)	
Train Epoch: [163][7/8]	Loss 0.2957 (0.4004)	LossFusion 0.2957 (0.4004)	
Train Epoch: [163][7/8]	Loss 0.2957 (0.4004)	LossFusion 0.2957 (0.4004)	
R@10:  55.59341311454773     R@50:  81.03350400924683
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.03350400924683
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.03350400924683
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.03350400924683
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.03350400924683
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.03350400924683
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.03350400924683
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
R@10:  55.59341311454773     R@50:  81.03350400924683
Mean Now:  68.31345856189728  Best Mean Before:  69.44918 --------------------
Train Epoch: [164][0/8]	Loss 0.5566 (0.5566)	LossFusion 0.5566 (0.5566)	
Train Epoch: [164][0/8]	Loss 0.5566 (0.5566)	LossFusion 0.5566 (0.5566)	
Train Epoch: [164][0/8]	Loss 0.5566 (0.5566)	LossFusion 0.5566 (0.5566)	
Train Epoch: [164][0/8]	Loss 0.5566 (0.5566)	LossFusion 0.5566 (0.5566)	
Train Epoch: [164][0/8]	Loss 0.5566 (0.5566)	LossFusion 0.5566 (0.5566)	
Train Epoch: [164][0/8]	Loss 0.5566 (0.5566)	LossFusion 0.5566 (0.5566)	
Train Epoch: [164][0/8]	Loss 0.5566 (0.5566)	LossFusion 0.5566 (0.5566)	
Train Epoch: [164][0/8]	Loss 0.5566 (0.5566)	LossFusion 0.5566 (0.5566)	
Train Epoch: [164][7/8]	Loss 0.2934 (0.3985)	LossFusion 0.2934 (0.3985)	
Train Epoch: [164][7/8]	Loss 0.2934 (0.3985)	LossFusion 0.2934 (0.3985)	
Train Epoch: [164][7/8]	Loss 0.2934 (0.3985)	LossFusion 0.2934 (0.3985)	
Train Epoch: [164][7/8]	Loss 0.2934 (0.3985)	LossFusion 0.2934 (0.3985)	
Train Epoch: [164][7/8]	Loss 0.2934 (0.3985)	LossFusion 0.2934 (0.3985)	
Train Epoch: [164][7/8]	Loss 0.2934 (0.3985)	LossFusion 0.2934 (0.3985)	
Train Epoch: [164][7/8]	Loss 0.2934 (0.3985)	LossFusion 0.2934 (0.3985)	
Train Epoch: [164][7/8]	Loss 0.2934 (0.3985)	LossFusion 0.2934 (0.3985)	
R@10:  54.514479637145996     R@50:  80.97671866416931
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.97671866416931
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.97671866416931
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.97671866416931
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.97671866416931
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.97671866416931
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.97671866416931
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.97671866416931
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
Train Epoch: [165][0/8]	Loss 0.5535 (0.5535)	LossFusion 0.5535 (0.5535)	
Train Epoch: [165][0/8]	Loss 0.5535 (0.5535)	LossFusion 0.5535 (0.5535)	
Train Epoch: [165][0/8]	Loss 0.5535 (0.5535)	LossFusion 0.5535 (0.5535)	
Train Epoch: [165][0/8]	Loss 0.5535 (0.5535)	LossFusion 0.5535 (0.5535)	
Train Epoch: [165][0/8]	Loss 0.5535 (0.5535)	LossFusion 0.5535 (0.5535)	
Train Epoch: [165][0/8]	Loss 0.5535 (0.5535)	LossFusion 0.5535 (0.5535)	
Train Epoch: [165][0/8]	Loss 0.5535 (0.5535)	LossFusion 0.5535 (0.5535)	
Train Epoch: [165][0/8]	Loss 0.5535 (0.5535)	LossFusion 0.5535 (0.5535)	
Train Epoch: [165][7/8]	Loss 0.2996 (0.3940)	LossFusion 0.2996 (0.3940)	
Train Epoch: [165][7/8]	Loss 0.2996 (0.3940)	LossFusion 0.2996 (0.3940)	
Train Epoch: [165][7/8]	Loss 0.2996 (0.3940)	LossFusion 0.2996 (0.3940)	
Train Epoch: [165][7/8]	Loss 0.2996 (0.3940)	LossFusion 0.2996 (0.3940)	
Train Epoch: [165][7/8]	Loss 0.2996 (0.3940)	LossFusion 0.2996 (0.3940)	
Train Epoch: [165][7/8]	Loss 0.2996 (0.3940)	LossFusion 0.2996 (0.3940)	
Train Epoch: [165][7/8]	Loss 0.2996 (0.3940)	LossFusion 0.2996 (0.3940)	
Train Epoch: [165][7/8]	Loss 0.2996 (0.3940)	LossFusion 0.2996 (0.3940)	
R@10:  54.45769429206848     R@50:  81.09028935432434
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  81.09028935432434
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  81.09028935432434
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  81.09028935432434
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  81.09028935432434
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  81.09028935432434
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  81.09028935432434
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  81.09028935432434
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
Train Epoch: [166][0/8]	Loss 0.5203 (0.5203)	LossFusion 0.5203 (0.5203)	
Train Epoch: [166][0/8]	Loss 0.5203 (0.5203)	LossFusion 0.5203 (0.5203)	
Train Epoch: [166][0/8]	Loss 0.5203 (0.5203)	LossFusion 0.5203 (0.5203)	
Train Epoch: [166][0/8]	Loss 0.5203 (0.5203)	LossFusion 0.5203 (0.5203)	
Train Epoch: [166][0/8]	Loss 0.5203 (0.5203)	LossFusion 0.5203 (0.5203)	
Train Epoch: [166][0/8]	Loss 0.5203 (0.5203)	LossFusion 0.5203 (0.5203)	
Train Epoch: [166][0/8]	Loss 0.5203 (0.5203)	LossFusion 0.5203 (0.5203)	
Train Epoch: [166][0/8]	Loss 0.5203 (0.5203)	LossFusion 0.5203 (0.5203)	
Train Epoch: [166][7/8]	Loss 0.3044 (0.3910)	LossFusion 0.3044 (0.3910)	Train Epoch: [166][7/8]	Loss 0.3044 (0.3910)	LossFusion 0.3044 (0.3910)	

Train Epoch: [166][7/8]	Loss 0.3044 (0.3910)	LossFusion 0.3044 (0.3910)	
Train Epoch: [166][7/8]	Loss 0.3044 (0.3910)	LossFusion 0.3044 (0.3910)	
Train Epoch: [166][7/8]	Loss 0.3044 (0.3910)	LossFusion 0.3044 (0.3910)	
Train Epoch: [166][7/8]	Loss 0.3044 (0.3910)	LossFusion 0.3044 (0.3910)	
Train Epoch: [166][7/8]	Loss 0.3044 (0.3910)	LossFusion 0.3044 (0.3910)	
Train Epoch: [166][7/8]	Loss 0.3044 (0.3910)	LossFusion 0.3044 (0.3910)	
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  69.44918 --------------------
R@10:  55.025553703308105     R@50:  81.14707469940186
Mean Now:  68.08631420135498  Best Mean Before:  69.44918 --------------------
Train Epoch: [167][0/8]	Loss 0.5189 (0.5189)	LossFusion 0.5189 (0.5189)	
Train Epoch: [167][0/8]	Loss 0.5189 (0.5189)	LossFusion 0.5189 (0.5189)	
Train Epoch: [167][0/8]	Loss 0.5189 (0.5189)	LossFusion 0.5189 (0.5189)	
Train Epoch: [167][0/8]	Loss 0.5189 (0.5189)	LossFusion 0.5189 (0.5189)	
Train Epoch: [167][0/8]	Loss 0.5189 (0.5189)	LossFusion 0.5189 (0.5189)	
Train Epoch: [167][0/8]	Loss 0.5189 (0.5189)	LossFusion 0.5189 (0.5189)	
Train Epoch: [167][0/8]	Loss 0.5189 (0.5189)	LossFusion 0.5189 (0.5189)	
Train Epoch: [167][0/8]	Loss 0.5189 (0.5189)	LossFusion 0.5189 (0.5189)	
Train Epoch: [167][7/8]	Loss 0.2858 (0.3867)	LossFusion 0.2858 (0.3867)	
Train Epoch: [167][7/8]	Loss 0.2858 (0.3867)	LossFusion 0.2858 (0.3867)	
Train Epoch: [167][7/8]	Loss 0.2858 (0.3867)	LossFusion 0.2858 (0.3867)	
Train Epoch: [167][7/8]	Loss 0.2858 (0.3867)	LossFusion 0.2858 (0.3867)	
Train Epoch: [167][7/8]	Loss 0.2858 (0.3867)	LossFusion 0.2858 (0.3867)	
Train Epoch: [167][7/8]	Loss 0.2858 (0.3867)	LossFusion 0.2858 (0.3867)	
Train Epoch: [167][7/8]	Loss 0.2858 (0.3867)	LossFusion 0.2858 (0.3867)	
Train Epoch: [167][7/8]	Loss 0.2858 (0.3867)	LossFusion 0.2858 (0.3867)	
R@10:  54.57126498222351     R@50:  80.86314797401428
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.86314797401428
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.86314797401428
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.86314797401428
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.86314797401428
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.86314797401428
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.86314797401428
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.86314797401428
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
Train Epoch: [168][0/8]	Loss 0.5052 (0.5052)	LossFusion 0.5052 (0.5052)	
Train Epoch: [168][0/8]	Loss 0.5052 (0.5052)	LossFusion 0.5052 (0.5052)	
Train Epoch: [168][0/8]	Loss 0.5052 (0.5052)	LossFusion 0.5052 (0.5052)	
Train Epoch: [168][0/8]	Loss 0.5052 (0.5052)	LossFusion 0.5052 (0.5052)	
Train Epoch: [168][0/8]	Loss 0.5052 (0.5052)	LossFusion 0.5052 (0.5052)	
Train Epoch: [168][0/8]	Loss 0.5052 (0.5052)	LossFusion 0.5052 (0.5052)	
Train Epoch: [168][0/8]	Loss 0.5052 (0.5052)	LossFusion 0.5052 (0.5052)	
Train Epoch: [168][0/8]	Loss 0.5052 (0.5052)	LossFusion 0.5052 (0.5052)	
Train Epoch: [168][7/8]	Loss 0.2856 (0.3690)	LossFusion 0.2856 (0.3690)	
Train Epoch: [168][7/8]	Loss 0.2856 (0.3690)	LossFusion 0.2856 (0.3690)	Train Epoch: [168][7/8]	Loss 0.2856 (0.3690)	LossFusion 0.2856 (0.3690)	

Train Epoch: [168][7/8]	Loss 0.2856 (0.3690)	LossFusion 0.2856 (0.3690)	
Train Epoch: [168][7/8]	Loss 0.2856 (0.3690)	LossFusion 0.2856 (0.3690)	
Train Epoch: [168][7/8]	Loss 0.2856 (0.3690)	LossFusion 0.2856 (0.3690)	
Train Epoch: [168][7/8]	Loss 0.2856 (0.3690)	LossFusion 0.2856 (0.3690)	
Train Epoch: [168][7/8]	Loss 0.2856 (0.3690)	LossFusion 0.2856 (0.3690)	
R@10:  54.79841232299805     R@50:  81.20386004447937
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.20386004447937
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.20386004447937
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.20386004447937
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.20386004447937
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.20386004447937
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.20386004447937
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
R@10:  54.79841232299805     R@50:  81.20386004447937
Mean Now:  68.00113618373871  Best Mean Before:  69.44918 --------------------
Train Epoch: [169][0/8]	Loss 0.5048 (0.5048)	LossFusion 0.5048 (0.5048)	
Train Epoch: [169][0/8]	Loss 0.5048 (0.5048)	LossFusion 0.5048 (0.5048)	
Train Epoch: [169][0/8]	Loss 0.5048 (0.5048)	LossFusion 0.5048 (0.5048)	
Train Epoch: [169][0/8]	Loss 0.5048 (0.5048)	LossFusion 0.5048 (0.5048)	
Train Epoch: [169][0/8]	Loss 0.5048 (0.5048)	LossFusion 0.5048 (0.5048)	
Train Epoch: [169][0/8]	Loss 0.5048 (0.5048)	LossFusion 0.5048 (0.5048)	
Train Epoch: [169][0/8]	Loss 0.5048 (0.5048)	LossFusion 0.5048 (0.5048)	
Train Epoch: [169][0/8]	Loss 0.5048 (0.5048)	LossFusion 0.5048 (0.5048)	
Train Epoch: [169][7/8]	Loss 0.2887 (0.3730)	LossFusion 0.2887 (0.3730)	
Train Epoch: [169][7/8]	Loss 0.2887 (0.3730)	LossFusion 0.2887 (0.3730)	Train Epoch: [169][7/8]	Loss 0.2887 (0.3730)	LossFusion 0.2887 (0.3730)	

Train Epoch: [169][7/8]	Loss 0.2887 (0.3730)	LossFusion 0.2887 (0.3730)	
Train Epoch: [169][7/8]	Loss 0.2887 (0.3730)	LossFusion 0.2887 (0.3730)	
Train Epoch: [169][7/8]	Loss 0.2887 (0.3730)	LossFusion 0.2887 (0.3730)	
Train Epoch: [169][7/8]	Loss 0.2887 (0.3730)	LossFusion 0.2887 (0.3730)	
Train Epoch: [169][7/8]	Loss 0.2887 (0.3730)	LossFusion 0.2887 (0.3730)	
R@10:  54.68483567237854     R@50:  80.9199333190918
Mean Now:  67.80238449573517  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.9199333190918
Mean Now:  67.80238449573517  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.9199333190918
Mean Now:  67.80238449573517  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.9199333190918
Mean Now:  67.80238449573517  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.9199333190918
Mean Now:  67.80238449573517  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.9199333190918
Mean Now:  67.80238449573517  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.9199333190918
Mean Now:  67.80238449573517  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.9199333190918
Mean Now:  67.80238449573517  Best Mean Before:  69.44918 --------------------
Train Epoch: [170][0/8]	Loss 0.5158 (0.5158)	LossFusion 0.5158 (0.5158)	
Train Epoch: [170][0/8]	Loss 0.5158 (0.5158)	LossFusion 0.5158 (0.5158)	
Train Epoch: [170][0/8]	Loss 0.5158 (0.5158)	LossFusion 0.5158 (0.5158)	
Train Epoch: [170][0/8]	Loss 0.5158 (0.5158)	LossFusion 0.5158 (0.5158)	
Train Epoch: [170][0/8]	Loss 0.5158 (0.5158)	LossFusion 0.5158 (0.5158)	
Train Epoch: [170][0/8]	Loss 0.5158 (0.5158)	LossFusion 0.5158 (0.5158)	
Train Epoch: [170][0/8]	Loss 0.5158 (0.5158)	LossFusion 0.5158 (0.5158)	
Train Epoch: [170][0/8]	Loss 0.5158 (0.5158)	LossFusion 0.5158 (0.5158)	
Train Epoch: [170][7/8]	Loss 0.2791 (0.3731)	LossFusion 0.2791 (0.3731)	
Train Epoch: [170][7/8]	Loss 0.2791 (0.3731)	LossFusion 0.2791 (0.3731)	
Train Epoch: [170][7/8]	Loss 0.2791 (0.3731)	LossFusion 0.2791 (0.3731)	
Train Epoch: [170][7/8]	Loss 0.2791 (0.3731)	LossFusion 0.2791 (0.3731)	
Train Epoch: [170][7/8]	Loss 0.2791 (0.3731)	LossFusion 0.2791 (0.3731)	
Train Epoch: [170][7/8]	Loss 0.2791 (0.3731)	LossFusion 0.2791 (0.3731)	
Train Epoch: [170][7/8]	Loss 0.2791 (0.3731)	LossFusion 0.2791 (0.3731)	
Train Epoch: [170][7/8]	Loss 0.2791 (0.3731)	LossFusion 0.2791 (0.3731)	
R@10:  54.514479637145996     R@50:  80.9199333190918
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.9199333190918
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.9199333190918
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.9199333190918
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.9199333190918
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.9199333190918
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.9199333190918
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
R@10:  54.514479637145996     R@50:  80.9199333190918
Mean Now:  67.7172064781189  Best Mean Before:  69.44918 --------------------
Train Epoch: [171][0/8]	Loss 0.4644 (0.4644)	LossFusion 0.4644 (0.4644)	
Train Epoch: [171][0/8]	Loss 0.4644 (0.4644)	LossFusion 0.4644 (0.4644)	
Train Epoch: [171][0/8]	Loss 0.4644 (0.4644)	LossFusion 0.4644 (0.4644)	
Train Epoch: [171][0/8]	Loss 0.4644 (0.4644)	LossFusion 0.4644 (0.4644)	
Train Epoch: [171][0/8]	Loss 0.4644 (0.4644)	LossFusion 0.4644 (0.4644)	
Train Epoch: [171][0/8]	Loss 0.4644 (0.4644)	LossFusion 0.4644 (0.4644)	
Train Epoch: [171][0/8]	Loss 0.4644 (0.4644)	LossFusion 0.4644 (0.4644)	
Train Epoch: [171][0/8]	Loss 0.4644 (0.4644)	LossFusion 0.4644 (0.4644)	
Train Epoch: [171][7/8]	Loss 0.2670 (0.3633)	LossFusion 0.2670 (0.3633)	
Train Epoch: [171][7/8]	Loss 0.2670 (0.3633)	LossFusion 0.2670 (0.3633)	
Train Epoch: [171][7/8]	Loss 0.2670 (0.3633)	LossFusion 0.2670 (0.3633)	
Train Epoch: [171][7/8]	Loss 0.2670 (0.3633)	LossFusion 0.2670 (0.3633)	
Train Epoch: [171][7/8]	Loss 0.2670 (0.3633)	LossFusion 0.2670 (0.3633)	
Train Epoch: [171][7/8]	Loss 0.2670 (0.3633)	LossFusion 0.2670 (0.3633)	
Train Epoch: [171][7/8]	Loss 0.2670 (0.3633)	LossFusion 0.2670 (0.3633)	
Train Epoch: [171][7/8]	Loss 0.2670 (0.3633)	LossFusion 0.2670 (0.3633)	
R@10:  54.85519766807556     R@50:  80.97671866416931
Mean Now:  67.91595816612244  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  80.97671866416931
Mean Now:  67.91595816612244  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  80.97671866416931
Mean Now:  67.91595816612244  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  80.97671866416931
Mean Now:  67.91595816612244  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  80.97671866416931
Mean Now:  67.91595816612244  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  80.97671866416931
Mean Now:  67.91595816612244  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  80.97671866416931
Mean Now:  67.91595816612244  Best Mean Before:  69.44918 --------------------
R@10:  54.85519766807556     R@50:  80.97671866416931
Mean Now:  67.91595816612244  Best Mean Before:  69.44918 --------------------
Train Epoch: [172][0/8]	Loss 0.5167 (0.5167)	LossFusion 0.5167 (0.5167)	
Train Epoch: [172][0/8]	Loss 0.5167 (0.5167)	LossFusion 0.5167 (0.5167)	
Train Epoch: [172][0/8]	Loss 0.5167 (0.5167)	LossFusion 0.5167 (0.5167)	
Train Epoch: [172][0/8]	Loss 0.5167 (0.5167)	LossFusion 0.5167 (0.5167)	
Train Epoch: [172][0/8]	Loss 0.5167 (0.5167)	LossFusion 0.5167 (0.5167)	
Train Epoch: [172][0/8]	Loss 0.5167 (0.5167)	LossFusion 0.5167 (0.5167)	
Train Epoch: [172][0/8]	Loss 0.5167 (0.5167)	LossFusion 0.5167 (0.5167)	
Train Epoch: [172][0/8]	Loss 0.5167 (0.5167)	LossFusion 0.5167 (0.5167)	
Train Epoch: [172][7/8]	Loss 0.2375 (0.3605)	LossFusion 0.2375 (0.3605)	
Train Epoch: [172][7/8]	Loss 0.2375 (0.3605)	LossFusion 0.2375 (0.3605)	
Train Epoch: [172][7/8]	Loss 0.2375 (0.3605)	LossFusion 0.2375 (0.3605)	
Train Epoch: [172][7/8]	Loss 0.2375 (0.3605)	LossFusion 0.2375 (0.3605)	
Train Epoch: [172][7/8]	Loss 0.2375 (0.3605)	LossFusion 0.2375 (0.3605)	
Train Epoch: [172][7/8]	Loss 0.2375 (0.3605)	LossFusion 0.2375 (0.3605)	
Train Epoch: [172][7/8]	Loss 0.2375 (0.3605)	LossFusion 0.2375 (0.3605)	
Train Epoch: [172][7/8]	Loss 0.2375 (0.3605)	LossFusion 0.2375 (0.3605)	
R@10:  54.00340557098389     R@50:  81.09028935432434
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  81.09028935432434
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  81.09028935432434
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  81.09028935432434
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  81.09028935432434
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  81.09028935432434
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  81.09028935432434
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  81.09028935432434
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
Train Epoch: [173][0/8]	Loss 0.4847 (0.4847)	LossFusion 0.4847 (0.4847)	Train Epoch: [173][0/8]	Loss 0.4847 (0.4847)	LossFusion 0.4847 (0.4847)	

Train Epoch: [173][0/8]	Loss 0.4847 (0.4847)	LossFusion 0.4847 (0.4847)	
Train Epoch: [173][0/8]	Loss 0.4847 (0.4847)	LossFusion 0.4847 (0.4847)	
Train Epoch: [173][0/8]	Loss 0.4847 (0.4847)	LossFusion 0.4847 (0.4847)	
Train Epoch: [173][0/8]	Loss 0.4847 (0.4847)	LossFusion 0.4847 (0.4847)	
Train Epoch: [173][0/8]	Loss 0.4847 (0.4847)	LossFusion 0.4847 (0.4847)	
Train Epoch: [173][0/8]	Loss 0.4847 (0.4847)	LossFusion 0.4847 (0.4847)	
Train Epoch: [173][7/8]	Loss 0.2630 (0.3553)	LossFusion 0.2630 (0.3553)	
Train Epoch: [173][7/8]	Loss 0.2630 (0.3553)	LossFusion 0.2630 (0.3553)	
Train Epoch: [173][7/8]	Loss 0.2630 (0.3553)	LossFusion 0.2630 (0.3553)	
Train Epoch: [173][7/8]	Loss 0.2630 (0.3553)	LossFusion 0.2630 (0.3553)	
Train Epoch: [173][7/8]	Loss 0.2630 (0.3553)	LossFusion 0.2630 (0.3553)	
Train Epoch: [173][7/8]	Loss 0.2630 (0.3553)	LossFusion 0.2630 (0.3553)	
Train Epoch: [173][7/8]	Loss 0.2630 (0.3553)	LossFusion 0.2630 (0.3553)	
Train Epoch: [173][7/8]	Loss 0.2630 (0.3553)	LossFusion 0.2630 (0.3553)	
R@10:  53.94662022590637     R@50:  80.74957132339478
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.74957132339478
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.74957132339478
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.74957132339478
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.74957132339478
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.74957132339478
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 R@10: -------------------- 
53.94662022590637     R@50:  80.74957132339478
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.74957132339478
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
Train Epoch: [174][0/8]	Loss 0.4795 (0.4795)	LossFusion 0.4795 (0.4795)	
Train Epoch: [174][0/8]	Loss 0.4795 (0.4795)	LossFusion 0.4795 (0.4795)	
Train Epoch: [174][0/8]	Loss 0.4795 (0.4795)	LossFusion 0.4795 (0.4795)	
Train Epoch: [174][0/8]	Loss 0.4795 (0.4795)	LossFusion 0.4795 (0.4795)	
Train Epoch: [174][0/8]	Loss 0.4795 (0.4795)	LossFusion 0.4795 (0.4795)	
Train Epoch: [174][0/8]	Loss 0.4795 (0.4795)	LossFusion 0.4795 (0.4795)	
Train Epoch: [174][0/8]	Loss 0.4795 (0.4795)	LossFusion 0.4795 (0.4795)	
Train Epoch: [174][0/8]	Loss 0.4795 (0.4795)	LossFusion 0.4795 (0.4795)	
Train Epoch: [174][7/8]	Loss 0.2755 (0.3447)	LossFusion 0.2755 (0.3447)	
Train Epoch: [174][7/8]	Loss 0.2755 (0.3447)	LossFusion 0.2755 (0.3447)	
Train Epoch: [174][7/8]	Loss 0.2755 (0.3447)	LossFusion 0.2755 (0.3447)	
Train Epoch: [174][7/8]	Loss 0.2755 (0.3447)	LossFusion 0.2755 (0.3447)	
Train Epoch: [174][7/8]	Loss 0.2755 (0.3447)	LossFusion 0.2755 (0.3447)	
Train Epoch: [174][7/8]	Loss 0.2755 (0.3447)	LossFusion 0.2755 (0.3447)	
Train Epoch: [174][7/8]	Loss 0.2755 (0.3447)	LossFusion 0.2755 (0.3447)	
Train Epoch: [174][7/8]	Loss 0.2755 (0.3447)	LossFusion 0.2755 (0.3447)	
R@10:  54.23055291175842     R@50:  80.9199333190918
Mean Now:  67.57524311542511  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.9199333190918
Mean Now:  67.57524311542511  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.9199333190918
Mean Now:  67.57524311542511  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.9199333190918
Mean Now:  67.57524311542511  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.9199333190918
Mean Now:  67.57524311542511  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.9199333190918
Mean Now:  67.57524311542511  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.9199333190918
Mean Now:  67.57524311542511  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.9199333190918
Mean Now:  67.57524311542511  Best Mean Before:  69.44918 --------------------
Train Epoch: [175][0/8]	Loss 0.4919 (0.4919)	LossFusion 0.4919 (0.4919)	
Train Epoch: [175][0/8]	Loss 0.4919 (0.4919)	LossFusion 0.4919 (0.4919)	
Train Epoch: [175][0/8]	Loss 0.4919 (0.4919)	LossFusion 0.4919 (0.4919)	
Train Epoch: [175][0/8]	Loss 0.4919 (0.4919)	LossFusion 0.4919 (0.4919)	
Train Epoch: [175][0/8]	Loss 0.4919 (0.4919)	LossFusion 0.4919 (0.4919)	
Train Epoch: [175][0/8]	Loss 0.4919 (0.4919)	LossFusion 0.4919 (0.4919)	
Train Epoch: [175][0/8]	Loss 0.4919 (0.4919)	LossFusion 0.4919 (0.4919)	
Train Epoch: [175][0/8]	Loss 0.4919 (0.4919)	LossFusion 0.4919 (0.4919)	
Train Epoch: [175][7/8]	Loss 0.2415 (0.3382)	LossFusion 0.2415 (0.3382)	
Train Epoch: [175][7/8]	Loss 0.2415 (0.3382)	LossFusion 0.2415 (0.3382)	
Train Epoch: [175][7/8]	Loss 0.2415 (0.3382)	LossFusion 0.2415 (0.3382)	
Train Epoch: [175][7/8]	Loss 0.2415 (0.3382)	LossFusion 0.2415 (0.3382)	
Train Epoch: [175][7/8]	Loss 0.2415 (0.3382)	LossFusion 0.2415 (0.3382)	
Train Epoch: [175][7/8]	Loss 0.2415 (0.3382)	LossFusion 0.2415 (0.3382)	
Train Epoch: [175][7/8]	Loss 0.2415 (0.3382)	LossFusion 0.2415 (0.3382)	
Train Epoch: [175][7/8]	Loss 0.2415 (0.3382)	LossFusion 0.2415 (0.3382)	
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
Train Epoch: [176][0/8]	Loss 0.4887 (0.4887)	LossFusion 0.4887 (0.4887)	
Train Epoch: [176][0/8]	Loss 0.4887 (0.4887)	LossFusion 0.4887 (0.4887)	
Train Epoch: [176][0/8]	Loss 0.4887 (0.4887)	LossFusion 0.4887 (0.4887)	
Train Epoch: [176][0/8]	Loss 0.4887 (0.4887)	LossFusion 0.4887 (0.4887)	
Train Epoch: [176][0/8]	Loss 0.4887 (0.4887)	LossFusion 0.4887 (0.4887)	
Train Epoch: [176][0/8]	Loss 0.4887 (0.4887)	LossFusion 0.4887 (0.4887)	
Train Epoch: [176][0/8]	Loss 0.4887 (0.4887)	LossFusion 0.4887 (0.4887)	
Train Epoch: [176][0/8]	Loss 0.4887 (0.4887)	LossFusion 0.4887 (0.4887)	
Train Epoch: [176][7/8]	Loss 0.2528 (0.3393)	LossFusion 0.2528 (0.3393)	
Train Epoch: [176][7/8]	Loss 0.2528 (0.3393)	LossFusion 0.2528 (0.3393)	
Train Epoch: [176][7/8]	Loss 0.2528 (0.3393)	LossFusion 0.2528 (0.3393)	
Train Epoch: [176][7/8]	Loss 0.2528 (0.3393)	LossFusion 0.2528 (0.3393)	
Train Epoch: [176][7/8]	Loss 0.2528 (0.3393)	LossFusion 0.2528 (0.3393)	
Train Epoch: [176][7/8]	Loss 0.2528 (0.3393)	LossFusion 0.2528 (0.3393)	
Train Epoch: [176][7/8]	Loss 0.2528 (0.3393)	LossFusion 0.2528 (0.3393)	
Train Epoch: [176][7/8]	Loss 0.2528 (0.3393)	LossFusion 0.2528 (0.3393)	
R@10:  54.45769429206848     R@50:  80.57921528816223
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.57921528816223
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.57921528816223
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.57921528816223
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.57921528816223
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.57921528816223
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.57921528816223
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.57921528816223
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
Train Epoch: [177][0/8]	Loss 0.4999 (0.4999)	LossFusion 0.4999 (0.4999)	
Train Epoch: [177][0/8]	Loss 0.4999 (0.4999)	LossFusion 0.4999 (0.4999)	
Train Epoch: [177][0/8]	Loss 0.4999 (0.4999)	LossFusion 0.4999 (0.4999)	
Train Epoch: [177][0/8]	Loss 0.4999 (0.4999)	LossFusion 0.4999 (0.4999)	
Train Epoch: [177][0/8]	Loss 0.4999 (0.4999)	LossFusion 0.4999 (0.4999)	
Train Epoch: [177][0/8]	Loss 0.4999 (0.4999)	LossFusion 0.4999 (0.4999)	
Train Epoch: [177][0/8]	Loss 0.4999 (0.4999)	LossFusion 0.4999 (0.4999)	
Train Epoch: [177][0/8]	Loss 0.4999 (0.4999)	LossFusion 0.4999 (0.4999)	
Train Epoch: [177][7/8]	Loss 0.2521 (0.3318)	LossFusion 0.2521 (0.3318)	
Train Epoch: [177][7/8]	Loss 0.2521 (0.3318)	LossFusion 0.2521 (0.3318)	
Train Epoch: [177][7/8]	Loss 0.2521 (0.3318)	LossFusion 0.2521 (0.3318)	
Train Epoch: [177][7/8]	Loss 0.2521 (0.3318)	LossFusion 0.2521 (0.3318)	
Train Epoch: [177][7/8]	Loss 0.2521 (0.3318)	LossFusion 0.2521 (0.3318)	
Train Epoch: [177][7/8]	Loss 0.2521 (0.3318)	LossFusion 0.2521 (0.3318)	
Train Epoch: [177][7/8]	Loss 0.2521 (0.3318)	LossFusion 0.2521 (0.3318)	
Train Epoch: [177][7/8]	Loss 0.2521 (0.3318)	LossFusion 0.2521 (0.3318)	
R@10:  54.34412360191345     R@50:  80.74957132339478
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.74957132339478
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.74957132339478
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.74957132339478
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.74957132339478
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.74957132339478
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.74957132339478
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.74957132339478
Mean Now:  67.54684746265411  Best Mean Before:  69.44918 --------------------
Train Epoch: [178][0/8]	Loss 0.4655 (0.4655)	LossFusion 0.4655 (0.4655)	
Train Epoch: [178][0/8]	Loss 0.4655 (0.4655)	LossFusion 0.4655 (0.4655)	
Train Epoch: [178][0/8]	Loss 0.4655 (0.4655)	LossFusion 0.4655 (0.4655)	
Train Epoch: [178][0/8]	Loss 0.4655 (0.4655)	LossFusion 0.4655 (0.4655)	
Train Epoch: [178][0/8]	Loss 0.4655 (0.4655)	LossFusion 0.4655 (0.4655)	
Train Epoch: [178][0/8]	Loss 0.4655 (0.4655)	LossFusion 0.4655 (0.4655)	
Train Epoch: [178][0/8]	Loss 0.4655 (0.4655)	LossFusion 0.4655 (0.4655)	
Train Epoch: [178][0/8]	Loss 0.4655 (0.4655)	LossFusion 0.4655 (0.4655)	
Train Epoch: [178][7/8]	Loss 0.2541 (0.3298)	LossFusion 0.2541 (0.3298)	
Train Epoch: [178][7/8]	Loss 0.2541 (0.3298)	LossFusion 0.2541 (0.3298)	
Train Epoch: [178][7/8]	Loss 0.2541 (0.3298)	LossFusion 0.2541 (0.3298)	
Train Epoch: [178][7/8]	Loss 0.2541 (0.3298)	LossFusion 0.2541 (0.3298)	
Train Epoch: [178][7/8]	Loss 0.2541 (0.3298)	LossFusion 0.2541 (0.3298)	
Train Epoch: [178][7/8]	Loss 0.2541 (0.3298)	LossFusion 0.2541 (0.3298)	
Train Epoch: [178][7/8]	Loss 0.2541 (0.3298)	LossFusion 0.2541 (0.3298)	
Train Epoch: [178][7/8]	Loss 0.2541 (0.3298)	LossFusion 0.2541 (0.3298)	
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.74957132339478
Mean Now:  67.66041815280914  Best Mean Before:  69.44918 --------------------
Train Epoch: [179][0/8]	Loss 0.4710 (0.4710)	LossFusion 0.4710 (0.4710)	
Train Epoch: [179][0/8]	Loss 0.4710 (0.4710)	LossFusion 0.4710 (0.4710)	
Train Epoch: [179][0/8]	Loss 0.4710 (0.4710)	LossFusion 0.4710 (0.4710)	Train Epoch: [179][0/8]	Loss 0.4710 (0.4710)	LossFusion 0.4710 (0.4710)	

Train Epoch: [179][0/8]	Loss 0.4710 (0.4710)	LossFusion 0.4710 (0.4710)	
Train Epoch: [179][0/8]	Loss 0.4710 (0.4710)	LossFusion 0.4710 (0.4710)	
Train Epoch: [179][0/8]	Loss 0.4710 (0.4710)	LossFusion 0.4710 (0.4710)	
Train Epoch: [179][0/8]	Loss 0.4710 (0.4710)	LossFusion 0.4710 (0.4710)	
Train Epoch: [179][7/8]	Loss 0.2373 (0.3243)	LossFusion 0.2373 (0.3243)	
Train Epoch: [179][7/8]	Loss 0.2373 (0.3243)	LossFusion 0.2373 (0.3243)	
Train Epoch: [179][7/8]	Loss 0.2373 (0.3243)	LossFusion 0.2373 (0.3243)	
Train Epoch: [179][7/8]	Loss 0.2373 (0.3243)	LossFusion 0.2373 (0.3243)	
Train Epoch: [179][7/8]	Loss 0.2373 (0.3243)	LossFusion 0.2373 (0.3243)	
Train Epoch: [179][7/8]	Loss 0.2373 (0.3243)	LossFusion 0.2373 (0.3243)	
Train Epoch: [179][7/8]	Loss 0.2373 (0.3243)	LossFusion 0.2373 (0.3243)	
Train Epoch: [179][7/8]	Loss 0.2373 (0.3243)	LossFusion 0.2373 (0.3243)	
R@10:  55.19590973854065     R@50:  80.52242994308472
Mean Now:  67.85916984081268  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  80.52242994308472
Mean Now:  67.85916984081268  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  80.52242994308472
Mean Now:  67.85916984081268  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  80.52242994308472
Mean Now:  67.85916984081268  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  80.52242994308472
Mean Now:  67.85916984081268  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  80.52242994308472
Mean Now:  67.85916984081268  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  80.52242994308472
Mean Now:  67.85916984081268  Best Mean Before:  69.44918 --------------------
R@10:  55.19590973854065     R@50:  80.52242994308472
Mean Now:  67.85916984081268  Best Mean Before:  69.44918 --------------------
Train Epoch: [180][0/8]	Loss 0.4237 (0.4237)	LossFusion 0.4237 (0.4237)	
Train Epoch: [180][0/8]	Loss 0.4237 (0.4237)	LossFusion 0.4237 (0.4237)	
Train Epoch: [180][0/8]	Loss 0.4237 (0.4237)	LossFusion 0.4237 (0.4237)	
Train Epoch: [180][0/8]	Loss 0.4237 (0.4237)	LossFusion 0.4237 (0.4237)	
Train Epoch: [180][0/8]	Loss 0.4237 (0.4237)	LossFusion 0.4237 (0.4237)	
Train Epoch: [180][0/8]	Loss 0.4237 (0.4237)	LossFusion 0.4237 (0.4237)	
Train Epoch: [180][0/8]	Loss 0.4237 (0.4237)	LossFusion 0.4237 (0.4237)	
Train Epoch: [180][0/8]	Loss 0.4237 (0.4237)	LossFusion 0.4237 (0.4237)	
Train Epoch: [180][7/8]	Loss 0.2411 (0.3155)	LossFusion 0.2411 (0.3155)	
Train Epoch: [180][7/8]	Loss 0.2411 (0.3155)	LossFusion 0.2411 (0.3155)	
Train Epoch: [180][7/8]	Loss 0.2411 (0.3155)	LossFusion 0.2411 (0.3155)	
Train Epoch: [180][7/8]	Loss 0.2411 (0.3155)	LossFusion 0.2411 (0.3155)	
Train Epoch: [180][7/8]	Loss 0.2411 (0.3155)	LossFusion 0.2411 (0.3155)	
Train Epoch: [180][7/8]	Loss 0.2411 (0.3155)	LossFusion 0.2411 (0.3155)	
Train Epoch: [180][7/8]	Loss 0.2411 (0.3155)	LossFusion 0.2411 (0.3155)	
Train Epoch: [180][7/8]	Loss 0.2411 (0.3155)	LossFusion 0.2411 (0.3155)	
R@10:  54.57126498222351     R@50:  80.80636262893677
Mean Now:  67.68881380558014  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.80636262893677
Mean Now:  R@10: 67.68881380558014  Best Mean Before:   69.44918 --------------------54.57126498222351
     R@50:  80.80636262893677
Mean Now:  67.68881380558014  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.80636262893677
Mean Now:  67.68881380558014  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.80636262893677
Mean Now:  67.68881380558014  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.80636262893677
Mean Now:  67.68881380558014  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.80636262893677
Mean Now:  67.68881380558014  Best Mean Before:  69.44918 --------------------
R@10:  54.57126498222351     R@50:  80.80636262893677
Mean Now:  67.68881380558014  Best Mean Before:  69.44918 --------------------
Train Epoch: [181][0/8]	Loss 0.4883 (0.4883)	LossFusion 0.4883 (0.4883)	
Train Epoch: [181][0/8]	Loss 0.4883 (0.4883)	LossFusion 0.4883 (0.4883)	
Train Epoch: [181][0/8]	Loss 0.4883 (0.4883)	LossFusion 0.4883 (0.4883)	
Train Epoch: [181][0/8]	Loss 0.4883 (0.4883)	LossFusion 0.4883 (0.4883)	
Train Epoch: [181][0/8]	Loss 0.4883 (0.4883)	LossFusion 0.4883 (0.4883)	
Train Epoch: [181][0/8]	Loss 0.4883 (0.4883)	LossFusion 0.4883 (0.4883)	
Train Epoch: [181][0/8]	Loss 0.4883 (0.4883)	LossFusion 0.4883 (0.4883)	
Train Epoch: [181][0/8]	Loss 0.4883 (0.4883)	LossFusion 0.4883 (0.4883)	
Train Epoch: [181][7/8]	Loss 0.2498 (0.3261)	LossFusion 0.2498 (0.3261)	
Train Epoch: [181][7/8]	Loss 0.2498 (0.3261)	LossFusion 0.2498 (0.3261)	
Train Epoch: [181][7/8]	Loss 0.2498 (0.3261)	LossFusion 0.2498 (0.3261)	
Train Epoch: [181][7/8]	Loss 0.2498 (0.3261)	LossFusion 0.2498 (0.3261)	
Train Epoch: [181][7/8]	Loss 0.2498 (0.3261)	LossFusion 0.2498 (0.3261)	
Train Epoch: [181][7/8]	Loss 0.2498 (0.3261)	LossFusion 0.2498 (0.3261)	
Train Epoch: [181][7/8]	Loss 0.2498 (0.3261)	LossFusion 0.2498 (0.3261)	
Train Epoch: [181][7/8]	Loss 0.2498 (0.3261)	LossFusion 0.2498 (0.3261)	
R@10:  53.54911684989929     R@50:  80.63600063323975
Mean Now:  67.09255874156952  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  80.63600063323975
Mean Now:  67.09255874156952  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  80.63600063323975
Mean Now:  67.09255874156952  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  80.63600063323975
Mean Now:  67.09255874156952  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  80.63600063323975
Mean Now:  67.09255874156952  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  80.63600063323975
Mean Now:  67.09255874156952  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  80.63600063323975
Mean Now:  67.09255874156952  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  80.63600063323975
Mean Now:  67.09255874156952  Best Mean Before:  69.44918 --------------------
Train Epoch: [182][0/8]	Loss 0.4660 (0.4660)	LossFusion 0.4660 (0.4660)	
Train Epoch: [182][0/8]	Loss 0.4660 (0.4660)	LossFusion 0.4660 (0.4660)	
Train Epoch: [182][0/8]	Loss 0.4660 (0.4660)	LossFusion 0.4660 (0.4660)	
Train Epoch: [182][0/8]	Loss 0.4660 (0.4660)	LossFusion 0.4660 (0.4660)	
Train Epoch: [182][0/8]	Loss 0.4660 (0.4660)	LossFusion 0.4660 (0.4660)	
Train Epoch: [182][0/8]	Loss 0.4660 (0.4660)	LossFusion 0.4660 (0.4660)	
Train Epoch: [182][0/8]	Loss 0.4660 (0.4660)	LossFusion 0.4660 (0.4660)	
Train Epoch: [182][0/8]	Loss 0.4660 (0.4660)	LossFusion 0.4660 (0.4660)	
Train Epoch: [182][7/8]	Loss 0.2575 (0.3280)	LossFusion 0.2575 (0.3280)	
Train Epoch: [182][7/8]	Loss 0.2575 (0.3280)	LossFusion 0.2575 (0.3280)	
Train Epoch: [182][7/8]	Loss 0.2575 (0.3280)	LossFusion 0.2575 (0.3280)	
Train Epoch: [182][7/8]	Loss 0.2575 (0.3280)	LossFusion 0.2575 (0.3280)	
Train Epoch: [182][7/8]	Loss 0.2575 (0.3280)	LossFusion 0.2575 (0.3280)	
Train Epoch: [182][7/8]	Loss 0.2575 (0.3280)	LossFusion 0.2575 (0.3280)	
Train Epoch: [182][7/8]	Loss 0.2575 (0.3280)	LossFusion 0.2575 (0.3280)	
Train Epoch: [182][7/8]	Loss 0.2575 (0.3280)	LossFusion 0.2575 (0.3280)	
R@10:  54.23055291175842     R@50:  80.4656445980072
Mean Now:  67.34809875488281  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.4656445980072
Mean Now:  67.34809875488281  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.4656445980072
Mean Now:  67.34809875488281  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.4656445980072
Mean Now:  67.34809875488281  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.4656445980072
Mean Now:  67.34809875488281  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.4656445980072
Mean Now:  67.34809875488281  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.4656445980072
Mean Now:  67.34809875488281  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.4656445980072
Mean Now:  67.34809875488281  Best Mean Before:  69.44918 --------------------
Train Epoch: [183][0/8]	Loss 0.4426 (0.4426)	LossFusion 0.4426 (0.4426)	
Train Epoch: [183][0/8]	Loss 0.4426 (0.4426)	LossFusion 0.4426 (0.4426)	
Train Epoch: [183][0/8]	Loss 0.4426 (0.4426)	LossFusion 0.4426 (0.4426)	
Train Epoch: [183][0/8]	Loss 0.4426 (0.4426)	LossFusion 0.4426 (0.4426)	
Train Epoch: [183][0/8]	Loss 0.4426 (0.4426)	LossFusion 0.4426 (0.4426)	
Train Epoch: [183][0/8]	Loss 0.4426 (0.4426)	LossFusion 0.4426 (0.4426)	
Train Epoch: [183][0/8]	Loss 0.4426 (0.4426)	LossFusion 0.4426 (0.4426)	
Train Epoch: [183][0/8]	Loss 0.4426 (0.4426)	LossFusion 0.4426 (0.4426)	
Train Epoch: [183][7/8]	Loss 0.2292 (0.3153)	LossFusion 0.2292 (0.3153)	
Train Epoch: [183][7/8]	Loss 0.2292 (0.3153)	LossFusion 0.2292 (0.3153)	
Train Epoch: [183][7/8]	Loss 0.2292 (0.3153)	LossFusion 0.2292 (0.3153)	
Train Epoch: [183][7/8]	Loss 0.2292 (0.3153)	LossFusion 0.2292 (0.3153)	
Train Epoch: [183][7/8]	Loss 0.2292 (0.3153)	LossFusion 0.2292 (0.3153)	
Train Epoch: [183][7/8]	Loss 0.2292 (0.3153)	LossFusion 0.2292 (0.3153)	
Train Epoch: [183][7/8]	Loss 0.2292 (0.3153)	LossFusion 0.2292 (0.3153)	Train Epoch: [183][7/8]	Loss 0.2292 (0.3153)	LossFusion 0.2292 (0.3153)	

R@10:  54.74162697792053     R@50:  80.52242994308472
Mean Now:  67.63202846050262  Best Mean Before:  69.44918 --------------------
R@10:  54.74162697792053     R@50:  80.52242994308472
Mean Now:  67.63202846050262  Best Mean Before:  69.44918 --------------------
R@10:  54.74162697792053     R@50:  80.52242994308472
Mean Now:  67.63202846050262  Best Mean Before:  69.44918 --------------------
R@10:  54.74162697792053     R@50:  80.52242994308472
Mean Now:  67.63202846050262  Best Mean Before:  69.44918 --------------------
R@10:  54.74162697792053     R@50:  80.52242994308472
Mean Now:  67.63202846050262  Best Mean Before:  69.44918 --------------------
R@10:  54.74162697792053     R@50:  80.52242994308472
Mean Now:  67.63202846050262  Best Mean Before:  69.44918 --------------------
R@10:  54.74162697792053     R@50:  80.52242994308472
Mean Now:  67.63202846050262  Best Mean Before:  69.44918 --------------------
R@10:  54.74162697792053     R@50:  80.52242994308472
Mean Now:  67.63202846050262  Best Mean Before:  69.44918 --------------------
Train Epoch: [184][0/8]	Loss 0.4373 (0.4373)	LossFusion 0.4373 (0.4373)	
Train Epoch: [184][0/8]	Loss 0.4373 (0.4373)	LossFusion 0.4373 (0.4373)	
Train Epoch: [184][0/8]	Loss 0.4373 (0.4373)	LossFusion 0.4373 (0.4373)	
Train Epoch: [184][0/8]	Loss 0.4373 (0.4373)	LossFusion 0.4373 (0.4373)	
Train Epoch: [184][0/8]	Loss 0.4373 (0.4373)	LossFusion 0.4373 (0.4373)	
Train Epoch: [184][0/8]	Loss 0.4373 (0.4373)	LossFusion 0.4373 (0.4373)	
Train Epoch: [184][0/8]	Loss 0.4373 (0.4373)	LossFusion 0.4373 (0.4373)	
Train Epoch: [184][0/8]	Loss 0.4373 (0.4373)	LossFusion 0.4373 (0.4373)	
Train Epoch: [184][7/8]	Loss 0.2256 (0.3016)	LossFusion 0.2256 (0.3016)	
Train Epoch: [184][7/8]	Loss 0.2256 (0.3016)	LossFusion 0.2256 (0.3016)	
Train Epoch: [184][7/8]	Loss 0.2256 (0.3016)	LossFusion 0.2256 (0.3016)	
Train Epoch: [184][7/8]	Loss 0.2256 (0.3016)	LossFusion 0.2256 (0.3016)	
Train Epoch: [184][7/8]	Loss 0.2256 (0.3016)	LossFusion 0.2256 (0.3016)	
Train Epoch: [184][7/8]	Loss 0.2256 (0.3016)	LossFusion 0.2256 (0.3016)	
Train Epoch: [184][7/8]	Loss 0.2256 (0.3016)	LossFusion 0.2256 (0.3016)	
Train Epoch: [184][7/8]	Loss 0.2256 (0.3016)	LossFusion 0.2256 (0.3016)	
R@10:  54.17376756668091     R@50:  81.14707469940186
Mean Now:  67.66042113304138  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  81.14707469940186
Mean Now:  67.66042113304138  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  81.14707469940186
Mean Now:  67.66042113304138  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  81.14707469940186
Mean Now:  67.66042113304138  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  81.14707469940186
Mean Now:  67.66042113304138  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  81.14707469940186
Mean Now:  67.66042113304138  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  81.14707469940186
Mean Now:  67.66042113304138  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  81.14707469940186
Mean Now:  67.66042113304138  Best Mean Before:  69.44918 --------------------
Train Epoch: [185][0/8]	Loss 0.4807 (0.4807)	LossFusion 0.4807 (0.4807)	
Train Epoch: [185][0/8]	Loss 0.4807 (0.4807)	LossFusion 0.4807 (0.4807)	
Train Epoch: [185][0/8]	Loss 0.4807 (0.4807)	LossFusion 0.4807 (0.4807)	
Train Epoch: [185][0/8]	Loss 0.4807 (0.4807)	LossFusion 0.4807 (0.4807)	
Train Epoch: [185][0/8]	Loss 0.4807 (0.4807)	LossFusion 0.4807 (0.4807)	
Train Epoch: [185][0/8]	Loss 0.4807 (0.4807)	LossFusion 0.4807 (0.4807)	
Train Epoch: [185][0/8]	Loss 0.4807 (0.4807)	LossFusion 0.4807 (0.4807)	
Train Epoch: [185][0/8]	Loss 0.4807 (0.4807)	LossFusion 0.4807 (0.4807)	
Train Epoch: [185][7/8]	Loss 0.2303 (0.3121)	LossFusion 0.2303 (0.3121)	
Train Epoch: [185][7/8]	Loss 0.2303 (0.3121)	LossFusion 0.2303 (0.3121)	
Train Epoch: [185][7/8]	Loss 0.2303 (0.3121)	LossFusion 0.2303 (0.3121)	
Train Epoch: [185][7/8]	Loss 0.2303 (0.3121)	LossFusion 0.2303 (0.3121)	
Train Epoch: [185][7/8]	Loss 0.2303 (0.3121)	LossFusion 0.2303 (0.3121)	
Train Epoch: [185][7/8]	Loss 0.2303 (0.3121)	LossFusion 0.2303 (0.3121)	
Train Epoch: [185][7/8]	Loss 0.2303 (0.3121)	LossFusion 0.2303 (0.3121)	
Train Epoch: [185][7/8]	Loss 0.2303 (0.3121)	LossFusion 0.2303 (0.3121)	
R@10:  54.0601909160614     R@50:  80.69278597831726
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.69278597831726
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.69278597831726
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.69278597831726
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.69278597831726
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.69278597831726
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.69278597831726
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.69278597831726
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
Train Epoch: [186][0/8]	Loss 0.4455 (0.4455)	LossFusion 0.4455 (0.4455)	
Train Epoch: [186][0/8]	Loss 0.4455 (0.4455)	LossFusion 0.4455 (0.4455)	
Train Epoch: [186][0/8]	Loss 0.4455 (0.4455)	LossFusion 0.4455 (0.4455)	
Train Epoch: [186][0/8]	Loss 0.4455 (0.4455)	LossFusion 0.4455 (0.4455)	
Train Epoch: [186][0/8]	Loss 0.4455 (0.4455)	LossFusion 0.4455 (0.4455)	
Train Epoch: [186][0/8]	Loss 0.4455 (0.4455)	LossFusion 0.4455 (0.4455)	
Train Epoch: [186][0/8]	Loss 0.4455 (0.4455)	LossFusion 0.4455 (0.4455)	
Train Epoch: [186][0/8]	Loss 0.4455 (0.4455)	LossFusion 0.4455 (0.4455)	
Train Epoch: [186][7/8]	Loss 0.2281 (0.2963)	LossFusion 0.2281 (0.2963)	Train Epoch: [186][7/8]	Loss 0.2281 (0.2963)	LossFusion 0.2281 (0.2963)	

Train Epoch: [186][7/8]	Loss 0.2281 (0.2963)	LossFusion 0.2281 (0.2963)	
Train Epoch: [186][7/8]	Loss 0.2281 (0.2963)	LossFusion 0.2281 (0.2963)	
Train Epoch: [186][7/8]	Loss 0.2281 (0.2963)	LossFusion 0.2281 (0.2963)	
Train Epoch: [186][7/8]	Loss 0.2281 (0.2963)	LossFusion 0.2281 (0.2963)	
Train Epoch: [186][7/8]	Loss 0.2281 (0.2963)	LossFusion 0.2281 (0.2963)	
Train Epoch: [186][7/8]	Loss 0.2281 (0.2963)	LossFusion 0.2281 (0.2963)	
R@10:  53.94662022590637     R@50:  80.63600063323975
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.63600063323975
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.63600063323975
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.63600063323975
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.63600063323975
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.63600063323975
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.63600063323975
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.63600063323975
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
Train Epoch: [187][0/8]	Loss 0.4670 (0.4670)	LossFusion 0.4670 (0.4670)	
Train Epoch: [187][0/8]	Loss 0.4670 (0.4670)	LossFusion 0.4670 (0.4670)	
Train Epoch: [187][0/8]	Loss 0.4670 (0.4670)	LossFusion 0.4670 (0.4670)	
Train Epoch: [187][0/8]	Loss 0.4670 (0.4670)	LossFusion 0.4670 (0.4670)	
Train Epoch: [187][0/8]	Loss 0.4670 (0.4670)	LossFusion 0.4670 (0.4670)	
Train Epoch: [187][0/8]	Loss 0.4670 (0.4670)	LossFusion 0.4670 (0.4670)	
Train Epoch: [187][0/8]	Loss 0.4670 (0.4670)	LossFusion 0.4670 (0.4670)	
Train Epoch: [187][0/8]	Loss 0.4670 (0.4670)	LossFusion 0.4670 (0.4670)	
Train Epoch: [187][7/8]	Loss 0.2312 (0.3038)	LossFusion 0.2312 (0.3038)	
Train Epoch: [187][7/8]	Loss 0.2312 (0.3038)	LossFusion 0.2312 (0.3038)	
Train Epoch: [187][7/8]	Loss 0.2312 (0.3038)	LossFusion 0.2312 (0.3038)	
Train Epoch: [187][7/8]	Loss 0.2312 (0.3038)	LossFusion 0.2312 (0.3038)	
Train Epoch: [187][7/8]	Loss 0.2312 (0.3038)	LossFusion 0.2312 (0.3038)	
Train Epoch: [187][7/8]	Loss 0.2312 (0.3038)	LossFusion 0.2312 (0.3038)	
Train Epoch: [187][7/8]	Loss 0.2312 (0.3038)	LossFusion 0.2312 (0.3038)	
Train Epoch: [187][7/8]	Loss 0.2312 (0.3038)	LossFusion 0.2312 (0.3038)	
R@10:  54.28733825683594     R@50:  80.69278597831726
Mean Now:  67.4900621175766  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.69278597831726
Mean Now:  67.4900621175766  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.69278597831726
Mean Now:  67.4900621175766  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.69278597831726
Mean Now:  67.4900621175766  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.69278597831726
Mean Now:  67.4900621175766  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.69278597831726
Mean Now:  67.4900621175766  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.69278597831726
Mean Now:  67.4900621175766  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.69278597831726
Mean Now:  67.4900621175766  Best Mean Before:  69.44918 --------------------
Train Epoch: [188][0/8]	Loss 0.4136 (0.4136)	LossFusion 0.4136 (0.4136)	
Train Epoch: [188][0/8]	Loss 0.4136 (0.4136)	LossFusion 0.4136 (0.4136)	
Train Epoch: [188][0/8]	Loss 0.4136 (0.4136)	LossFusion 0.4136 (0.4136)	
Train Epoch: [188][0/8]	Loss 0.4136 (0.4136)	LossFusion 0.4136 (0.4136)	
Train Epoch: [188][0/8]	Loss 0.4136 (0.4136)	LossFusion 0.4136 (0.4136)	
Train Epoch: [188][0/8]	Loss 0.4136 (0.4136)	LossFusion 0.4136 (0.4136)	
Train Epoch: [188][0/8]	Loss 0.4136 (0.4136)	LossFusion 0.4136 (0.4136)	
Train Epoch: [188][0/8]	Loss 0.4136 (0.4136)	LossFusion 0.4136 (0.4136)	
Train Epoch: [188][7/8]	Loss 0.2430 (0.2903)	LossFusion 0.2430 (0.2903)	
Train Epoch: [188][7/8]	Loss 0.2430 (0.2903)	LossFusion 0.2430 (0.2903)	
Train Epoch: [188][7/8]	Loss 0.2430 (0.2903)	LossFusion 0.2430 (0.2903)	
Train Epoch: [188][7/8]	Loss 0.2430 (0.2903)	LossFusion 0.2430 (0.2903)	
Train Epoch: [188][7/8]	Loss 0.2430 (0.2903)	LossFusion 0.2430 (0.2903)	
Train Epoch: [188][7/8]	Loss 0.2430 (0.2903)	LossFusion 0.2430 (0.2903)	
Train Epoch: [188][7/8]	Loss 0.2430 (0.2903)	LossFusion 0.2430 (0.2903)	
Train Epoch: [188][7/8]	Loss 0.2430 (0.2903)	LossFusion 0.2430 (0.2903)	
R@10:  54.68483567237854     R@50:  80.35207390785217
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.35207390785217
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.35207390785217
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.35207390785217
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.35207390785217
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.35207390785217
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.35207390785217
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.35207390785217
Mean Now:  67.51845479011536  Best Mean Before:  69.44918 --------------------
Train Epoch: [189][0/8]	Loss 0.4312 (0.4312)	LossFusion 0.4312 (0.4312)	
Train Epoch: [189][0/8]	Loss 0.4312 (0.4312)	LossFusion 0.4312 (0.4312)	
Train Epoch: [189][0/8]	Loss 0.4312 (0.4312)	LossFusion 0.4312 (0.4312)	
Train Epoch: [189][0/8]	Loss 0.4312 (0.4312)	LossFusion 0.4312 (0.4312)	
Train Epoch: [189][0/8]	Loss 0.4312 (0.4312)	LossFusion 0.4312 (0.4312)	
Train Epoch: [189][0/8]	Loss 0.4312 (0.4312)	LossFusion 0.4312 (0.4312)	
Train Epoch: [189][0/8]	Loss 0.4312 (0.4312)	LossFusion 0.4312 (0.4312)	
Train Epoch: [189][0/8]	Loss 0.4312 (0.4312)	LossFusion 0.4312 (0.4312)	
Train Epoch: [189][7/8]	Loss 0.2070 (0.2960)	LossFusion 0.2070 (0.2960)	
Train Epoch: [189][7/8]	Loss 0.2070 (0.2960)	LossFusion 0.2070 (0.2960)	
Train Epoch: [189][7/8]	Loss 0.2070 (0.2960)	LossFusion 0.2070 (0.2960)	
Train Epoch: [189][7/8]	Loss 0.2070 (0.2960)	LossFusion 0.2070 (0.2960)	
Train Epoch: [189][7/8]	Loss 0.2070 (0.2960)	LossFusion 0.2070 (0.2960)	
Train Epoch: [189][7/8]	Loss 0.2070 (0.2960)	LossFusion 0.2070 (0.2960)	
Train Epoch: [189][7/8]	Loss 0.2070 (0.2960)	LossFusion 0.2070 (0.2960)	
Train Epoch: [189][7/8]	Loss 0.2070 (0.2960)	LossFusion 0.2070 (0.2960)	
R@10:  54.45769429206848     R@50:  80.4656445980072
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.4656445980072
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.4656445980072
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.4656445980072
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.4656445980072
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.4656445980072
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.4656445980072
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.4656445980072
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
Train Epoch: [190][0/8]	Loss 0.4115 (0.4115)	LossFusion 0.4115 (0.4115)	
Train Epoch: [190][0/8]	Loss 0.4115 (0.4115)	LossFusion 0.4115 (0.4115)	
Train Epoch: [190][0/8]	Loss 0.4115 (0.4115)	LossFusion 0.4115 (0.4115)	
Train Epoch: [190][0/8]	Loss 0.4115 (0.4115)	LossFusion 0.4115 (0.4115)	
Train Epoch: [190][0/8]	Loss 0.4115 (0.4115)	LossFusion 0.4115 (0.4115)	
Train Epoch: [190][0/8]	Loss 0.4115 (0.4115)	LossFusion 0.4115 (0.4115)	
Train Epoch: [190][0/8]	Loss 0.4115 (0.4115)	LossFusion 0.4115 (0.4115)	
Train Epoch: [190][0/8]	Loss 0.4115 (0.4115)	LossFusion 0.4115 (0.4115)	
Train Epoch: [190][7/8]	Loss 0.2247 (0.2873)	LossFusion 0.2247 (0.2873)	
Train Epoch: [190][7/8]	Loss 0.2247 (0.2873)	LossFusion 0.2247 (0.2873)	
Train Epoch: [190][7/8]	Loss 0.2247 (0.2873)	LossFusion 0.2247 (0.2873)	
Train Epoch: [190][7/8]	Loss 0.2247 (0.2873)	LossFusion 0.2247 (0.2873)	
Train Epoch: [190][7/8]	Loss 0.2247 (0.2873)	LossFusion 0.2247 (0.2873)	
Train Epoch: [190][7/8]	Loss 0.2247 (0.2873)	LossFusion 0.2247 (0.2873)	
Train Epoch: [190][7/8]	Loss 0.2247 (0.2873)	LossFusion 0.2247 (0.2873)	
Train Epoch: [190][7/8]	Loss 0.2247 (0.2873)	LossFusion 0.2247 (0.2873)	
R@10:  54.628050327301025     R@50:  80.86314797401428
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.628050327301025     R@50:  80.86314797401428
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.628050327301025     R@50:  80.86314797401428
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.628050327301025     R@50:  80.86314797401428
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.628050327301025     R@50:  80.86314797401428
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.628050327301025     R@50:  80.86314797401428
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.628050327301025     R@50:  80.86314797401428
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
R@10:  54.628050327301025     R@50:  80.86314797401428
Mean Now:  67.74559915065765  Best Mean Before:  69.44918 --------------------
Train Epoch: [191][0/8]	Loss 0.3880 (0.3880)	LossFusion 0.3880 (0.3880)	
Train Epoch: [191][0/8]	Loss 0.3880 (0.3880)	LossFusion 0.3880 (0.3880)	
Train Epoch: [191][0/8]	Loss 0.3880 (0.3880)	LossFusion 0.3880 (0.3880)	
Train Epoch: [191][0/8]	Loss 0.3880 (0.3880)	LossFusion 0.3880 (0.3880)	
Train Epoch: [191][0/8]	Loss 0.3880 (0.3880)	LossFusion 0.3880 (0.3880)	
Train Epoch: [191][0/8]	Loss 0.3880 (0.3880)	LossFusion 0.3880 (0.3880)	
Train Epoch: [191][0/8]	Loss 0.3880 (0.3880)	LossFusion 0.3880 (0.3880)	
Train Epoch: [191][0/8]	Loss 0.3880 (0.3880)	LossFusion 0.3880 (0.3880)	
Train Epoch: [191][7/8]	Loss 0.2058 (0.2771)	LossFusion 0.2058 (0.2771)	
Train Epoch: [191][7/8]	Loss 0.2058 (0.2771)	LossFusion 0.2058 (0.2771)	
Train Epoch: [191][7/8]	Loss 0.2058 (0.2771)	LossFusion 0.2058 (0.2771)	
Train Epoch: [191][7/8]	Loss 0.2058 (0.2771)	LossFusion 0.2058 (0.2771)	
Train Epoch: [191][7/8]	Loss 0.2058 (0.2771)	LossFusion 0.2058 (0.2771)	
Train Epoch: [191][7/8]	Loss 0.2058 (0.2771)	LossFusion 0.2058 (0.2771)	
Train Epoch: [191][7/8]	Loss 0.2058 (0.2771)	LossFusion 0.2058 (0.2771)	Train Epoch: [191][7/8]	Loss 0.2058 (0.2771)	LossFusion 0.2058 (0.2771)	

R@10:  53.6626935005188     R@50:  80.69278597831726
Mean Now:  67.17773973941803  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.69278597831726
Mean Now:  67.17773973941803  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.69278597831726
Mean Now:  67.17773973941803  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.69278597831726
Mean Now:  67.17773973941803  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.69278597831726
Mean Now:  67.17773973941803  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.69278597831726
Mean Now:  67.17773973941803  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.69278597831726
Mean Now:  67.17773973941803  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.69278597831726
Mean Now:  67.17773973941803  Best Mean Before:  69.44918 --------------------
Train Epoch: [192][0/8]	Loss 0.4101 (0.4101)	LossFusion 0.4101 (0.4101)	
Train Epoch: [192][0/8]	Loss 0.4101 (0.4101)	LossFusion 0.4101 (0.4101)	
Train Epoch: [192][0/8]	Loss 0.4101 (0.4101)	LossFusion 0.4101 (0.4101)	
Train Epoch: [192][0/8]	Loss 0.4101 (0.4101)	LossFusion 0.4101 (0.4101)	
Train Epoch: [192][0/8]	Loss 0.4101 (0.4101)	LossFusion 0.4101 (0.4101)	
Train Epoch: [192][0/8]	Loss 0.4101 (0.4101)	LossFusion 0.4101 (0.4101)	
Train Epoch: [192][0/8]	Loss 0.4101 (0.4101)	LossFusion 0.4101 (0.4101)	
Train Epoch: [192][0/8]	Loss 0.4101 (0.4101)	LossFusion 0.4101 (0.4101)	
Train Epoch: [192][7/8]	Loss 0.2036 (0.2782)	LossFusion 0.2036 (0.2782)	
Train Epoch: [192][7/8]	Loss 0.2036 (0.2782)	LossFusion 0.2036 (0.2782)	
Train Epoch: [192][7/8]	Loss 0.2036 (0.2782)	LossFusion 0.2036 (0.2782)	
Train Epoch: [192][7/8]	Loss 0.2036 (0.2782)	LossFusion 0.2036 (0.2782)	
Train Epoch: [192][7/8]	Loss 0.2036 (0.2782)	LossFusion 0.2036 (0.2782)	
Train Epoch: [192][7/8]	Loss 0.2036 (0.2782)	LossFusion 0.2036 (0.2782)	
Train Epoch: [192][7/8]	Loss 0.2036 (0.2782)	LossFusion 0.2036 (0.2782)	
Train Epoch: [192][7/8]	Loss 0.2036 (0.2782)	LossFusion 0.2036 (0.2782)	
R@10:  54.45769429206848     R@50:  79.95457053184509
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  79.95457053184509
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  79.95457053184509
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  79.95457053184509
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  79.95457053184509
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  79.95457053184509
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  79.95457053184509
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  79.95457053184509
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
Train Epoch: [193][0/8]	Loss 0.4218 (0.4218)	LossFusion 0.4218 (0.4218)	
Train Epoch: [193][0/8]	Loss 0.4218 (0.4218)	LossFusion 0.4218 (0.4218)	
Train Epoch: [193][0/8]	Loss 0.4218 (0.4218)	LossFusion 0.4218 (0.4218)	
Train Epoch: [193][0/8]	Loss 0.4218 (0.4218)	LossFusion 0.4218 (0.4218)	
Train Epoch: [193][0/8]	Loss 0.4218 (0.4218)	LossFusion 0.4218 (0.4218)	
Train Epoch: [193][0/8]	Loss 0.4218 (0.4218)	LossFusion 0.4218 (0.4218)	
Train Epoch: [193][0/8]	Loss 0.4218 (0.4218)	LossFusion 0.4218 (0.4218)	
Train Epoch: [193][0/8]	Loss 0.4218 (0.4218)	LossFusion 0.4218 (0.4218)	
Train Epoch: [193][7/8]	Loss 0.2060 (0.2773)	LossFusion 0.2060 (0.2773)	
Train Epoch: [193][7/8]	Loss 0.2060 (0.2773)	LossFusion 0.2060 (0.2773)	
Train Epoch: [193][7/8]	Loss 0.2060 (0.2773)	LossFusion 0.2060 (0.2773)	
Train Epoch: [193][7/8]	Loss 0.2060 (0.2773)	LossFusion 0.2060 (0.2773)	
Train Epoch: [193][7/8]	Loss 0.2060 (0.2773)	LossFusion 0.2060 (0.2773)	
Train Epoch: [193][7/8]	Loss 0.2060 (0.2773)	LossFusion 0.2060 (0.2773)	
Train Epoch: [193][7/8]	Loss 0.2060 (0.2773)	LossFusion 0.2060 (0.2773)	
Train Epoch: [193][7/8]	Loss 0.2060 (0.2773)	LossFusion 0.2060 (0.2773)	
R@10:  55.08233904838562     R@50:  80.86314797401428
Mean Now:  67.97274351119995  Best Mean Before:  69.44918 --------------------
R@10:  55.08233904838562     R@50:  80.86314797401428
Mean Now:  67.97274351119995  Best Mean Before:  69.44918 --------------------
R@10:  55.08233904838562     R@50:  80.86314797401428
Mean Now:  67.97274351119995  Best Mean Before:  69.44918 --------------------
R@10:  55.08233904838562     R@50:  80.86314797401428
Mean Now:  67.97274351119995  Best Mean Before:  69.44918 --------------------
R@10:  55.08233904838562     R@50:  80.86314797401428
Mean Now:  67.97274351119995  Best Mean Before:  69.44918 --------------------
R@10:  55.08233904838562     R@50:  80.86314797401428
Mean Now:  67.97274351119995  Best Mean Before:  69.44918 --------------------
R@10:  55.08233904838562     R@50:  80.86314797401428
Mean Now:  67.97274351119995  Best Mean Before:  69.44918 --------------------
R@10:  55.08233904838562     R@50:  80.86314797401428
Mean Now:  67.97274351119995  Best Mean Before:  69.44918 --------------------
Train Epoch: [194][0/8]	Loss 0.4038 (0.4038)	LossFusion 0.4038 (0.4038)	
Train Epoch: [194][0/8]	Loss 0.4038 (0.4038)	LossFusion 0.4038 (0.4038)	
Train Epoch: [194][0/8]	Loss 0.4038 (0.4038)	LossFusion 0.4038 (0.4038)	
Train Epoch: [194][0/8]	Loss 0.4038 (0.4038)	LossFusion 0.4038 (0.4038)	
Train Epoch: [194][0/8]	Loss 0.4038 (0.4038)	LossFusion 0.4038 (0.4038)	
Train Epoch: [194][0/8]	Loss 0.4038 (0.4038)	LossFusion 0.4038 (0.4038)	
Train Epoch: [194][0/8]	Loss 0.4038 (0.4038)	LossFusion 0.4038 (0.4038)	
Train Epoch: [194][0/8]	Loss 0.4038 (0.4038)	LossFusion 0.4038 (0.4038)	
Train Epoch: [194][7/8]	Loss 0.2299 (0.2776)	LossFusion 0.2299 (0.2776)	
Train Epoch: [194][7/8]	Loss 0.2299 (0.2776)	LossFusion 0.2299 (0.2776)	Train Epoch: [194][7/8]	Loss 0.2299 (0.2776)	LossFusion 0.2299 (0.2776)	

Train Epoch: [194][7/8]	Loss 0.2299 (0.2776)	LossFusion 0.2299 (0.2776)	
Train Epoch: [194][7/8]	Loss 0.2299 (0.2776)	LossFusion 0.2299 (0.2776)	
Train Epoch: [194][7/8]	Loss 0.2299 (0.2776)	LossFusion 0.2299 (0.2776)	
Train Epoch: [194][7/8]	Loss 0.2299 (0.2776)	LossFusion 0.2299 (0.2776)	Train Epoch: [194][7/8]	Loss 0.2299 (0.2776)	LossFusion 0.2299 (0.2776)	

R@10:  54.45769429206848     R@50:  80.12492656707764
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.12492656707764
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.12492656707764
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.12492656707764
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.12492656707764
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.12492656707764
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.12492656707764
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.45769429206848     R@50:  80.12492656707764
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
Train Epoch: [195][0/8]	Loss 0.3820 (0.3820)	LossFusion 0.3820 (0.3820)	
Train Epoch: [195][0/8]	Loss 0.3820 (0.3820)	LossFusion 0.3820 (0.3820)	
Train Epoch: [195][0/8]	Loss 0.3820 (0.3820)	LossFusion 0.3820 (0.3820)	
Train Epoch: [195][0/8]	Loss 0.3820 (0.3820)	LossFusion 0.3820 (0.3820)	
Train Epoch: [195][0/8]	Loss 0.3820 (0.3820)	LossFusion 0.3820 (0.3820)	
Train Epoch: [195][0/8]	Loss 0.3820 (0.3820)	LossFusion 0.3820 (0.3820)	
Train Epoch: [195][0/8]	Loss 0.3820 (0.3820)	LossFusion 0.3820 (0.3820)	
Train Epoch: [195][0/8]	Loss 0.3820 (0.3820)	LossFusion 0.3820 (0.3820)	
Train Epoch: [195][7/8]	Loss 0.1985 (0.2642)	LossFusion 0.1985 (0.2642)	
Train Epoch: [195][7/8]	Loss 0.1985 (0.2642)	LossFusion 0.1985 (0.2642)	
Train Epoch: [195][7/8]	Loss 0.1985 (0.2642)	LossFusion 0.1985 (0.2642)	
Train Epoch: [195][7/8]	Loss 0.1985 (0.2642)	LossFusion 0.1985 (0.2642)	
Train Epoch: [195][7/8]	Loss 0.1985 (0.2642)	LossFusion 0.1985 (0.2642)	
Train Epoch: [195][7/8]	Loss 0.1985 (0.2642)	LossFusion 0.1985 (0.2642)	
Train Epoch: [195][7/8]	Loss 0.1985 (0.2642)	LossFusion 0.1985 (0.2642)	
Train Epoch: [195][7/8]	Loss 0.1985 (0.2642)	LossFusion 0.1985 (0.2642)	
R@10:  55.4798424243927     R@50:  80.97671866416931
Mean Now:  68.228280544281  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  80.97671866416931
Mean Now:  68.228280544281  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  80.97671866416931
Mean Now:  68.228280544281  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  80.97671866416931
Mean Now:  68.228280544281  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  80.97671866416931
Mean Now:  68.228280544281  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  80.97671866416931
Mean Now:  68.228280544281  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  80.97671866416931
Mean Now:  68.228280544281  Best Mean Before:  69.44918 --------------------
R@10:  55.4798424243927     R@50:  80.97671866416931
Mean Now:  68.228280544281  Best Mean Before:  69.44918 --------------------
Train Epoch: [196][0/8]	Loss 0.3850 (0.3850)	LossFusion 0.3850 (0.3850)	
Train Epoch: [196][0/8]	Loss 0.3850 (0.3850)	LossFusion 0.3850 (0.3850)	
Train Epoch: [196][0/8]	Loss 0.3850 (0.3850)	LossFusion 0.3850 (0.3850)	Train Epoch: [196][0/8]	Loss 0.3850 (0.3850)	LossFusion 0.3850 (0.3850)	

Train Epoch: [196][0/8]	Loss 0.3850 (0.3850)	LossFusion 0.3850 (0.3850)	
Train Epoch: [196][0/8]	Loss 0.3850 (0.3850)	LossFusion 0.3850 (0.3850)	
Train Epoch: [196][0/8]	Loss 0.3850 (0.3850)	LossFusion 0.3850 (0.3850)	
Train Epoch: [196][0/8]	Loss 0.3850 (0.3850)	LossFusion 0.3850 (0.3850)	
Train Epoch: [196][7/8]	Loss 0.2195 (0.2618)	LossFusion 0.2195 (0.2618)	Train Epoch: [196][7/8]	Loss 0.2195 (0.2618)	LossFusion 0.2195 (0.2618)	
Train Epoch: [196][7/8]	Loss 0.2195 (0.2618)	LossFusion 0.2195 (0.2618)	

Train Epoch: [196][7/8]	Loss 0.2195 (0.2618)	LossFusion 0.2195 (0.2618)	
Train Epoch: [196][7/8]	Loss 0.2195 (0.2618)	LossFusion 0.2195 (0.2618)	
Train Epoch: [196][7/8]	Loss 0.2195 (0.2618)	LossFusion 0.2195 (0.2618)	
Train Epoch: [196][7/8]	Loss 0.2195 (0.2618)	LossFusion 0.2195 (0.2618)	
Train Epoch: [196][7/8]	Loss 0.2195 (0.2618)	LossFusion 0.2195 (0.2618)	
R@10:  54.68483567237854     R@50:  80.23850321769714
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.23850321769714
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.23850321769714
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.23850321769714
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.23850321769714
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.23850321769714
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.23850321769714
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
R@10:  54.68483567237854     R@50:  80.23850321769714
Mean Now:  67.46166944503784  Best Mean Before:  69.44918 --------------------
Train Epoch: [197][0/8]	Loss 0.3941 (0.3941)	LossFusion 0.3941 (0.3941)	
Train Epoch: [197][0/8]	Loss 0.3941 (0.3941)	LossFusion 0.3941 (0.3941)	
Train Epoch: [197][0/8]	Loss 0.3941 (0.3941)	LossFusion 0.3941 (0.3941)	
Train Epoch: [197][0/8]	Loss 0.3941 (0.3941)	LossFusion 0.3941 (0.3941)	
Train Epoch: [197][0/8]	Loss 0.3941 (0.3941)	LossFusion 0.3941 (0.3941)	
Train Epoch: [197][0/8]	Loss 0.3941 (0.3941)	LossFusion 0.3941 (0.3941)	
Train Epoch: [197][0/8]	Loss 0.3941 (0.3941)	LossFusion 0.3941 (0.3941)	
Train Epoch: [197][0/8]	Loss 0.3941 (0.3941)	LossFusion 0.3941 (0.3941)	
Train Epoch: [197][7/8]	Loss 0.2094 (0.2548)	LossFusion 0.2094 (0.2548)	
Train Epoch: [197][7/8]	Loss 0.2094 (0.2548)	LossFusion 0.2094 (0.2548)	
Train Epoch: [197][7/8]	Loss 0.2094 (0.2548)	LossFusion 0.2094 (0.2548)	
Train Epoch: [197][7/8]	Loss 0.2094 (0.2548)	LossFusion 0.2094 (0.2548)	
Train Epoch: [197][7/8]	Loss 0.2094 (0.2548)	LossFusion 0.2094 (0.2548)	
Train Epoch: [197][7/8]	Loss 0.2094 (0.2548)	LossFusion 0.2094 (0.2548)	
Train Epoch: [197][7/8]	Loss 0.2094 (0.2548)	LossFusion 0.2094 (0.2548)	
Train Epoch: [197][7/8]	Loss 0.2094 (0.2548)	LossFusion 0.2094 (0.2548)	
R@10:  53.88983488082886     R@50:  80.52242994308472
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  R@10: 53.88983488082886      R@50:  80.5224299430847253.88983488082886
     R@50:  80.52242994308472Mean Now: 
 67.20613241195679  Best Mean Before: Mean Now:   69.4491867.20613241195679  -------------------- Best Mean Before: 
 69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.52242994308472
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.52242994308472
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.52242994308472
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.52242994308472
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.52242994308472
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
Train Epoch: [198][0/8]	Loss 0.3789 (0.3789)	LossFusion 0.3789 (0.3789)	
Train Epoch: [198][0/8]	Loss 0.3789 (0.3789)	LossFusion 0.3789 (0.3789)	
Train Epoch: [198][0/8]	Loss 0.3789 (0.3789)	LossFusion 0.3789 (0.3789)	
Train Epoch: [198][0/8]	Loss 0.3789 (0.3789)	LossFusion 0.3789 (0.3789)	
Train Epoch: [198][0/8]	Loss 0.3789 (0.3789)	LossFusion 0.3789 (0.3789)	
Train Epoch: [198][0/8]	Loss 0.3789 (0.3789)	LossFusion 0.3789 (0.3789)	
Train Epoch: [198][0/8]	Loss 0.3789 (0.3789)	LossFusion 0.3789 (0.3789)	
Train Epoch: [198][0/8]	Loss 0.3789 (0.3789)	LossFusion 0.3789 (0.3789)	
Train Epoch: [198][7/8]	Loss 0.2070 (0.2555)	LossFusion 0.2070 (0.2555)	
Train Epoch: [198][7/8]	Loss 0.2070 (0.2555)	LossFusion 0.2070 (0.2555)	
Train Epoch: [198][7/8]	Loss 0.2070 (0.2555)	LossFusion 0.2070 (0.2555)	
Train Epoch: [198][7/8]	Loss 0.2070 (0.2555)	LossFusion 0.2070 (0.2555)	
Train Epoch: [198][7/8]	Loss 0.2070 (0.2555)	LossFusion 0.2070 (0.2555)	
Train Epoch: [198][7/8]	Loss 0.2070 (0.2555)	LossFusion 0.2070 (0.2555)	
Train Epoch: [198][7/8]	Loss 0.2070 (0.2555)	LossFusion 0.2070 (0.2555)	
Train Epoch: [198][7/8]	Loss 0.2070 (0.2555)	LossFusion 0.2070 (0.2555)	
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
Train Epoch: [199][0/8]	Loss 0.3832 (0.3832)	LossFusion 0.3832 (0.3832)	
Train Epoch: [199][0/8]	Loss 0.3832 (0.3832)	LossFusion 0.3832 (0.3832)	
Train Epoch: [199][0/8]	Loss 0.3832 (0.3832)	LossFusion 0.3832 (0.3832)	
Train Epoch: [199][0/8]	Loss 0.3832 (0.3832)	LossFusion 0.3832 (0.3832)	
Train Epoch: [199][0/8]	Loss 0.3832 (0.3832)	LossFusion 0.3832 (0.3832)	
Train Epoch: [199][0/8]	Loss 0.3832 (0.3832)	LossFusion 0.3832 (0.3832)	Train Epoch: [199][0/8]	Loss 0.3832 (0.3832)	LossFusion 0.3832 (0.3832)	

Train Epoch: [199][0/8]	Loss 0.3832 (0.3832)	LossFusion 0.3832 (0.3832)	
Train Epoch: [199][7/8]	Loss 0.2007 (0.2537)	LossFusion 0.2007 (0.2537)	
Train Epoch: [199][7/8]	Loss 0.2007 (0.2537)	LossFusion 0.2007 (0.2537)	
Train Epoch: [199][7/8]	Loss 0.2007 (0.2537)	LossFusion 0.2007 (0.2537)	
Train Epoch: [199][7/8]	Loss 0.2007 (0.2537)	LossFusion 0.2007 (0.2537)	
Train Epoch: [199][7/8]	Loss 0.2007 (0.2537)	LossFusion 0.2007 (0.2537)	
Train Epoch: [199][7/8]	Loss 0.2007 (0.2537)	LossFusion 0.2007 (0.2537)	
Train Epoch: [199][7/8]	Loss 0.2007 (0.2537)	LossFusion 0.2007 (0.2537)	
Train Epoch: [199][7/8]	Loss 0.2007 (0.2537)	LossFusion 0.2007 (0.2537)	
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.63600063323975
Mean Now:  67.43327677249908  Best Mean Before:  69.44918 --------------------
Train Epoch: [200][0/8]	Loss 0.3320 (0.3320)	LossFusion 0.3320 (0.3320)	
Train Epoch: [200][0/8]	Loss 0.3320 (0.3320)	LossFusion 0.3320 (0.3320)	
Train Epoch: [200][0/8]	Loss 0.3320 (0.3320)	LossFusion 0.3320 (0.3320)	
Train Epoch: [200][0/8]	Loss 0.3320 (0.3320)	LossFusion 0.3320 (0.3320)	
Train Epoch: [200][0/8]	Loss 0.3320 (0.3320)	LossFusion 0.3320 (0.3320)	
Train Epoch: [200][0/8]	Loss 0.3320 (0.3320)	LossFusion 0.3320 (0.3320)	
Train Epoch: [200][0/8]	Loss 0.3320 (0.3320)	LossFusion 0.3320 (0.3320)	
Train Epoch: [200][0/8]	Loss 0.3320 (0.3320)	LossFusion 0.3320 (0.3320)	
Train Epoch: [200][7/8]	Loss 0.1922 (0.2379)	LossFusion 0.1922 (0.2379)	
Train Epoch: [200][7/8]	Loss 0.1922 (0.2379)	LossFusion 0.1922 (0.2379)	
Train Epoch: [200][7/8]	Loss 0.1922 (0.2379)	LossFusion 0.1922 (0.2379)	
Train Epoch: [200][7/8]	Loss 0.1922 (0.2379)	LossFusion 0.1922 (0.2379)	
Train Epoch: [200][7/8]	Loss 0.1922 (0.2379)	LossFusion 0.1922 (0.2379)	
Train Epoch: [200][7/8]	Loss 0.1922 (0.2379)	LossFusion 0.1922 (0.2379)	
Train Epoch: [200][7/8]	Loss 0.1922 (0.2379)	LossFusion 0.1922 (0.2379)	
Train Epoch: [200][7/8]	Loss 0.1922 (0.2379)	LossFusion 0.1922 (0.2379)	
R@10:  53.6626935005188     R@50:  80.35207390785217
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.35207390785217
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.35207390785217
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.35207390785217
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.35207390785217
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.35207390785217
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.35207390785217
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.35207390785217
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
Train Epoch: [201][0/8]	Loss 0.3821 (0.3821)	LossFusion 0.3821 (0.3821)	
Train Epoch: [201][0/8]	Loss 0.3821 (0.3821)	LossFusion 0.3821 (0.3821)	
Train Epoch: [201][0/8]	Loss 0.3821 (0.3821)	LossFusion 0.3821 (0.3821)	
Train Epoch: [201][0/8]	Loss 0.3821 (0.3821)	LossFusion 0.3821 (0.3821)	
Train Epoch: [201][0/8]	Loss 0.3821 (0.3821)	LossFusion 0.3821 (0.3821)	
Train Epoch: [201][0/8]	Loss 0.3821 (0.3821)	LossFusion 0.3821 (0.3821)	
Train Epoch: [201][0/8]	Loss 0.3821 (0.3821)	LossFusion 0.3821 (0.3821)	
Train Epoch: [201][0/8]	Loss 0.3821 (0.3821)	LossFusion 0.3821 (0.3821)	
Train Epoch: [201][7/8]	Loss 0.1803 (0.2468)	LossFusion 0.1803 (0.2468)	
Train Epoch: [201][7/8]	Loss 0.1803 (0.2468)	LossFusion 0.1803 (0.2468)	
Train Epoch: [201][7/8]	Loss 0.1803 (0.2468)	LossFusion 0.1803 (0.2468)	
Train Epoch: [201][7/8]	Loss 0.1803 (0.2468)	LossFusion 0.1803 (0.2468)	
Train Epoch: [201][7/8]	Loss 0.1803 (0.2468)	LossFusion 0.1803 (0.2468)	
Train Epoch: [201][7/8]	Loss 0.1803 (0.2468)	LossFusion 0.1803 (0.2468)	
Train Epoch: [201][7/8]	Loss 0.1803 (0.2468)	LossFusion 0.1803 (0.2468)	
Train Epoch: [201][7/8]	Loss 0.1803 (0.2468)	LossFusion 0.1803 (0.2468)	
R@10:  54.34412360191345     R@50:  80.29528856277466
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.29528856277466
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.29528856277466
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.29528856277466
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.29528856277466
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.29528856277466
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.29528856277466
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.34412360191345     R@50:  80.29528856277466
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
Train Epoch: [202][0/8]	Loss 0.3763 (0.3763)	LossFusion 0.3763 (0.3763)	
Train Epoch: [202][0/8]	Loss 0.3763 (0.3763)	LossFusion 0.3763 (0.3763)	
Train Epoch: [202][0/8]	Loss 0.3763 (0.3763)	LossFusion 0.3763 (0.3763)	
Train Epoch: [202][0/8]	Loss 0.3763 (0.3763)	LossFusion 0.3763 (0.3763)	
Train Epoch: [202][0/8]	Loss 0.3763 (0.3763)	LossFusion 0.3763 (0.3763)	
Train Epoch: [202][0/8]	Loss 0.3763 (0.3763)	LossFusion 0.3763 (0.3763)	
Train Epoch: [202][0/8]	Loss 0.3763 (0.3763)	LossFusion 0.3763 (0.3763)	
Train Epoch: [202][0/8]	Loss 0.3763 (0.3763)	LossFusion 0.3763 (0.3763)	
Train Epoch: [202][7/8]	Loss 0.1914 (0.2469)	LossFusion 0.1914 (0.2469)	
Train Epoch: [202][7/8]	Loss 0.1914 (0.2469)	LossFusion 0.1914 (0.2469)	
Train Epoch: [202][7/8]	Loss 0.1914 (0.2469)	LossFusion 0.1914 (0.2469)	
Train Epoch: [202][7/8]	Loss 0.1914 (0.2469)	LossFusion 0.1914 (0.2469)	
Train Epoch: [202][7/8]	Loss 0.1914 (0.2469)	LossFusion 0.1914 (0.2469)	
Train Epoch: [202][7/8]	Loss 0.1914 (0.2469)	LossFusion 0.1914 (0.2469)	
Train Epoch: [202][7/8]	Loss 0.1914 (0.2469)	LossFusion 0.1914 (0.2469)	
Train Epoch: [202][7/8]	Loss 0.1914 (0.2469)	LossFusion 0.1914 (0.2469)	
R@10:  54.00340557098389     R@50:  80.63600063323975
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.63600063323975
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.63600063323975
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.63600063323975
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.63600063323975
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.63600063323975
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.63600063323975
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.63600063323975
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
Train Epoch: [203][0/8]	Loss 0.3784 (0.3784)	LossFusion 0.3784 (0.3784)	
Train Epoch: [203][0/8]	Loss 0.3784 (0.3784)	LossFusion 0.3784 (0.3784)	
Train Epoch: [203][0/8]	Loss 0.3784 (0.3784)	LossFusion 0.3784 (0.3784)	
Train Epoch: [203][0/8]	Loss 0.3784 (0.3784)	LossFusion 0.3784 (0.3784)	
Train Epoch: [203][0/8]	Loss 0.3784 (0.3784)	LossFusion 0.3784 (0.3784)	
Train Epoch: [203][0/8]	Loss 0.3784 (0.3784)	LossFusion 0.3784 (0.3784)	
Train Epoch: [203][0/8]	Loss 0.3784 (0.3784)	LossFusion 0.3784 (0.3784)	
Train Epoch: [203][0/8]	Loss 0.3784 (0.3784)	LossFusion 0.3784 (0.3784)	
Train Epoch: [203][7/8]	Loss 0.2042 (0.2465)	LossFusion 0.2042 (0.2465)	
Train Epoch: [203][7/8]	Loss 0.2042 (0.2465)	LossFusion 0.2042 (0.2465)	
Train Epoch: [203][7/8]	Loss 0.2042 (0.2465)	LossFusion 0.2042 (0.2465)	
Train Epoch: [203][7/8]	Loss 0.2042 (0.2465)	LossFusion 0.2042 (0.2465)	
Train Epoch: [203][7/8]	Loss 0.2042 (0.2465)	LossFusion 0.2042 (0.2465)	
Train Epoch: [203][7/8]	Loss 0.2042 (0.2465)	LossFusion 0.2042 (0.2465)	
Train Epoch: [203][7/8]	Loss 0.2042 (0.2465)	LossFusion 0.2042 (0.2465)	
Train Epoch: [203][7/8]	Loss 0.2042 (0.2465)	LossFusion 0.2042 (0.2465)	
R@10:  54.96876835823059     R@50:  80.57921528816223
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  80.57921528816223
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  80.57921528816223
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  80.57921528816223
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  80.57921528816223
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  80.57921528816223
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  80.57921528816223
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
R@10:  54.96876835823059     R@50:  80.57921528816223
Mean Now:  67.77399182319641  Best Mean Before:  69.44918 --------------------
Train Epoch: [204][0/8]	Loss 0.3419 (0.3419)	LossFusion 0.3419 (0.3419)	
Train Epoch: [204][0/8]	Loss 0.3419 (0.3419)	LossFusion 0.3419 (0.3419)	
Train Epoch: [204][0/8]	Loss 0.3419 (0.3419)	LossFusion 0.3419 (0.3419)	
Train Epoch: [204][0/8]	Loss 0.3419 (0.3419)	LossFusion 0.3419 (0.3419)	
Train Epoch: [204][0/8]	Loss 0.3419 (0.3419)	LossFusion 0.3419 (0.3419)	
Train Epoch: [204][0/8]	Loss 0.3419 (0.3419)	LossFusion 0.3419 (0.3419)	
Train Epoch: [204][0/8]	Loss 0.3419 (0.3419)	LossFusion 0.3419 (0.3419)	
Train Epoch: [204][0/8]	Loss 0.3419 (0.3419)	LossFusion 0.3419 (0.3419)	
Train Epoch: [204][7/8]	Loss 0.2281 (0.2445)	LossFusion 0.2281 (0.2445)	
Train Epoch: [204][7/8]	Loss 0.2281 (0.2445)	LossFusion 0.2281 (0.2445)	
Train Epoch: [204][7/8]	Loss 0.2281 (0.2445)	LossFusion 0.2281 (0.2445)	
Train Epoch: [204][7/8]	Loss 0.2281 (0.2445)	LossFusion 0.2281 (0.2445)	
Train Epoch: [204][7/8]	Loss 0.2281 (0.2445)	LossFusion 0.2281 (0.2445)	
Train Epoch: [204][7/8]	Loss 0.2281 (0.2445)	LossFusion 0.2281 (0.2445)	
Train Epoch: [204][7/8]	Loss 0.2281 (0.2445)	LossFusion 0.2281 (0.2445)	
Train Epoch: [204][7/8]	Loss 0.2281 (0.2445)	LossFusion 0.2281 (0.2445)	
R@10:  54.23055291175842     R@50:  80.01135587692261
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.01135587692261
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.01135587692261
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.01135587692261
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.01135587692261
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.01135587692261
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.01135587692261
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  54.23055291175842     R@50:  80.01135587692261
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
Train Epoch: [205][0/8]	Loss 0.3497 (0.3497)	LossFusion 0.3497 (0.3497)	
Train Epoch: [205][0/8]	Loss 0.3497 (0.3497)	LossFusion 0.3497 (0.3497)	
Train Epoch: [205][0/8]	Loss 0.3497 (0.3497)	LossFusion 0.3497 (0.3497)	
Train Epoch: [205][0/8]	Loss 0.3497 (0.3497)	LossFusion 0.3497 (0.3497)	
Train Epoch: [205][0/8]	Loss 0.3497 (0.3497)	LossFusion 0.3497 (0.3497)	
Train Epoch: [205][0/8]	Loss 0.3497 (0.3497)	LossFusion 0.3497 (0.3497)	
Train Epoch: [205][0/8]	Loss 0.3497 (0.3497)	LossFusion 0.3497 (0.3497)	
Train Epoch: [205][0/8]	Loss 0.3497 (0.3497)	LossFusion 0.3497 (0.3497)	
Train Epoch: [205][7/8]	Loss 0.1687 (0.2278)	LossFusion 0.1687 (0.2278)	
Train Epoch: [205][7/8]	Loss 0.1687 (0.2278)	LossFusion 0.1687 (0.2278)	
Train Epoch: [205][7/8]	Loss 0.1687 (0.2278)	LossFusion 0.1687 (0.2278)	
Train Epoch: [205][7/8]	Loss 0.1687 (0.2278)	LossFusion 0.1687 (0.2278)	
Train Epoch: [205][7/8]	Loss 0.1687 (0.2278)	LossFusion 0.1687 (0.2278)	
Train Epoch: [205][7/8]	Loss 0.1687 (0.2278)	LossFusion 0.1687 (0.2278)	
Train Epoch: [205][7/8]	Loss 0.1687 (0.2278)	LossFusion 0.1687 (0.2278)	
Train Epoch: [205][7/8]	Loss 0.1687 (0.2278)	LossFusion 0.1687 (0.2278)	
R@10:  54.17376756668091     R@50:  80.35207390785217
Mean Now:  67.26292073726654  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.35207390785217
Mean Now:  67.26292073726654  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.35207390785217
Mean Now:  67.26292073726654  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.35207390785217
Mean Now:  67.26292073726654  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.35207390785217
Mean Now:  67.26292073726654  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.35207390785217
Mean Now:  67.26292073726654  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.35207390785217
Mean Now:  67.26292073726654  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.35207390785217
Mean Now:  67.26292073726654  Best Mean Before:  69.44918 --------------------
Train Epoch: [206][0/8]	Loss 0.3628 (0.3628)	LossFusion 0.3628 (0.3628)	
Train Epoch: [206][0/8]	Loss 0.3628 (0.3628)	LossFusion 0.3628 (0.3628)	
Train Epoch: [206][0/8]	Loss 0.3628 (0.3628)	LossFusion 0.3628 (0.3628)	
Train Epoch: [206][0/8]	Loss 0.3628 (0.3628)	LossFusion 0.3628 (0.3628)	
Train Epoch: [206][0/8]	Loss 0.3628 (0.3628)	LossFusion 0.3628 (0.3628)	
Train Epoch: [206][0/8]	Loss 0.3628 (0.3628)	LossFusion 0.3628 (0.3628)	
Train Epoch: [206][0/8]	Loss 0.3628 (0.3628)	LossFusion 0.3628 (0.3628)	
Train Epoch: [206][0/8]	Loss 0.3628 (0.3628)	LossFusion 0.3628 (0.3628)	
Train Epoch: [206][7/8]	Loss 0.1822 (0.2315)	LossFusion 0.1822 (0.2315)	
Train Epoch: [206][7/8]	Loss 0.1822 (0.2315)	LossFusion 0.1822 (0.2315)	
Train Epoch: [206][7/8]	Loss 0.1822 (0.2315)	LossFusion 0.1822 (0.2315)	
Train Epoch: [206][7/8]	Loss 0.1822 (0.2315)	LossFusion 0.1822 (0.2315)	
Train Epoch: [206][7/8]	Loss 0.1822 (0.2315)	LossFusion 0.1822 (0.2315)	
Train Epoch: [206][7/8]	Loss 0.1822 (0.2315)	LossFusion 0.1822 (0.2315)	
Train Epoch: [206][7/8]	Loss 0.1822 (0.2315)	LossFusion 0.1822 (0.2315)	
Train Epoch: [206][7/8]	Loss 0.1822 (0.2315)	LossFusion 0.1822 (0.2315)	
R@10:  54.0601909160614     R@50:  80.63600063323975
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.63600063323975
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.63600063323975
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.63600063323975
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.63600063323975
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.63600063323975
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.63600063323975
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.63600063323975
Mean Now:  67.34809577465057  Best Mean Before:  69.44918 --------------------
Train Epoch: [207][0/8]	Loss 0.3713 (0.3713)	LossFusion 0.3713 (0.3713)	
Train Epoch: [207][0/8]	Loss 0.3713 (0.3713)	LossFusion 0.3713 (0.3713)	
Train Epoch: [207][0/8]	Loss 0.3713 (0.3713)	LossFusion 0.3713 (0.3713)	
Train Epoch: [207][0/8]	Loss 0.3713 (0.3713)	LossFusion 0.3713 (0.3713)	
Train Epoch: [207][0/8]	Loss 0.3713 (0.3713)	LossFusion 0.3713 (0.3713)	
Train Epoch: [207][0/8]	Loss 0.3713 (0.3713)	LossFusion 0.3713 (0.3713)	
Train Epoch: [207][0/8]	Loss 0.3713 (0.3713)	LossFusion 0.3713 (0.3713)	
Train Epoch: [207][0/8]	Loss 0.3713 (0.3713)	LossFusion 0.3713 (0.3713)	
Train Epoch: [207][7/8]	Loss 0.1881 (0.2308)	LossFusion 0.1881 (0.2308)	
Train Epoch: [207][7/8]	Loss 0.1881 (0.2308)	LossFusion 0.1881 (0.2308)	
Train Epoch: [207][7/8]	Loss 0.1881 (0.2308)	LossFusion 0.1881 (0.2308)	
Train Epoch: [207][7/8]	Loss 0.1881 (0.2308)	LossFusion 0.1881 (0.2308)	
Train Epoch: [207][7/8]	Loss 0.1881 (0.2308)	LossFusion 0.1881 (0.2308)	
Train Epoch: [207][7/8]	Loss 0.1881 (0.2308)	LossFusion 0.1881 (0.2308)	
Train Epoch: [207][7/8]	Loss 0.1881 (0.2308)	LossFusion 0.1881 (0.2308)	
Train Epoch: [207][7/8]	Loss 0.1881 (0.2308)	LossFusion 0.1881 (0.2308)	
R@10:  54.00340557098389     R@50:  80.57921528816223
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.57921528816223
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.57921528816223
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.57921528816223
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.57921528816223
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.57921528816223
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.57921528816223
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.57921528816223
Mean Now:  67.29131042957306  Best Mean Before:  69.44918 --------------------
Train Epoch: [208][0/8]	Loss 0.3696 (0.3696)	LossFusion 0.3696 (0.3696)	
Train Epoch: [208][0/8]	Loss 0.3696 (0.3696)	LossFusion 0.3696 (0.3696)	
Train Epoch: [208][0/8]	Loss 0.3696 (0.3696)	LossFusion 0.3696 (0.3696)	
Train Epoch: [208][0/8]	Loss 0.3696 (0.3696)	LossFusion 0.3696 (0.3696)	
Train Epoch: [208][0/8]	Loss 0.3696 (0.3696)	LossFusion 0.3696 (0.3696)	
Train Epoch: [208][0/8]	Loss 0.3696 (0.3696)	LossFusion 0.3696 (0.3696)	
Train Epoch: [208][0/8]	Loss 0.3696 (0.3696)	LossFusion 0.3696 (0.3696)	
Train Epoch: [208][0/8]	Loss 0.3696 (0.3696)	LossFusion 0.3696 (0.3696)	
Train Epoch: [208][7/8]	Loss 0.1786 (0.2232)	LossFusion 0.1786 (0.2232)	
Train Epoch: [208][7/8]	Loss 0.1786 (0.2232)	LossFusion 0.1786 (0.2232)	
Train Epoch: [208][7/8]	Loss 0.1786 (0.2232)	LossFusion 0.1786 (0.2232)	
Train Epoch: [208][7/8]	Loss 0.1786 (0.2232)	LossFusion 0.1786 (0.2232)	
Train Epoch: [208][7/8]	Loss 0.1786 (0.2232)	LossFusion 0.1786 (0.2232)	
Train Epoch: [208][7/8]	Loss 0.1786 (0.2232)	LossFusion 0.1786 (0.2232)	
Train Epoch: [208][7/8]	Loss 0.1786 (0.2232)	LossFusion 0.1786 (0.2232)	
Train Epoch: [208][7/8]	Loss 0.1786 (0.2232)	LossFusion 0.1786 (0.2232)	
R@10:  54.28733825683594     R@50:  80.29528856277466
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.29528856277466
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.29528856277466
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.29528856277466
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.29528856277466
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.29528856277466
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.29528856277466
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.29528856277466
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
Train Epoch: [209][0/8]	Loss 0.3725 (0.3725)	LossFusion 0.3725 (0.3725)	
Train Epoch: [209][0/8]	Loss 0.3725 (0.3725)	LossFusion 0.3725 (0.3725)	
Train Epoch: [209][0/8]	Loss 0.3725 (0.3725)	LossFusion 0.3725 (0.3725)	
Train Epoch: [209][0/8]	Loss 0.3725 (0.3725)	LossFusion 0.3725 (0.3725)	
Train Epoch: [209][0/8]	Loss 0.3725 (0.3725)	LossFusion 0.3725 (0.3725)	
Train Epoch: [209][0/8]	Loss 0.3725 (0.3725)	LossFusion 0.3725 (0.3725)	
Train Epoch: [209][0/8]	Loss 0.3725 (0.3725)	LossFusion 0.3725 (0.3725)	
Train Epoch: [209][0/8]	Loss 0.3725 (0.3725)	LossFusion 0.3725 (0.3725)	
Train Epoch: [209][7/8]	Loss 0.2011 (0.2265)	LossFusion 0.2011 (0.2265)	
Train Epoch: [209][7/8]	Loss 0.2011 (0.2265)	LossFusion 0.2011 (0.2265)	
Train Epoch: [209][7/8]	Loss 0.2011 (0.2265)	LossFusion 0.2011 (0.2265)	
Train Epoch: [209][7/8]	Loss 0.2011 (0.2265)	LossFusion 0.2011 (0.2265)	
Train Epoch: [209][7/8]	Loss 0.2011 (0.2265)	LossFusion 0.2011 (0.2265)	
Train Epoch: [209][7/8]	Loss 0.2011 (0.2265)	LossFusion 0.2011 (0.2265)	
Train Epoch: [209][7/8]	Loss 0.2011 (0.2265)	LossFusion 0.2011 (0.2265)	
Train Epoch: [209][7/8]	Loss 0.2011 (0.2265)	LossFusion 0.2011 (0.2265)	
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
Train Epoch: [210][0/8]	Loss 0.3565 (0.3565)	LossFusion 0.3565 (0.3565)	
Train Epoch: [210][0/8]	Loss 0.3565 (0.3565)	LossFusion 0.3565 (0.3565)	
Train Epoch: [210][0/8]	Loss 0.3565 (0.3565)	LossFusion 0.3565 (0.3565)	
Train Epoch: [210][0/8]	Loss 0.3565 (0.3565)	LossFusion 0.3565 (0.3565)	
Train Epoch: [210][0/8]	Loss 0.3565 (0.3565)	LossFusion 0.3565 (0.3565)	
Train Epoch: [210][0/8]	Loss 0.3565 (0.3565)	LossFusion 0.3565 (0.3565)	
Train Epoch: [210][0/8]	Loss 0.3565 (0.3565)	LossFusion 0.3565 (0.3565)	
Train Epoch: [210][0/8]	Loss 0.3565 (0.3565)	LossFusion 0.3565 (0.3565)	
Train Epoch: [210][7/8]	Loss 0.1698 (0.2167)	LossFusion 0.1698 (0.2167)	
Train Epoch: [210][7/8]	Loss 0.1698 (0.2167)	LossFusion 0.1698 (0.2167)	
Train Epoch: [210][7/8]	Loss 0.1698 (0.2167)	LossFusion 0.1698 (0.2167)	
Train Epoch: [210][7/8]	Loss 0.1698 (0.2167)	LossFusion 0.1698 (0.2167)	
Train Epoch: [210][7/8]	Loss 0.1698 (0.2167)	LossFusion 0.1698 (0.2167)	
Train Epoch: [210][7/8]	Loss 0.1698 (0.2167)	LossFusion 0.1698 (0.2167)	
Train Epoch: [210][7/8]	Loss 0.1698 (0.2167)	LossFusion 0.1698 (0.2167)	
Train Epoch: [210][7/8]	Loss 0.1698 (0.2167)	LossFusion 0.1698 (0.2167)	
R@10:  53.88983488082886     R@50:  80.35207390785217
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.35207390785217
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.35207390785217
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.35207390785217
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.35207390785217
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.35207390785217
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.35207390785217
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.35207390785217
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
Train Epoch: [211][0/8]	Loss 0.3225 (0.3225)	LossFusion 0.3225 (0.3225)	
Train Epoch: [211][0/8]	Loss 0.3225 (0.3225)	LossFusion 0.3225 (0.3225)	
Train Epoch: [211][0/8]	Loss 0.3225 (0.3225)	LossFusion 0.3225 (0.3225)	
Train Epoch: [211][0/8]	Loss 0.3225 (0.3225)	LossFusion 0.3225 (0.3225)	
Train Epoch: [211][0/8]	Loss 0.3225 (0.3225)	LossFusion 0.3225 (0.3225)	
Train Epoch: [211][0/8]	Loss 0.3225 (0.3225)	LossFusion 0.3225 (0.3225)	
Train Epoch: [211][0/8]	Loss 0.3225 (0.3225)	LossFusion 0.3225 (0.3225)	
Train Epoch: [211][0/8]	Loss 0.3225 (0.3225)	LossFusion 0.3225 (0.3225)	
Train Epoch: [211][7/8]	Loss 0.1662 (0.2162)	LossFusion 0.1662 (0.2162)	
Train Epoch: [211][7/8]	Loss 0.1662 (0.2162)	LossFusion 0.1662 (0.2162)	
Train Epoch: [211][7/8]	Loss 0.1662 (0.2162)	LossFusion 0.1662 (0.2162)	
Train Epoch: [211][7/8]	Loss 0.1662 (0.2162)	LossFusion 0.1662 (0.2162)	
Train Epoch: [211][7/8]	Loss 0.1662 (0.2162)	LossFusion 0.1662 (0.2162)	
Train Epoch: [211][7/8]	Loss 0.1662 (0.2162)	LossFusion 0.1662 (0.2162)	
Train Epoch: [211][7/8]	Loss 0.1662 (0.2162)	LossFusion 0.1662 (0.2162)	
Train Epoch: [211][7/8]	Loss 0.1662 (0.2162)	LossFusion 0.1662 (0.2162)	
R@10:  52.86768674850464     R@50:  80.35207390785217
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  52.86768674850464     R@50:  80.35207390785217
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  52.86768674850464     R@50:  80.35207390785217
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  52.86768674850464     R@50:  80.35207390785217
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  52.86768674850464     R@50:  80.35207390785217
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  52.86768674850464     R@50:  80.35207390785217
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  52.86768674850464     R@50:  80.35207390785217
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  52.86768674850464     R@50:  80.35207390785217
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
Train Epoch: [212][0/8]	Loss 0.3306 (0.3306)	LossFusion 0.3306 (0.3306)	
Train Epoch: [212][0/8]	Loss 0.3306 (0.3306)	LossFusion 0.3306 (0.3306)	
Train Epoch: [212][0/8]	Loss 0.3306 (0.3306)	LossFusion 0.3306 (0.3306)	
Train Epoch: [212][0/8]	Loss 0.3306 (0.3306)	LossFusion 0.3306 (0.3306)	
Train Epoch: [212][0/8]	Loss 0.3306 (0.3306)	LossFusion 0.3306 (0.3306)	
Train Epoch: [212][0/8]	Loss 0.3306 (0.3306)	LossFusion 0.3306 (0.3306)	
Train Epoch: [212][0/8]	Loss 0.3306 (0.3306)	LossFusion 0.3306 (0.3306)	
Train Epoch: [212][0/8]	Loss 0.3306 (0.3306)	LossFusion 0.3306 (0.3306)	
Train Epoch: [212][7/8]	Loss 0.1914 (0.2216)	LossFusion 0.1914 (0.2216)	
Train Epoch: [212][7/8]	Loss 0.1914 (0.2216)	LossFusion 0.1914 (0.2216)	
Train Epoch: [212][7/8]	Loss 0.1914 (0.2216)	LossFusion 0.1914 (0.2216)	
Train Epoch: [212][7/8]	Loss 0.1914 (0.2216)	LossFusion 0.1914 (0.2216)	
Train Epoch: [212][7/8]	Loss 0.1914 (0.2216)	LossFusion 0.1914 (0.2216)	
Train Epoch: [212][7/8]	Loss 0.1914 (0.2216)	LossFusion 0.1914 (0.2216)	
Train Epoch: [212][7/8]	Loss 0.1914 (0.2216)	LossFusion 0.1914 (0.2216)	
Train Epoch: [212][7/8]	Loss 0.1914 (0.2216)	LossFusion 0.1914 (0.2216)	
R@10:  54.116976261138916     R@50:  80.18171787261963
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  80.18171787261963
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  80.18171787261963
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  80.18171787261963
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  80.18171787261963
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  80.18171787261963
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  80.18171787261963
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  80.18171787261963
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
Train Epoch: [213][0/8]	Loss 0.3200 (0.3200)	LossFusion 0.3200 (0.3200)	
Train Epoch: [213][0/8]	Loss 0.3200 (0.3200)	LossFusion 0.3200 (0.3200)	
Train Epoch: [213][0/8]	Loss 0.3200 (0.3200)	LossFusion 0.3200 (0.3200)	
Train Epoch: [213][0/8]	Loss 0.3200 (0.3200)	LossFusion 0.3200 (0.3200)	
Train Epoch: [213][0/8]	Loss 0.3200 (0.3200)	LossFusion 0.3200 (0.3200)	
Train Epoch: [213][0/8]	Loss 0.3200 (0.3200)	LossFusion 0.3200 (0.3200)	
Train Epoch: [213][0/8]	Loss 0.3200 (0.3200)	LossFusion 0.3200 (0.3200)	
Train Epoch: [213][0/8]	Loss 0.3200 (0.3200)	LossFusion 0.3200 (0.3200)	
Train Epoch: [213][7/8]	Loss 0.1730 (0.2151)	LossFusion 0.1730 (0.2151)	
Train Epoch: [213][7/8]	Loss 0.1730 (0.2151)	LossFusion 0.1730 (0.2151)	
Train Epoch: [213][7/8]	Loss 0.1730 (0.2151)	LossFusion 0.1730 (0.2151)	
Train Epoch: [213][7/8]	Loss 0.1730 (0.2151)	LossFusion 0.1730 (0.2151)	
Train Epoch: [213][7/8]	Loss 0.1730 (0.2151)	LossFusion 0.1730 (0.2151)	
Train Epoch: [213][7/8]	Loss 0.1730 (0.2151)	LossFusion 0.1730 (0.2151)	
Train Epoch: [213][7/8]	Loss 0.1730 (0.2151)	LossFusion 0.1730 (0.2151)	
Train Epoch: [213][7/8]	Loss 0.1730 (0.2151)	LossFusion 0.1730 (0.2151)	
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
Train Epoch: [214][0/8]	Loss 0.3174 (0.3174)	LossFusion 0.3174 (0.3174)	
Train Epoch: [214][0/8]	Loss 0.3174 (0.3174)	LossFusion 0.3174 (0.3174)	
Train Epoch: [214][0/8]	Loss 0.3174 (0.3174)	LossFusion 0.3174 (0.3174)	
Train Epoch: [214][0/8]	Loss 0.3174 (0.3174)	LossFusion 0.3174 (0.3174)	
Train Epoch: [214][0/8]	Loss 0.3174 (0.3174)	LossFusion 0.3174 (0.3174)	
Train Epoch: [214][0/8]	Loss 0.3174 (0.3174)	LossFusion 0.3174 (0.3174)	
Train Epoch: [214][0/8]	Loss 0.3174 (0.3174)	LossFusion 0.3174 (0.3174)	
Train Epoch: [214][0/8]	Loss 0.3174 (0.3174)	LossFusion 0.3174 (0.3174)	
Train Epoch: [214][7/8]	Loss 0.1730 (0.2091)	LossFusion 0.1730 (0.2091)	
Train Epoch: [214][7/8]	Loss 0.1730 (0.2091)	LossFusion 0.1730 (0.2091)	
Train Epoch: [214][7/8]	Loss 0.1730 (0.2091)	LossFusion 0.1730 (0.2091)	
Train Epoch: [214][7/8]	Loss 0.1730 (0.2091)	LossFusion 0.1730 (0.2091)	
Train Epoch: [214][7/8]	Loss 0.1730 (0.2091)	LossFusion 0.1730 (0.2091)	
Train Epoch: [214][7/8]	Loss 0.1730 (0.2091)	LossFusion 0.1730 (0.2091)	
Train Epoch: [214][7/8]	Loss 0.1730 (0.2091)	LossFusion 0.1730 (0.2091)	
Train Epoch: [214][7/8]	Loss 0.1730 (0.2091)	LossFusion 0.1730 (0.2091)	
R@10:  54.17376756668091     R@50:  80.40885925292969
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.40885925292969
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.40885925292969
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.40885925292969
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.40885925292969
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.40885925292969
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.40885925292969
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.40885925292969
Mean Now:  67.2913134098053  Best Mean Before:  69.44918 --------------------
Train Epoch: [215][0/8]	Loss 0.3241 (0.3241)	LossFusion 0.3241 (0.3241)	
Train Epoch: [215][0/8]	Loss 0.3241 (0.3241)	LossFusion 0.3241 (0.3241)	
Train Epoch: [215][0/8]	Loss 0.3241 (0.3241)	LossFusion 0.3241 (0.3241)	
Train Epoch: [215][0/8]	Loss 0.3241 (0.3241)	LossFusion 0.3241 (0.3241)	
Train Epoch: [215][0/8]	Loss 0.3241 (0.3241)	LossFusion 0.3241 (0.3241)	
Train Epoch: [215][0/8]	Loss 0.3241 (0.3241)	LossFusion 0.3241 (0.3241)	
Train Epoch: [215][0/8]	Loss 0.3241 (0.3241)	LossFusion 0.3241 (0.3241)	
Train Epoch: [215][0/8]	Loss 0.3241 (0.3241)	LossFusion 0.3241 (0.3241)	
Train Epoch: [215][7/8]	Loss 0.1576 (0.2067)	LossFusion 0.1576 (0.2067)	
Train Epoch: [215][7/8]	Loss 0.1576 (0.2067)	LossFusion 0.1576 (0.2067)	Train Epoch: [215][7/8]	Loss 0.1576 (0.2067)	LossFusion 0.1576 (0.2067)	

Train Epoch: [215][7/8]	Loss 0.1576 (0.2067)	LossFusion 0.1576 (0.2067)	
Train Epoch: [215][7/8]	Loss 0.1576 (0.2067)	LossFusion 0.1576 (0.2067)	
Train Epoch: [215][7/8]	Loss 0.1576 (0.2067)	LossFusion 0.1576 (0.2067)	
Train Epoch: [215][7/8]	Loss 0.1576 (0.2067)	LossFusion 0.1576 (0.2067)	
Train Epoch: [215][7/8]	Loss 0.1576 (0.2067)	LossFusion 0.1576 (0.2067)	
R@10:  53.94662022590637     R@50:  80.4656445980072
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.4656445980072
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.4656445980072
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.4656445980072
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.4656445980072
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.4656445980072
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.4656445980072
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.4656445980072
Mean Now:  67.20613241195679  Best Mean Before:  69.44918 --------------------
Train Epoch: [216][0/8]	Loss 0.3217 (0.3217)	LossFusion 0.3217 (0.3217)	
Train Epoch: [216][0/8]	Loss 0.3217 (0.3217)	LossFusion 0.3217 (0.3217)	
Train Epoch: [216][0/8]	Loss 0.3217 (0.3217)	LossFusion 0.3217 (0.3217)	
Train Epoch: [216][0/8]	Loss 0.3217 (0.3217)	LossFusion 0.3217 (0.3217)	
Train Epoch: [216][0/8]	Loss 0.3217 (0.3217)	LossFusion 0.3217 (0.3217)	
Train Epoch: [216][0/8]	Loss 0.3217 (0.3217)	LossFusion 0.3217 (0.3217)	
Train Epoch: [216][0/8]	Loss 0.3217 (0.3217)	LossFusion 0.3217 (0.3217)	
Train Epoch: [216][0/8]	Loss 0.3217 (0.3217)	LossFusion 0.3217 (0.3217)	
Train Epoch: [216][7/8]	Loss 0.1611 (0.2033)	LossFusion 0.1611 (0.2033)	
Train Epoch: [216][7/8]	Loss 0.1611 (0.2033)	LossFusion 0.1611 (0.2033)	
Train Epoch: [216][7/8]	Loss 0.1611 (0.2033)	LossFusion 0.1611 (0.2033)	
Train Epoch: [216][7/8]	Loss 0.1611 (0.2033)	LossFusion 0.1611 (0.2033)	
Train Epoch: [216][7/8]	Loss 0.1611 (0.2033)	LossFusion 0.1611 (0.2033)	
Train Epoch: [216][7/8]	Loss 0.1611 (0.2033)	LossFusion 0.1611 (0.2033)	
Train Epoch: [216][7/8]	Loss 0.1611 (0.2033)	LossFusion 0.1611 (0.2033)	
Train Epoch: [216][7/8]	Loss 0.1611 (0.2033)	LossFusion 0.1611 (0.2033)	
R@10:  53.37876081466675     R@50:  80.12492656707764
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.12492656707764
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.12492656707764
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.12492656707764
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.12492656707764
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.12492656707764
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.12492656707764
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.12492656707764
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
Train Epoch: [217][0/8]	Loss 0.3058 (0.3058)	LossFusion 0.3058 (0.3058)	
Train Epoch: [217][0/8]	Loss 0.3058 (0.3058)	LossFusion 0.3058 (0.3058)	
Train Epoch: [217][0/8]	Loss 0.3058 (0.3058)	LossFusion 0.3058 (0.3058)	
Train Epoch: [217][0/8]	Loss 0.3058 (0.3058)	LossFusion 0.3058 (0.3058)	
Train Epoch: [217][0/8]	Loss 0.3058 (0.3058)	LossFusion 0.3058 (0.3058)	
Train Epoch: [217][0/8]	Loss 0.3058 (0.3058)	LossFusion 0.3058 (0.3058)	
Train Epoch: [217][0/8]	Loss 0.3058 (0.3058)	LossFusion 0.3058 (0.3058)	
Train Epoch: [217][0/8]	Loss 0.3058 (0.3058)	LossFusion 0.3058 (0.3058)	
Train Epoch: [217][7/8]	Loss 0.1655 (0.2065)	LossFusion 0.1655 (0.2065)	
Train Epoch: [217][7/8]	Loss 0.1655 (0.2065)	LossFusion 0.1655 (0.2065)	
Train Epoch: [217][7/8]	Loss 0.1655 (0.2065)	LossFusion 0.1655 (0.2065)	
Train Epoch: [217][7/8]	Loss 0.1655 (0.2065)	LossFusion 0.1655 (0.2065)	
Train Epoch: [217][7/8]	Loss 0.1655 (0.2065)	LossFusion 0.1655 (0.2065)	
Train Epoch: [217][7/8]	Loss 0.1655 (0.2065)	LossFusion 0.1655 (0.2065)	
Train Epoch: [217][7/8]	Loss 0.1655 (0.2065)	LossFusion 0.1655 (0.2065)	
Train Epoch: [217][7/8]	Loss 0.1655 (0.2065)	LossFusion 0.1655 (0.2065)	
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
R@10: R@10:  54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
 54.17376756668091     R@50:  80.23850321769714
Mean Now:  67.20613539218903  Best Mean Before:  69.44918 --------------------
Train Epoch: [218][0/8]	Loss 0.3044 (0.3044)	LossFusion 0.3044 (0.3044)	
Train Epoch: [218][0/8]	Loss 0.3044 (0.3044)	LossFusion 0.3044 (0.3044)	
Train Epoch: [218][0/8]	Loss 0.3044 (0.3044)	LossFusion 0.3044 (0.3044)	
Train Epoch: [218][0/8]	Loss 0.3044 (0.3044)	LossFusion 0.3044 (0.3044)	
Train Epoch: [218][0/8]	Loss 0.3044 (0.3044)	LossFusion 0.3044 (0.3044)	
Train Epoch: [218][0/8]	Loss 0.3044 (0.3044)	LossFusion 0.3044 (0.3044)	
Train Epoch: [218][0/8]	Loss 0.3044 (0.3044)	LossFusion 0.3044 (0.3044)	
Train Epoch: [218][0/8]	Loss 0.3044 (0.3044)	LossFusion 0.3044 (0.3044)	
Train Epoch: [218][7/8]	Loss 0.1677 (0.2027)	LossFusion 0.1677 (0.2027)	
Train Epoch: [218][7/8]	Loss 0.1677 (0.2027)	LossFusion 0.1677 (0.2027)	
Train Epoch: [218][7/8]	Loss 0.1677 (0.2027)	LossFusion 0.1677 (0.2027)	
Train Epoch: [218][7/8]	Loss 0.1677 (0.2027)	LossFusion 0.1677 (0.2027)	
Train Epoch: [218][7/8]	Loss 0.1677 (0.2027)	LossFusion 0.1677 (0.2027)	
Train Epoch: [218][7/8]	Loss 0.1677 (0.2027)	LossFusion 0.1677 (0.2027)	
Train Epoch: [218][7/8]	Loss 0.1677 (0.2027)	LossFusion 0.1677 (0.2027)	
Train Epoch: [218][7/8]	Loss 0.1677 (0.2027)	LossFusion 0.1677 (0.2027)	
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
Train Epoch: [219][0/8]	Loss 0.3051 (0.3051)	LossFusion 0.3051 (0.3051)	
Train Epoch: [219][0/8]	Loss 0.3051 (0.3051)	LossFusion 0.3051 (0.3051)	
Train Epoch: [219][0/8]	Loss 0.3051 (0.3051)	LossFusion 0.3051 (0.3051)	
Train Epoch: [219][0/8]	Loss 0.3051 (0.3051)	LossFusion 0.3051 (0.3051)	
Train Epoch: [219][0/8]	Loss 0.3051 (0.3051)	LossFusion 0.3051 (0.3051)	
Train Epoch: [219][0/8]	Loss 0.3051 (0.3051)	LossFusion 0.3051 (0.3051)	
Train Epoch: [219][0/8]	Loss 0.3051 (0.3051)	LossFusion 0.3051 (0.3051)	
Train Epoch: [219][0/8]	Loss 0.3051 (0.3051)	LossFusion 0.3051 (0.3051)	
Train Epoch: [219][7/8]	Loss 0.1683 (0.1925)	LossFusion 0.1683 (0.1925)	
Train Epoch: [219][7/8]	Loss 0.1683 (0.1925)	LossFusion 0.1683 (0.1925)	
Train Epoch: [219][7/8]	Loss 0.1683 (0.1925)	LossFusion 0.1683 (0.1925)	
Train Epoch: [219][7/8]	Loss 0.1683 (0.1925)	LossFusion 0.1683 (0.1925)	
Train Epoch: [219][7/8]	Loss 0.1683 (0.1925)	LossFusion 0.1683 (0.1925)	
Train Epoch: [219][7/8]	Loss 0.1683 (0.1925)	LossFusion 0.1683 (0.1925)	
Train Epoch: [219][7/8]	Loss 0.1683 (0.1925)	LossFusion 0.1683 (0.1925)	
Train Epoch: [219][7/8]	Loss 0.1683 (0.1925)	LossFusion 0.1683 (0.1925)	
R@10:  54.0601909160614     R@50:  80.57921528816223
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.57921528816223
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.57921528816223
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.57921528816223
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.57921528816223
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.57921528816223
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.57921528816223
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  80.57921528816223
Mean Now:  67.31970310211182  Best Mean Before:  69.44918 --------------------
Train Epoch: [220][0/8]	Loss 0.3024 (0.3024)	LossFusion 0.3024 (0.3024)	
Train Epoch: [220][0/8]	Loss 0.3024 (0.3024)	LossFusion 0.3024 (0.3024)	
Train Epoch: [220][0/8]	Loss 0.3024 (0.3024)	LossFusion 0.3024 (0.3024)	
Train Epoch: [220][0/8]	Loss 0.3024 (0.3024)	LossFusion 0.3024 (0.3024)	
Train Epoch: [220][0/8]	Loss 0.3024 (0.3024)	LossFusion 0.3024 (0.3024)	
Train Epoch: [220][0/8]	Loss 0.3024 (0.3024)	LossFusion 0.3024 (0.3024)	
Train Epoch: [220][0/8]	Loss 0.3024 (0.3024)	LossFusion 0.3024 (0.3024)	
Train Epoch: [220][0/8]	Loss 0.3024 (0.3024)	LossFusion 0.3024 (0.3024)	
Train Epoch: [220][7/8]	Loss 0.1496 (0.1972)	LossFusion 0.1496 (0.1972)	
Train Epoch: [220][7/8]	Loss 0.1496 (0.1972)	LossFusion 0.1496 (0.1972)	
Train Epoch: [220][7/8]	Loss 0.1496 (0.1972)	LossFusion 0.1496 (0.1972)	
Train Epoch: [220][7/8]	Loss 0.1496 (0.1972)	LossFusion 0.1496 (0.1972)	
Train Epoch: [220][7/8]	Loss 0.1496 (0.1972)	LossFusion 0.1496 (0.1972)	
Train Epoch: [220][7/8]	Loss 0.1496 (0.1972)	LossFusion 0.1496 (0.1972)	
Train Epoch: [220][7/8]	Loss 0.1496 (0.1972)	LossFusion 0.1496 (0.1972)	
Train Epoch: [220][7/8]	Loss 0.1496 (0.1972)	LossFusion 0.1496 (0.1972)	
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.23850321769714
Mean Now:  67.00738370418549  Best Mean Before:  69.44918 --------------------
Train Epoch: [221][0/8]	Loss 0.2943 (0.2943)	LossFusion 0.2943 (0.2943)	
Train Epoch: [221][0/8]	Loss 0.2943 (0.2943)	LossFusion 0.2943 (0.2943)	
Train Epoch: [221][0/8]	Loss 0.2943 (0.2943)	LossFusion 0.2943 (0.2943)	
Train Epoch: [221][0/8]	Loss 0.2943 (0.2943)	LossFusion 0.2943 (0.2943)	
Train Epoch: [221][0/8]	Loss 0.2943 (0.2943)	LossFusion 0.2943 (0.2943)	
Train Epoch: [221][0/8]	Loss 0.2943 (0.2943)	LossFusion 0.2943 (0.2943)	
Train Epoch: [221][0/8]	Loss 0.2943 (0.2943)	LossFusion 0.2943 (0.2943)	
Train Epoch: [221][0/8]	Loss 0.2943 (0.2943)	LossFusion 0.2943 (0.2943)	
Train Epoch: [221][7/8]	Loss 0.1547 (0.1900)	LossFusion 0.1547 (0.1900)	
Train Epoch: [221][7/8]	Loss 0.1547 (0.1900)	LossFusion 0.1547 (0.1900)	
Train Epoch: [221][7/8]	Loss 0.1547 (0.1900)	LossFusion 0.1547 (0.1900)	
Train Epoch: [221][7/8]	Loss 0.1547 (0.1900)	LossFusion 0.1547 (0.1900)	
Train Epoch: [221][7/8]	Loss 0.1547 (0.1900)	LossFusion 0.1547 (0.1900)	
Train Epoch: [221][7/8]	Loss 0.1547 (0.1900)	LossFusion 0.1547 (0.1900)	
Train Epoch: [221][7/8]	Loss 0.1547 (0.1900)	LossFusion 0.1547 (0.1900)	
Train Epoch: [221][7/8]	Loss 0.1547 (0.1900)	LossFusion 0.1547 (0.1900)	
R@10:  53.605908155441284     R@50:  80.52242994308472
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.52242994308472
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.52242994308472
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.52242994308472
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.52242994308472
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.52242994308472
R@10: Mean Now:   67.06416904926353.605908155441284   Best Mean Before:     R@50:   69.4491880.52242994308472 
--------------------
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.52242994308472
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
Train Epoch: [222][0/8]	Loss 0.3048 (0.3048)	LossFusion 0.3048 (0.3048)	
Train Epoch: [222][0/8]	Loss 0.3048 (0.3048)	LossFusion 0.3048 (0.3048)	
Train Epoch: [222][0/8]	Loss 0.3048 (0.3048)	LossFusion 0.3048 (0.3048)	
Train Epoch: [222][0/8]	Loss 0.3048 (0.3048)	LossFusion 0.3048 (0.3048)	
Train Epoch: [222][0/8]	Loss 0.3048 (0.3048)	LossFusion 0.3048 (0.3048)	
Train Epoch: [222][0/8]	Loss 0.3048 (0.3048)	LossFusion 0.3048 (0.3048)	
Train Epoch: [222][0/8]	Loss 0.3048 (0.3048)	LossFusion 0.3048 (0.3048)	
Train Epoch: [222][0/8]	Loss 0.3048 (0.3048)	LossFusion 0.3048 (0.3048)	
Train Epoch: [222][7/8]	Loss 0.1709 (0.1917)	LossFusion 0.1709 (0.1917)	
Train Epoch: [222][7/8]	Loss 0.1709 (0.1917)	LossFusion 0.1709 (0.1917)	
Train Epoch: [222][7/8]	Loss 0.1709 (0.1917)	LossFusion 0.1709 (0.1917)	
Train Epoch: [222][7/8]	Loss 0.1709 (0.1917)	LossFusion 0.1709 (0.1917)	
Train Epoch: [222][7/8]	Loss 0.1709 (0.1917)	LossFusion 0.1709 (0.1917)	
Train Epoch: [222][7/8]	Loss 0.1709 (0.1917)	LossFusion 0.1709 (0.1917)	
Train Epoch: [222][7/8]	Loss 0.1709 (0.1917)	LossFusion 0.1709 (0.1917)	
Train Epoch: [222][7/8]	Loss 0.1709 (0.1917)	LossFusion 0.1709 (0.1917)	
R@10:  54.28733825683594     R@50:  80.35207390785217
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.35207390785217
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.35207390785217
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.35207390785217
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.35207390785217
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.35207390785217
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.35207390785217
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
R@10:  54.28733825683594     R@50:  80.35207390785217
Mean Now:  67.31970608234406  Best Mean Before:  69.44918 --------------------
Train Epoch: [223][0/8]	Loss 0.3141 (0.3141)	LossFusion 0.3141 (0.3141)	
Train Epoch: [223][0/8]	Loss 0.3141 (0.3141)	LossFusion 0.3141 (0.3141)	
Train Epoch: [223][0/8]	Loss 0.3141 (0.3141)	LossFusion 0.3141 (0.3141)	
Train Epoch: [223][0/8]	Loss 0.3141 (0.3141)	LossFusion 0.3141 (0.3141)	
Train Epoch: [223][0/8]	Loss 0.3141 (0.3141)	LossFusion 0.3141 (0.3141)	
Train Epoch: [223][0/8]	Loss 0.3141 (0.3141)	LossFusion 0.3141 (0.3141)	
Train Epoch: [223][0/8]	Loss 0.3141 (0.3141)	LossFusion 0.3141 (0.3141)	
Train Epoch: [223][0/8]	Loss 0.3141 (0.3141)	LossFusion 0.3141 (0.3141)	
Train Epoch: [223][7/8]	Loss 0.1641 (0.1941)	LossFusion 0.1641 (0.1941)	
Train Epoch: [223][7/8]	Loss 0.1641 (0.1941)	LossFusion 0.1641 (0.1941)	
Train Epoch: [223][7/8]	Loss 0.1641 (0.1941)	LossFusion 0.1641 (0.1941)	
Train Epoch: [223][7/8]	Loss 0.1641 (0.1941)	LossFusion 0.1641 (0.1941)	
Train Epoch: [223][7/8]	Loss 0.1641 (0.1941)	LossFusion 0.1641 (0.1941)	
Train Epoch: [223][7/8]	Loss 0.1641 (0.1941)	LossFusion 0.1641 (0.1941)	
Train Epoch: [223][7/8]	Loss 0.1641 (0.1941)	LossFusion 0.1641 (0.1941)	
Train Epoch: [223][7/8]	Loss 0.1641 (0.1941)	LossFusion 0.1641 (0.1941)	
R@10:  53.03804874420166     R@50:  79.95457053184509
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.03804874420166     R@50:  79.95457053184509
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.03804874420166     R@50:  79.95457053184509
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.03804874420166     R@50:  79.95457053184509
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.03804874420166     R@50:  79.95457053184509
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.03804874420166     R@50:  79.95457053184509
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.03804874420166     R@50:  79.95457053184509
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.03804874420166     R@50:  79.95457053184509
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
Train Epoch: [224][0/8]	Loss 0.3007 (0.3007)	LossFusion 0.3007 (0.3007)	
Train Epoch: [224][0/8]	Loss 0.3007 (0.3007)	LossFusion 0.3007 (0.3007)	
Train Epoch: [224][0/8]	Loss 0.3007 (0.3007)	LossFusion 0.3007 (0.3007)	
Train Epoch: [224][0/8]	Loss 0.3007 (0.3007)	LossFusion 0.3007 (0.3007)	
Train Epoch: [224][0/8]	Loss 0.3007 (0.3007)	LossFusion 0.3007 (0.3007)	
Train Epoch: [224][0/8]	Loss 0.3007 (0.3007)	LossFusion 0.3007 (0.3007)	
Train Epoch: [224][0/8]	Loss 0.3007 (0.3007)	LossFusion 0.3007 (0.3007)	
Train Epoch: [224][0/8]	Loss 0.3007 (0.3007)	LossFusion 0.3007 (0.3007)	
Train Epoch: [224][7/8]	Loss 0.1689 (0.1928)	LossFusion 0.1689 (0.1928)	
Train Epoch: [224][7/8]	Loss 0.1689 (0.1928)	LossFusion 0.1689 (0.1928)	
Train Epoch: [224][7/8]	Loss 0.1689 (0.1928)	LossFusion 0.1689 (0.1928)	
Train Epoch: [224][7/8]	Loss 0.1689 (0.1928)	LossFusion 0.1689 (0.1928)	
Train Epoch: [224][7/8]	Loss 0.1689 (0.1928)	LossFusion 0.1689 (0.1928)	
Train Epoch: [224][7/8]	Loss 0.1689 (0.1928)	LossFusion 0.1689 (0.1928)	
Train Epoch: [224][7/8]	Loss 0.1689 (0.1928)	LossFusion 0.1689 (0.1928)	
Train Epoch: [224][7/8]	Loss 0.1689 (0.1928)	LossFusion 0.1689 (0.1928)	
R@10:  54.00340557098389     R@50:  80.74957132339478
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.74957132339478
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.74957132339478
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.74957132339478
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.74957132339478
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.74957132339478
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.74957132339478
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.74957132339478
Mean Now:  67.37648844718933  Best Mean Before:  69.44918 --------------------
Train Epoch: [225][0/8]	Loss 0.3066 (0.3066)	LossFusion 0.3066 (0.3066)	
Train Epoch: [225][0/8]	Loss 0.3066 (0.3066)	LossFusion 0.3066 (0.3066)	
Train Epoch: [225][0/8]	Loss 0.3066 (0.3066)	LossFusion 0.3066 (0.3066)	
Train Epoch: [225][0/8]	Loss 0.3066 (0.3066)	LossFusion 0.3066 (0.3066)	
Train Epoch: [225][0/8]	Loss 0.3066 (0.3066)	LossFusion 0.3066 (0.3066)	
Train Epoch: [225][0/8]	Loss 0.3066 (0.3066)	LossFusion 0.3066 (0.3066)	
Train Epoch: [225][0/8]	Loss 0.3066 (0.3066)	LossFusion 0.3066 (0.3066)	
Train Epoch: [225][0/8]	Loss 0.3066 (0.3066)	LossFusion 0.3066 (0.3066)	
Train Epoch: [225][7/8]	Loss 0.1607 (0.1895)	LossFusion 0.1607 (0.1895)	
Train Epoch: [225][7/8]	Loss 0.1607 (0.1895)	LossFusion 0.1607 (0.1895)	
Train Epoch: [225][7/8]	Loss 0.1607 (0.1895)	LossFusion 0.1607 (0.1895)	
Train Epoch: [225][7/8]	Loss 0.1607 (0.1895)	LossFusion 0.1607 (0.1895)	
Train Epoch: [225][7/8]	Loss 0.1607 (0.1895)	LossFusion 0.1607 (0.1895)	
Train Epoch: [225][7/8]	Loss 0.1607 (0.1895)	LossFusion 0.1607 (0.1895)	
Train Epoch: [225][7/8]	Loss 0.1607 (0.1895)	LossFusion 0.1607 (0.1895)	
Train Epoch: [225][7/8]	Loss 0.1607 (0.1895)	LossFusion 0.1607 (0.1895)	
R@10:  52.92447209358215     R@50:  80.01135587692261
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  52.92447209358215     R@50:  80.01135587692261
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  52.92447209358215     R@50:  80.01135587692261
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  52.92447209358215     R@50:  80.01135587692261
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  52.92447209358215     R@50:  80.01135587692261
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  52.92447209358215     R@50:  80.01135587692261
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  52.92447209358215     R@50:  80.01135587692261
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  52.92447209358215     R@50:  80.01135587692261
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
Train Epoch: [226][0/8]	Loss 0.2868 (0.2868)	LossFusion 0.2868 (0.2868)	
Train Epoch: [226][0/8]	Loss 0.2868 (0.2868)	LossFusion 0.2868 (0.2868)	
Train Epoch: [226][0/8]	Loss 0.2868 (0.2868)	LossFusion 0.2868 (0.2868)	
Train Epoch: [226][0/8]	Loss 0.2868 (0.2868)	LossFusion 0.2868 (0.2868)	
Train Epoch: [226][0/8]	Loss 0.2868 (0.2868)	LossFusion 0.2868 (0.2868)	
Train Epoch: [226][0/8]	Loss 0.2868 (0.2868)	LossFusion 0.2868 (0.2868)	
Train Epoch: [226][0/8]	Loss 0.2868 (0.2868)	LossFusion 0.2868 (0.2868)	
Train Epoch: [226][0/8]	Loss 0.2868 (0.2868)	LossFusion 0.2868 (0.2868)	
Train Epoch: [226][7/8]	Loss 0.1483 (0.1820)	LossFusion 0.1483 (0.1820)	
Train Epoch: [226][7/8]	Loss 0.1483 (0.1820)	LossFusion 0.1483 (0.1820)	
Train Epoch: [226][7/8]	Loss 0.1483 (0.1820)	LossFusion 0.1483 (0.1820)	
Train Epoch: [226][7/8]	Loss 0.1483 (0.1820)	LossFusion 0.1483 (0.1820)	
Train Epoch: [226][7/8]	Loss 0.1483 (0.1820)	LossFusion 0.1483 (0.1820)	Train Epoch: [226][7/8]	Loss 0.1483 (0.1820)	LossFusion 0.1483 (0.1820)	

Train Epoch: [226][7/8]	Loss 0.1483 (0.1820)	LossFusion 0.1483 (0.1820)	
Train Epoch: [226][7/8]	Loss 0.1483 (0.1820)	LossFusion 0.1483 (0.1820)	
R@10:  53.49233150482178     R@50:  80.40885925292969
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.40885925292969
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.40885925292969
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.40885925292969
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.40885925292969
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  R@10: 53.49233150482178      R@50:  53.4923315048217880.40885925292969 
    R@50:  80.40885925292969Mean Now: 
 66.95059537887573  Best Mean Before:  Mean Now: 69.44918  66.95059537887573-------------------- 
 Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.40885925292969
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
Train Epoch: [227][0/8]	Loss 0.2708 (0.2708)	LossFusion 0.2708 (0.2708)	
Train Epoch: [227][0/8]	Loss 0.2708 (0.2708)	LossFusion 0.2708 (0.2708)	
Train Epoch: [227][0/8]	Loss 0.2708 (0.2708)	LossFusion 0.2708 (0.2708)	
Train Epoch: [227][0/8]	Loss 0.2708 (0.2708)	LossFusion 0.2708 (0.2708)	
Train Epoch: [227][0/8]	Loss 0.2708 (0.2708)	LossFusion 0.2708 (0.2708)	
Train Epoch: [227][0/8]	Loss 0.2708 (0.2708)	LossFusion 0.2708 (0.2708)	
Train Epoch: [227][0/8]	Loss 0.2708 (0.2708)	LossFusion 0.2708 (0.2708)	
Train Epoch: [227][0/8]	Loss 0.2708 (0.2708)	LossFusion 0.2708 (0.2708)	
Train Epoch: [227][7/8]	Loss 0.1446 (0.1764)	LossFusion 0.1446 (0.1764)	
Train Epoch: [227][7/8]	Loss 0.1446 (0.1764)	LossFusion 0.1446 (0.1764)	
Train Epoch: [227][7/8]	Loss 0.1446 (0.1764)	LossFusion 0.1446 (0.1764)	
Train Epoch: [227][7/8]	Loss 0.1446 (0.1764)	LossFusion 0.1446 (0.1764)	
Train Epoch: [227][7/8]	Loss 0.1446 (0.1764)	LossFusion 0.1446 (0.1764)	
Train Epoch: [227][7/8]	Loss 0.1446 (0.1764)	LossFusion 0.1446 (0.1764)	
Train Epoch: [227][7/8]	Loss 0.1446 (0.1764)	LossFusion 0.1446 (0.1764)	
Train Epoch: [227][7/8]	Loss 0.1446 (0.1764)	LossFusion 0.1446 (0.1764)	
R@10:  53.37876081466675     R@50:  80.06814122200012
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.06814122200012
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.06814122200012
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.06814122200012
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.06814122200012
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------R@10: 
 53.37876081466675     R@50:  80.06814122200012
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.06814122200012
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  80.06814122200012
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
Train Epoch: [228][0/8]	Loss 0.2847 (0.2847)	LossFusion 0.2847 (0.2847)	
Train Epoch: [228][0/8]	Loss 0.2847 (0.2847)	LossFusion 0.2847 (0.2847)	
Train Epoch: [228][0/8]	Loss 0.2847 (0.2847)	LossFusion 0.2847 (0.2847)	
Train Epoch: [228][0/8]	Loss 0.2847 (0.2847)	LossFusion 0.2847 (0.2847)	
Train Epoch: [228][0/8]	Loss 0.2847 (0.2847)	LossFusion 0.2847 (0.2847)	
Train Epoch: [228][0/8]	Loss 0.2847 (0.2847)	LossFusion 0.2847 (0.2847)	
Train Epoch: [228][0/8]	Loss 0.2847 (0.2847)	LossFusion 0.2847 (0.2847)	
Train Epoch: [228][0/8]	Loss 0.2847 (0.2847)	LossFusion 0.2847 (0.2847)	
Train Epoch: [228][7/8]	Loss 0.1306 (0.1744)	LossFusion 0.1306 (0.1744)	
Train Epoch: [228][7/8]	Loss 0.1306 (0.1744)	LossFusion 0.1306 (0.1744)	
Train Epoch: [228][7/8]	Loss 0.1306 (0.1744)	LossFusion 0.1306 (0.1744)	
Train Epoch: [228][7/8]	Loss 0.1306 (0.1744)	LossFusion 0.1306 (0.1744)	
Train Epoch: [228][7/8]	Loss 0.1306 (0.1744)	LossFusion 0.1306 (0.1744)	
Train Epoch: [228][7/8]	Loss 0.1306 (0.1744)	LossFusion 0.1306 (0.1744)	
Train Epoch: [228][7/8]	Loss 0.1306 (0.1744)	LossFusion 0.1306 (0.1744)	
Train Epoch: [228][7/8]	Loss 0.1306 (0.1744)	LossFusion 0.1306 (0.1744)	
R@10:  53.71947884559631     R@50:  80.12492656707764
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.12492656707764
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.12492656707764
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.12492656707764
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.12492656707764
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.12492656707764
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.12492656707764
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.12492656707764
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
Train Epoch: [229][0/8]	Loss 0.3018 (0.3018)	LossFusion 0.3018 (0.3018)	
Train Epoch: [229][0/8]	Loss 0.3018 (0.3018)	LossFusion 0.3018 (0.3018)	
Train Epoch: [229][0/8]	Loss 0.3018 (0.3018)	LossFusion 0.3018 (0.3018)	
Train Epoch: [229][0/8]	Loss 0.3018 (0.3018)	LossFusion 0.3018 (0.3018)	
Train Epoch: [229][0/8]	Loss 0.3018 (0.3018)	LossFusion 0.3018 (0.3018)	
Train Epoch: [229][0/8]	Loss 0.3018 (0.3018)	LossFusion 0.3018 (0.3018)	
Train Epoch: [229][0/8]	Loss 0.3018 (0.3018)	LossFusion 0.3018 (0.3018)	
Train Epoch: [229][0/8]	Loss 0.3018 (0.3018)	LossFusion 0.3018 (0.3018)	
Train Epoch: [229][7/8]	Loss 0.1771 (0.1820)	LossFusion 0.1771 (0.1820)	
Train Epoch: [229][7/8]	Loss 0.1771 (0.1820)	LossFusion 0.1771 (0.1820)	
Train Epoch: [229][7/8]	Loss 0.1771 (0.1820)	LossFusion 0.1771 (0.1820)	
Train Epoch: [229][7/8]	Loss 0.1771 (0.1820)	LossFusion 0.1771 (0.1820)	
Train Epoch: [229][7/8]	Loss 0.1771 (0.1820)	LossFusion 0.1771 (0.1820)	
Train Epoch: [229][7/8]	Loss 0.1771 (0.1820)	LossFusion 0.1771 (0.1820)	
Train Epoch: [229][7/8]	Loss 0.1771 (0.1820)	LossFusion 0.1771 (0.1820)	
Train Epoch: [229][7/8]	Loss 0.1771 (0.1820)	LossFusion 0.1771 (0.1820)	
R@10:  53.94662022590637     R@50:  80.12492656707764
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.12492656707764
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.12492656707764
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.12492656707764
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.12492656707764
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.12492656707764
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.12492656707764
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  80.12492656707764
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
Train Epoch: [230][0/8]	Loss 0.2950 (0.2950)	LossFusion 0.2950 (0.2950)	
Train Epoch: [230][0/8]	Loss 0.2950 (0.2950)	LossFusion 0.2950 (0.2950)	
Train Epoch: [230][0/8]	Loss 0.2950 (0.2950)	LossFusion 0.2950 (0.2950)	
Train Epoch: [230][0/8]	Loss 0.2950 (0.2950)	LossFusion 0.2950 (0.2950)	
Train Epoch: [230][0/8]	Loss 0.2950 (0.2950)	LossFusion 0.2950 (0.2950)	
Train Epoch: [230][0/8]	Loss 0.2950 (0.2950)	LossFusion 0.2950 (0.2950)	
Train Epoch: [230][0/8]	Loss 0.2950 (0.2950)	LossFusion 0.2950 (0.2950)	
Train Epoch: [230][0/8]	Loss 0.2950 (0.2950)	LossFusion 0.2950 (0.2950)	
Train Epoch: [230][7/8]	Loss 0.1597 (0.1823)	LossFusion 0.1597 (0.1823)	
Train Epoch: [230][7/8]	Loss 0.1597 (0.1823)	LossFusion 0.1597 (0.1823)	
Train Epoch: [230][7/8]	Loss 0.1597 (0.1823)	LossFusion 0.1597 (0.1823)	
Train Epoch: [230][7/8]	Loss 0.1597 (0.1823)	LossFusion 0.1597 (0.1823)	
Train Epoch: [230][7/8]	Loss 0.1597 (0.1823)	LossFusion 0.1597 (0.1823)	
Train Epoch: [230][7/8]	Loss 0.1597 (0.1823)	LossFusion 0.1597 (0.1823)	
Train Epoch: [230][7/8]	Loss 0.1597 (0.1823)	LossFusion 0.1597 (0.1823)	
Train Epoch: [230][7/8]	Loss 0.1597 (0.1823)	LossFusion 0.1597 (0.1823)	
R@10:  53.26519012451172     R@50:  79.89778518676758
Mean Now:  66.58148765563965  Best Mean Before:  69.44918 --------------------
R@10:  53.26519012451172     R@50:  79.89778518676758
Mean Now:  66.58148765563965  Best Mean Before:  69.44918 --------------------
R@10:  53.26519012451172     R@50:  79.89778518676758
Mean Now:  66.58148765563965  Best Mean Before:  69.44918 --------------------
R@10:  53.26519012451172     R@50:  79.89778518676758
Mean Now:  66.58148765563965  Best Mean Before:  69.44918 --------------------
R@10:  53.26519012451172     R@50:  79.89778518676758
Mean Now:  66.58148765563965  Best Mean Before:  69.44918 --------------------
R@10:  53.26519012451172     R@50:  79.89778518676758
Mean Now:  66.58148765563965  Best Mean Before:  69.44918 --------------------
R@10:  53.26519012451172     R@50:  79.89778518676758
Mean Now:  66.58148765563965  Best Mean Before:  69.44918 --------------------
R@10:  53.26519012451172     R@50:  79.89778518676758
Mean Now:  66.58148765563965  Best Mean Before:  69.44918 --------------------
Train Epoch: [231][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [231][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [231][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [231][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [231][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [231][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [231][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [231][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [231][7/8]	Loss 0.1650 (0.1760)	LossFusion 0.1650 (0.1760)	
Train Epoch: [231][7/8]	Loss 0.1650 (0.1760)	LossFusion 0.1650 (0.1760)	
Train Epoch: [231][7/8]	Loss 0.1650 (0.1760)	LossFusion 0.1650 (0.1760)	
Train Epoch: [231][7/8]	Loss 0.1650 (0.1760)	LossFusion 0.1650 (0.1760)	
Train Epoch: [231][7/8]	Loss 0.1650 (0.1760)	LossFusion 0.1650 (0.1760)	
Train Epoch: [231][7/8]	Loss 0.1650 (0.1760)	LossFusion 0.1650 (0.1760)	
Train Epoch: [231][7/8]	Loss 0.1650 (0.1760)	LossFusion 0.1650 (0.1760)	
Train Epoch: [231][7/8]	Loss 0.1650 (0.1760)	LossFusion 0.1650 (0.1760)	
R@10:  53.43554615974426     R@50:  79.84099984169006
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.84099984169006
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.84099984169006
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.84099984169006
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.84099984169006
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.84099984169006
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.84099984169006
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.84099984169006
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
Train Epoch: [232][0/8]	Loss 0.2631 (0.2631)	LossFusion 0.2631 (0.2631)	
Train Epoch: [232][0/8]	Loss 0.2631 (0.2631)	LossFusion 0.2631 (0.2631)	
Train Epoch: [232][0/8]	Loss 0.2631 (0.2631)	LossFusion 0.2631 (0.2631)	
Train Epoch: [232][0/8]	Loss 0.2631 (0.2631)	LossFusion 0.2631 (0.2631)	
Train Epoch: [232][0/8]	Loss 0.2631 (0.2631)	LossFusion 0.2631 (0.2631)	
Train Epoch: [232][0/8]	Loss 0.2631 (0.2631)	LossFusion 0.2631 (0.2631)	
Train Epoch: [232][0/8]	Loss 0.2631 (0.2631)	LossFusion 0.2631 (0.2631)	
Train Epoch: [232][0/8]	Loss 0.2631 (0.2631)	LossFusion 0.2631 (0.2631)	
Train Epoch: [232][7/8]	Loss 0.1420 (0.1691)	LossFusion 0.1420 (0.1691)	
Train Epoch: [232][7/8]	Loss 0.1420 (0.1691)	LossFusion 0.1420 (0.1691)	
Train Epoch: [232][7/8]	Loss 0.1420 (0.1691)	LossFusion 0.1420 (0.1691)	
Train Epoch: [232][7/8]	Loss 0.1420 (0.1691)	LossFusion 0.1420 (0.1691)	
Train Epoch: [232][7/8]	Loss 0.1420 (0.1691)	LossFusion 0.1420 (0.1691)	
Train Epoch: [232][7/8]	Loss 0.1420 (0.1691)	LossFusion 0.1420 (0.1691)	
Train Epoch: [232][7/8]	Loss 0.1420 (0.1691)	LossFusion 0.1420 (0.1691)	
Train Epoch: [232][7/8]	Loss 0.1420 (0.1691)	LossFusion 0.1420 (0.1691)	
R@10:  53.43554615974426     R@50:  80.23850321769714
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.23850321769714
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.23850321769714
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.23850321769714
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.23850321769714
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.23850321769714
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.23850321769714
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.23850321769714
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
Train Epoch: [233][0/8]	Loss 0.3009 (0.3009)	LossFusion 0.3009 (0.3009)	
Train Epoch: [233][0/8]	Loss 0.3009 (0.3009)	LossFusion 0.3009 (0.3009)	
Train Epoch: [233][0/8]	Loss 0.3009 (0.3009)	LossFusion 0.3009 (0.3009)	
Train Epoch: [233][0/8]	Loss 0.3009 (0.3009)	LossFusion 0.3009 (0.3009)	
Train Epoch: [233][0/8]	Loss 0.3009 (0.3009)	LossFusion 0.3009 (0.3009)	
Train Epoch: [233][0/8]	Loss 0.3009 (0.3009)	LossFusion 0.3009 (0.3009)	
Train Epoch: [233][0/8]	Loss 0.3009 (0.3009)	LossFusion 0.3009 (0.3009)	
Train Epoch: [233][0/8]	Loss 0.3009 (0.3009)	LossFusion 0.3009 (0.3009)	
Train Epoch: [233][7/8]	Loss 0.1670 (0.1804)	LossFusion 0.1670 (0.1804)	
Train Epoch: [233][7/8]	Loss 0.1670 (0.1804)	LossFusion 0.1670 (0.1804)	
Train Epoch: [233][7/8]	Loss 0.1670 (0.1804)	LossFusion 0.1670 (0.1804)	
Train Epoch: [233][7/8]	Loss 0.1670 (0.1804)	LossFusion 0.1670 (0.1804)	
Train Epoch: [233][7/8]	Loss 0.1670 (0.1804)	LossFusion 0.1670 (0.1804)	
Train Epoch: [233][7/8]	Loss 0.1670 (0.1804)	LossFusion 0.1670 (0.1804)	
Train Epoch: [233][7/8]	Loss 0.1670 (0.1804)	LossFusion 0.1670 (0.1804)	
Train Epoch: [233][7/8]	Loss 0.1670 (0.1804)	LossFusion 0.1670 (0.1804)	
R@10:  53.83304953575134     R@50:  80.40885925292969
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.40885925292969
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.40885925292969
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.40885925292969
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.40885925292969
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.40885925292969
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.40885925292969
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.40885925292969
Mean Now:  67.12095439434052  Best Mean Before:  69.44918 --------------------
Train Epoch: [234][0/8]	Loss 0.2718 (0.2718)	LossFusion 0.2718 (0.2718)	
Train Epoch: [234][0/8]	Loss 0.2718 (0.2718)	LossFusion 0.2718 (0.2718)	
Train Epoch: [234][0/8]	Loss 0.2718 (0.2718)	LossFusion 0.2718 (0.2718)	
Train Epoch: [234][0/8]	Loss 0.2718 (0.2718)	LossFusion 0.2718 (0.2718)	
Train Epoch: [234][0/8]	Loss 0.2718 (0.2718)	LossFusion 0.2718 (0.2718)	
Train Epoch: [234][0/8]	Loss 0.2718 (0.2718)	LossFusion 0.2718 (0.2718)	
Train Epoch: [234][0/8]	Loss 0.2718 (0.2718)	LossFusion 0.2718 (0.2718)	
Train Epoch: [234][0/8]	Loss 0.2718 (0.2718)	LossFusion 0.2718 (0.2718)	
Train Epoch: [234][7/8]	Loss 0.1444 (0.1700)	LossFusion 0.1444 (0.1700)	
Train Epoch: [234][7/8]	Loss 0.1444 (0.1700)	LossFusion 0.1444 (0.1700)	
Train Epoch: [234][7/8]	Loss 0.1444 (0.1700)	LossFusion 0.1444 (0.1700)	
Train Epoch: [234][7/8]	Loss 0.1444 (0.1700)	LossFusion 0.1444 (0.1700)	
Train Epoch: [234][7/8]	Loss 0.1444 (0.1700)	LossFusion 0.1444 (0.1700)	
Train Epoch: [234][7/8]	Loss 0.1444 (0.1700)	LossFusion 0.1444 (0.1700)	
Train Epoch: [234][7/8]	Loss 0.1444 (0.1700)	LossFusion 0.1444 (0.1700)	
Train Epoch: [234][7/8]	Loss 0.1444 (0.1700)	LossFusion 0.1444 (0.1700)	
R@10:  53.43554615974426     R@50:  80.12492656707764
Mean Now:  66.78023636341095  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.12492656707764
Mean Now:  66.78023636341095  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.12492656707764
Mean Now:  66.78023636341095  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.12492656707764
Mean Now:  66.78023636341095  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.12492656707764
Mean Now:  66.78023636341095  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.12492656707764
Mean Now:  66.78023636341095  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.12492656707764
Mean Now:  66.78023636341095  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.12492656707764
Mean Now:  66.78023636341095  Best Mean Before:  69.44918 --------------------
Train Epoch: [235][0/8]	Loss 0.2731 (0.2731)	LossFusion 0.2731 (0.2731)	
Train Epoch: [235][0/8]	Loss 0.2731 (0.2731)	LossFusion 0.2731 (0.2731)	
Train Epoch: [235][0/8]	Loss 0.2731 (0.2731)	LossFusion 0.2731 (0.2731)	
Train Epoch: [235][0/8]	Loss 0.2731 (0.2731)	LossFusion 0.2731 (0.2731)	
Train Epoch: [235][0/8]	Loss 0.2731 (0.2731)	LossFusion 0.2731 (0.2731)	
Train Epoch: [235][0/8]	Loss 0.2731 (0.2731)	LossFusion 0.2731 (0.2731)	
Train Epoch: [235][0/8]	Loss 0.2731 (0.2731)	LossFusion 0.2731 (0.2731)	
Train Epoch: [235][0/8]	Loss 0.2731 (0.2731)	LossFusion 0.2731 (0.2731)	
Train Epoch: [235][7/8]	Loss 0.1325 (0.1666)	LossFusion 0.1325 (0.1666)	
Train Epoch: [235][7/8]	Loss 0.1325 (0.1666)	LossFusion 0.1325 (0.1666)	
Train Epoch: [235][7/8]	Loss 0.1325 (0.1666)	LossFusion 0.1325 (0.1666)	
Train Epoch: [235][7/8]	Loss 0.1325 (0.1666)	LossFusion 0.1325 (0.1666)	
Train Epoch: [235][7/8]	Loss 0.1325 (0.1666)	LossFusion 0.1325 (0.1666)	
Train Epoch: [235][7/8]	Loss 0.1325 (0.1666)	LossFusion 0.1325 (0.1666)	
Train Epoch: [235][7/8]	Loss 0.1325 (0.1666)	LossFusion 0.1325 (0.1666)	
Train Epoch: [235][7/8]	Loss 0.1325 (0.1666)	LossFusion 0.1325 (0.1666)	
R@10:  53.6626935005188     R@50:  80.52242994308472
Mean Now:  67.09256172180176  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.52242994308472
Mean Now:  67.09256172180176  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.52242994308472
Mean Now:  67.09256172180176  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.52242994308472
Mean Now:  67.09256172180176  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.52242994308472
Mean Now:  67.09256172180176  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.52242994308472
Mean Now:  67.09256172180176  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.52242994308472
Mean Now:  67.09256172180176  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.52242994308472
Mean Now:  67.09256172180176  Best Mean Before:  69.44918 --------------------
Train Epoch: [236][0/8]	Loss 0.2740 (0.2740)	LossFusion 0.2740 (0.2740)	
Train Epoch: [236][0/8]	Loss 0.2740 (0.2740)	LossFusion 0.2740 (0.2740)	
Train Epoch: [236][0/8]	Loss 0.2740 (0.2740)	LossFusion 0.2740 (0.2740)	
Train Epoch: [236][0/8]	Loss 0.2740 (0.2740)	LossFusion 0.2740 (0.2740)	
Train Epoch: [236][0/8]	Loss 0.2740 (0.2740)	LossFusion 0.2740 (0.2740)	
Train Epoch: [236][0/8]	Loss 0.2740 (0.2740)	LossFusion 0.2740 (0.2740)	
Train Epoch: [236][0/8]	Loss 0.2740 (0.2740)	LossFusion 0.2740 (0.2740)	
Train Epoch: [236][0/8]	Loss 0.2740 (0.2740)	LossFusion 0.2740 (0.2740)	
Train Epoch: [236][7/8]	Loss 0.1501 (0.1718)	LossFusion 0.1501 (0.1718)	
Train Epoch: [236][7/8]	Loss 0.1501 (0.1718)	LossFusion 0.1501 (0.1718)	
Train Epoch: [236][7/8]	Loss 0.1501 (0.1718)	LossFusion 0.1501 (0.1718)	
Train Epoch: [236][7/8]	Loss 0.1501 (0.1718)	LossFusion 0.1501 (0.1718)	
Train Epoch: [236][7/8]	Loss 0.1501 (0.1718)	LossFusion 0.1501 (0.1718)	
Train Epoch: [236][7/8]	Loss 0.1501 (0.1718)	LossFusion 0.1501 (0.1718)	
Train Epoch: [236][7/8]	Loss 0.1501 (0.1718)	LossFusion 0.1501 (0.1718)	
Train Epoch: [236][7/8]	Loss 0.1501 (0.1718)	LossFusion 0.1501 (0.1718)	
R@10:  53.605908155441284     R@50:  80.29528856277466
Mean Now:  66.95059835910797  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.29528856277466
Mean Now:  66.95059835910797  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.29528856277466
Mean Now:  66.95059835910797  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.29528856277466
Mean Now:  66.95059835910797  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.29528856277466
Mean Now:  66.95059835910797  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.29528856277466
Mean Now:  66.95059835910797  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.29528856277466
Mean Now:  66.95059835910797  Best Mean Before:  69.44918 --------------------
R@10:  53.605908155441284     R@50:  80.29528856277466
Mean Now:  66.95059835910797  Best Mean Before:  69.44918 --------------------
Train Epoch: [237][0/8]	Loss 0.2897 (0.2897)	LossFusion 0.2897 (0.2897)	
Train Epoch: [237][0/8]	Loss 0.2897 (0.2897)	LossFusion 0.2897 (0.2897)	
Train Epoch: [237][0/8]	Loss 0.2897 (0.2897)	LossFusion 0.2897 (0.2897)	
Train Epoch: [237][0/8]	Loss 0.2897 (0.2897)	LossFusion 0.2897 (0.2897)	
Train Epoch: [237][0/8]	Loss 0.2897 (0.2897)	LossFusion 0.2897 (0.2897)	
Train Epoch: [237][0/8]	Loss 0.2897 (0.2897)	LossFusion 0.2897 (0.2897)	
Train Epoch: [237][0/8]	Loss 0.2897 (0.2897)	LossFusion 0.2897 (0.2897)	
Train Epoch: [237][0/8]	Loss 0.2897 (0.2897)	LossFusion 0.2897 (0.2897)	
Train Epoch: [237][7/8]	Loss 0.1352 (0.1709)	LossFusion 0.1352 (0.1709)	
Train Epoch: [237][7/8]	Loss 0.1352 (0.1709)	LossFusion 0.1352 (0.1709)	
Train Epoch: [237][7/8]	Loss 0.1352 (0.1709)	LossFusion 0.1352 (0.1709)	
Train Epoch: [237][7/8]	Loss 0.1352 (0.1709)	LossFusion 0.1352 (0.1709)	
Train Epoch: [237][7/8]	Loss 0.1352 (0.1709)	LossFusion 0.1352 (0.1709)	
Train Epoch: [237][7/8]	Loss 0.1352 (0.1709)	LossFusion 0.1352 (0.1709)	
Train Epoch: [237][7/8]	Loss 0.1352 (0.1709)	LossFusion 0.1352 (0.1709)	
Train Epoch: [237][7/8]	Loss 0.1352 (0.1709)	LossFusion 0.1352 (0.1709)	
R@10:  53.77626419067383     R@50:  80.18171787261963
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.18171787261963
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.18171787261963
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.18171787261963
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.18171787261963
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.18171787261963
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.18171787261963
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  80.18171787261963
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
Train Epoch: [238][0/8]	Loss 0.2743 (0.2743)	LossFusion 0.2743 (0.2743)	
Train Epoch: [238][0/8]	Loss 0.2743 (0.2743)	LossFusion 0.2743 (0.2743)	
Train Epoch: [238][0/8]	Loss 0.2743 (0.2743)	LossFusion 0.2743 (0.2743)	
Train Epoch: [238][0/8]	Loss 0.2743 (0.2743)	LossFusion 0.2743 (0.2743)	
Train Epoch: [238][0/8]	Loss 0.2743 (0.2743)	LossFusion 0.2743 (0.2743)	
Train Epoch: [238][0/8]	Loss 0.2743 (0.2743)	LossFusion 0.2743 (0.2743)	
Train Epoch: [238][0/8]	Loss 0.2743 (0.2743)	LossFusion 0.2743 (0.2743)	
Train Epoch: [238][0/8]	Loss 0.2743 (0.2743)	LossFusion 0.2743 (0.2743)	
Train Epoch: [238][7/8]	Loss 0.1353 (0.1747)	LossFusion 0.1353 (0.1747)	
Train Epoch: [238][7/8]	Loss 0.1353 (0.1747)	LossFusion 0.1353 (0.1747)	
Train Epoch: [238][7/8]	Loss 0.1353 (0.1747)	LossFusion 0.1353 (0.1747)	
Train Epoch: [238][7/8]	Loss 0.1353 (0.1747)	LossFusion 0.1353 (0.1747)	
Train Epoch: [238][7/8]	Loss 0.1353 (0.1747)	LossFusion 0.1353 (0.1747)	
Train Epoch: [238][7/8]	Loss 0.1353 (0.1747)	LossFusion 0.1353 (0.1747)	
Train Epoch: [238][7/8]	Loss 0.1353 (0.1747)	LossFusion 0.1353 (0.1747)	
Train Epoch: [238][7/8]	Loss 0.1353 (0.1747)	LossFusion 0.1353 (0.1747)	
R@10:  53.88983488082886     R@50:  80.40885925292969
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.40885925292969
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.40885925292969
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.40885925292969
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.40885925292969
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.40885925292969
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.40885925292969
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  80.40885925292969
Mean Now:  67.14934706687927  Best Mean Before:  69.44918 --------------------
Train Epoch: [239][0/8]	Loss 0.2791 (0.2791)	LossFusion 0.2791 (0.2791)	
Train Epoch: [239][0/8]	Loss 0.2791 (0.2791)	LossFusion 0.2791 (0.2791)	
Train Epoch: [239][0/8]	Loss 0.2791 (0.2791)	LossFusion 0.2791 (0.2791)	
Train Epoch: [239][0/8]	Loss 0.2791 (0.2791)	LossFusion 0.2791 (0.2791)	
Train Epoch: [239][0/8]	Loss 0.2791 (0.2791)	LossFusion 0.2791 (0.2791)	
Train Epoch: [239][0/8]	Loss 0.2791 (0.2791)	LossFusion 0.2791 (0.2791)	
Train Epoch: [239][0/8]	Loss 0.2791 (0.2791)	LossFusion 0.2791 (0.2791)	
Train Epoch: [239][0/8]	Loss 0.2791 (0.2791)	LossFusion 0.2791 (0.2791)	
Train Epoch: [239][7/8]	Loss 0.1320 (0.1641)	LossFusion 0.1320 (0.1641)	
Train Epoch: [239][7/8]	Loss 0.1320 (0.1641)	LossFusion 0.1320 (0.1641)	
Train Epoch: [239][7/8]	Loss 0.1320 (0.1641)	LossFusion 0.1320 (0.1641)	
Train Epoch: [239][7/8]	Loss 0.1320 (0.1641)	LossFusion 0.1320 (0.1641)	
Train Epoch: [239][7/8]	Loss 0.1320 (0.1641)	LossFusion 0.1320 (0.1641)	
Train Epoch: [239][7/8]	Loss 0.1320 (0.1641)	LossFusion 0.1320 (0.1641)	
Train Epoch: [239][7/8]	Loss 0.1320 (0.1641)	LossFusion 0.1320 (0.1641)	
Train Epoch: [239][7/8]	Loss 0.1320 (0.1641)	LossFusion 0.1320 (0.1641)	
R@10:  53.6626935005188     R@50:  80.06814122200012
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.06814122200012
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.06814122200012
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.06814122200012
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.06814122200012
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.06814122200012
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.06814122200012
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  80.06814122200012
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
Train Epoch: [240][0/8]	Loss 0.2464 (0.2464)	LossFusion 0.2464 (0.2464)	
Train Epoch: [240][0/8]	Loss 0.2464 (0.2464)	LossFusion 0.2464 (0.2464)	
Train Epoch: [240][0/8]	Loss 0.2464 (0.2464)	LossFusion 0.2464 (0.2464)	
Train Epoch: [240][0/8]	Loss 0.2464 (0.2464)	LossFusion 0.2464 (0.2464)	
Train Epoch: [240][0/8]	Loss 0.2464 (0.2464)	LossFusion 0.2464 (0.2464)	
Train Epoch: [240][0/8]	Loss 0.2464 (0.2464)	LossFusion 0.2464 (0.2464)	
Train Epoch: [240][0/8]	Loss 0.2464 (0.2464)	LossFusion 0.2464 (0.2464)	
Train Epoch: [240][0/8]	Loss 0.2464 (0.2464)	LossFusion 0.2464 (0.2464)	
Train Epoch: [240][7/8]	Loss 0.1215 (0.1557)	LossFusion 0.1215 (0.1557)	
Train Epoch: [240][7/8]	Loss 0.1215 (0.1557)	LossFusion 0.1215 (0.1557)	
Train Epoch: [240][7/8]	Loss 0.1215 (0.1557)	LossFusion 0.1215 (0.1557)	
Train Epoch: [240][7/8]	Loss 0.1215 (0.1557)	LossFusion 0.1215 (0.1557)	
Train Epoch: [240][7/8]	Loss 0.1215 (0.1557)	LossFusion 0.1215 (0.1557)	
Train Epoch: [240][7/8]	Loss 0.1215 (0.1557)	LossFusion 0.1215 (0.1557)	
Train Epoch: [240][7/8]	Loss 0.1215 (0.1557)	LossFusion 0.1215 (0.1557)	
Train Epoch: [240][7/8]	Loss 0.1215 (0.1557)	LossFusion 0.1215 (0.1557)	
R@10:  53.32197546958923     R@50:  80.35207390785217
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.35207390785217
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.35207390785217
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.35207390785217
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.35207390785217
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.35207390785217
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.35207390785217
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.35207390785217
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
Train Epoch: [241][0/8]	Loss 0.2573 (0.2573)	LossFusion 0.2573 (0.2573)	
Train Epoch: [241][0/8]	Loss 0.2573 (0.2573)	LossFusion 0.2573 (0.2573)	
Train Epoch: [241][0/8]	Loss 0.2573 (0.2573)	LossFusion 0.2573 (0.2573)	
Train Epoch: [241][0/8]	Loss 0.2573 (0.2573)	LossFusion 0.2573 (0.2573)	
Train Epoch: [241][0/8]	Loss 0.2573 (0.2573)	LossFusion 0.2573 (0.2573)	
Train Epoch: [241][0/8]	Loss 0.2573 (0.2573)	LossFusion 0.2573 (0.2573)	
Train Epoch: [241][0/8]	Loss 0.2573 (0.2573)	LossFusion 0.2573 (0.2573)	
Train Epoch: [241][0/8]	Loss 0.2573 (0.2573)	LossFusion 0.2573 (0.2573)	
Train Epoch: [241][7/8]	Loss 0.1381 (0.1611)	LossFusion 0.1381 (0.1611)	
Train Epoch: [241][7/8]	Loss 0.1381 (0.1611)	LossFusion 0.1381 (0.1611)	
Train Epoch: [241][7/8]	Loss 0.1381 (0.1611)	LossFusion 0.1381 (0.1611)	
Train Epoch: [241][7/8]	Loss 0.1381 (0.1611)	LossFusion 0.1381 (0.1611)	
Train Epoch: [241][7/8]	Loss 0.1381 (0.1611)	LossFusion 0.1381 (0.1611)	
Train Epoch: [241][7/8]	Loss 0.1381 (0.1611)	LossFusion 0.1381 (0.1611)	
Train Epoch: [241][7/8]	Loss 0.1381 (0.1611)	LossFusion 0.1381 (0.1611)	
Train Epoch: [241][7/8]	Loss 0.1381 (0.1611)	LossFusion 0.1381 (0.1611)	
R@10:  54.17376756668091     R@50:  79.67064380645752
Mean Now:  66.92220568656921  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.67064380645752
Mean Now:  66.92220568656921  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.67064380645752
Mean Now:  66.92220568656921  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.67064380645752
Mean Now:  66.92220568656921  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.67064380645752
Mean Now:  66.92220568656921  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.67064380645752
Mean Now:  66.92220568656921  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.67064380645752
Mean Now:  66.92220568656921  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.67064380645752
Mean Now:  66.92220568656921  Best Mean Before:  69.44918 --------------------
Train Epoch: [242][0/8]	Loss 0.2647 (0.2647)	LossFusion 0.2647 (0.2647)	
Train Epoch: [242][0/8]	Loss 0.2647 (0.2647)	LossFusion 0.2647 (0.2647)	
Train Epoch: [242][0/8]	Loss 0.2647 (0.2647)	LossFusion 0.2647 (0.2647)	
Train Epoch: [242][0/8]	Loss 0.2647 (0.2647)	LossFusion 0.2647 (0.2647)	
Train Epoch: [242][0/8]	Loss 0.2647 (0.2647)	LossFusion 0.2647 (0.2647)	
Train Epoch: [242][0/8]	Loss 0.2647 (0.2647)	LossFusion 0.2647 (0.2647)	
Train Epoch: [242][0/8]	Loss 0.2647 (0.2647)	LossFusion 0.2647 (0.2647)	
Train Epoch: [242][0/8]	Loss 0.2647 (0.2647)	LossFusion 0.2647 (0.2647)	
Train Epoch: [242][7/8]	Loss 0.1529 (0.1688)	LossFusion 0.1529 (0.1688)	
Train Epoch: [242][7/8]	Loss 0.1529 (0.1688)	LossFusion 0.1529 (0.1688)	
Train Epoch: [242][7/8]	Loss 0.1529 (0.1688)	LossFusion 0.1529 (0.1688)	
Train Epoch: [242][7/8]	Loss 0.1529 (0.1688)	LossFusion 0.1529 (0.1688)	
Train Epoch: [242][7/8]	Loss 0.1529 (0.1688)	LossFusion 0.1529 (0.1688)	
Train Epoch: [242][7/8]	Loss 0.1529 (0.1688)	LossFusion 0.1529 (0.1688)	
Train Epoch: [242][7/8]	Loss 0.1529 (0.1688)	LossFusion 0.1529 (0.1688)	
Train Epoch: [242][7/8]	Loss 0.1529 (0.1688)	LossFusion 0.1529 (0.1688)	
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
Train Epoch: [243][0/8]	Loss 0.2588 (0.2588)	LossFusion 0.2588 (0.2588)	
Train Epoch: [243][0/8]	Loss 0.2588 (0.2588)	LossFusion 0.2588 (0.2588)	
Train Epoch: [243][0/8]	Loss 0.2588 (0.2588)	LossFusion 0.2588 (0.2588)	
Train Epoch: [243][0/8]	Loss 0.2588 (0.2588)	LossFusion 0.2588 (0.2588)	
Train Epoch: [243][0/8]	Loss 0.2588 (0.2588)	LossFusion 0.2588 (0.2588)	
Train Epoch: [243][0/8]	Loss 0.2588 (0.2588)	LossFusion 0.2588 (0.2588)	
Train Epoch: [243][0/8]	Loss 0.2588 (0.2588)	LossFusion 0.2588 (0.2588)	
Train Epoch: [243][0/8]	Loss 0.2588 (0.2588)	LossFusion 0.2588 (0.2588)	
Train Epoch: [243][7/8]	Loss 0.1554 (0.1657)	LossFusion 0.1554 (0.1657)	
Train Epoch: [243][7/8]	Loss 0.1554 (0.1657)	LossFusion 0.1554 (0.1657)	
Train Epoch: [243][7/8]	Loss 0.1554 (0.1657)	LossFusion 0.1554 (0.1657)	
Train Epoch: [243][7/8]	Loss 0.1554 (0.1657)	LossFusion 0.1554 (0.1657)	
Train Epoch: [243][7/8]	Loss 0.1554 (0.1657)	LossFusion 0.1554 (0.1657)	
Train Epoch: [243][7/8]	Loss 0.1554 (0.1657)	LossFusion 0.1554 (0.1657)	
Train Epoch: [243][7/8]	Loss 0.1554 (0.1657)	LossFusion 0.1554 (0.1657)	
Train Epoch: [243][7/8]	Loss 0.1554 (0.1657)	LossFusion 0.1554 (0.1657)	
R@10:  54.00340557098389     R@50:  80.06814122200012
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.06814122200012
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.06814122200012
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.06814122200012
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.06814122200012
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.06814122200012
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.06814122200012
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  80.06814122200012
Mean Now:  67.035773396492  Best Mean Before:  69.44918 --------------------
Train Epoch: [244][0/8]	Loss 0.2670 (0.2670)	LossFusion 0.2670 (0.2670)	
Train Epoch: [244][0/8]	Loss 0.2670 (0.2670)	LossFusion 0.2670 (0.2670)	
Train Epoch: [244][0/8]	Loss 0.2670 (0.2670)	LossFusion 0.2670 (0.2670)	
Train Epoch: [244][0/8]	Loss 0.2670 (0.2670)	LossFusion 0.2670 (0.2670)	
Train Epoch: [244][0/8]	Loss 0.2670 (0.2670)	LossFusion 0.2670 (0.2670)	
Train Epoch: [244][0/8]	Loss 0.2670 (0.2670)	LossFusion 0.2670 (0.2670)	
Train Epoch: [244][0/8]	Loss 0.2670 (0.2670)	LossFusion 0.2670 (0.2670)	
Train Epoch: [244][0/8]	Loss 0.2670 (0.2670)	LossFusion 0.2670 (0.2670)	
Train Epoch: [244][7/8]	Loss 0.1360 (0.1564)	LossFusion 0.1360 (0.1564)	
Train Epoch: [244][7/8]	Loss 0.1360 (0.1564)	LossFusion 0.1360 (0.1564)	
Train Epoch: [244][7/8]	Loss 0.1360 (0.1564)	LossFusion 0.1360 (0.1564)	
Train Epoch: [244][7/8]	Loss 0.1360 (0.1564)	LossFusion 0.1360 (0.1564)	
Train Epoch: [244][7/8]	Loss 0.1360 (0.1564)	LossFusion 0.1360 (0.1564)	
Train Epoch: [244][7/8]	Loss 0.1360 (0.1564)	LossFusion 0.1360 (0.1564)	
Train Epoch: [244][7/8]	Loss 0.1360 (0.1564)	LossFusion 0.1360 (0.1564)	
Train Epoch: [244][7/8]	Loss 0.1360 (0.1564)	LossFusion 0.1360 (0.1564)	
R@10:  53.77626419067383     R@50:  79.95457053184509
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.95457053184509
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.95457053184509
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.95457053184509
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.95457053184509
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.95457053184509
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.95457053184509
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.95457053184509
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
Train Epoch: [245][0/8]	Loss 0.2625 (0.2625)	LossFusion 0.2625 (0.2625)	
Train Epoch: [245][0/8]	Loss 0.2625 (0.2625)	LossFusion 0.2625 (0.2625)	
Train Epoch: [245][0/8]	Loss 0.2625 (0.2625)	LossFusion 0.2625 (0.2625)	
Train Epoch: [245][0/8]	Loss 0.2625 (0.2625)	LossFusion 0.2625 (0.2625)	
Train Epoch: [245][0/8]	Loss 0.2625 (0.2625)	LossFusion 0.2625 (0.2625)	
Train Epoch: [245][0/8]	Loss 0.2625 (0.2625)	LossFusion 0.2625 (0.2625)	
Train Epoch: [245][0/8]	Loss 0.2625 (0.2625)	LossFusion 0.2625 (0.2625)	
Train Epoch: [245][0/8]	Loss 0.2625 (0.2625)	LossFusion 0.2625 (0.2625)	
Train Epoch: [245][7/8]	Loss 0.1337 (0.1591)	LossFusion 0.1337 (0.1591)	
Train Epoch: [245][7/8]	Loss 0.1337 (0.1591)	LossFusion 0.1337 (0.1591)	
Train Epoch: [245][7/8]	Loss 0.1337 (0.1591)	LossFusion 0.1337 (0.1591)	
Train Epoch: [245][7/8]	Loss 0.1337 (0.1591)	LossFusion 0.1337 (0.1591)	
Train Epoch: [245][7/8]	Loss 0.1337 (0.1591)	LossFusion 0.1337 (0.1591)	
Train Epoch: [245][7/8]	Loss 0.1337 (0.1591)	LossFusion 0.1337 (0.1591)	
Train Epoch: [245][7/8]	Loss 0.1337 (0.1591)	LossFusion 0.1337 (0.1591)	
Train Epoch: [245][7/8]	Loss 0.1337 (0.1591)	LossFusion 0.1337 (0.1591)	
R@10:  54.17376756668091     R@50:  79.89778518676758
Mean Now:  67.03577637672424  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.89778518676758
Mean Now:  67.03577637672424  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.89778518676758
Mean Now:  67.03577637672424  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.89778518676758
Mean Now:  67.03577637672424  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.89778518676758
Mean Now:  67.03577637672424  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.89778518676758
Mean Now:  67.03577637672424  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.89778518676758
Mean Now:  67.03577637672424  Best Mean Before:  69.44918 --------------------
R@10:  54.17376756668091     R@50:  79.89778518676758
Mean Now:  67.03577637672424  Best Mean Before:  69.44918 --------------------
Train Epoch: [246][0/8]	Loss 0.2915 (0.2915)	LossFusion 0.2915 (0.2915)	
Train Epoch: [246][0/8]	Loss 0.2915 (0.2915)	LossFusion 0.2915 (0.2915)	
Train Epoch: [246][0/8]	Loss 0.2915 (0.2915)	LossFusion 0.2915 (0.2915)	
Train Epoch: [246][0/8]	Loss 0.2915 (0.2915)	LossFusion 0.2915 (0.2915)	
Train Epoch: [246][0/8]	Loss 0.2915 (0.2915)	LossFusion 0.2915 (0.2915)	
Train Epoch: [246][0/8]	Loss 0.2915 (0.2915)	LossFusion 0.2915 (0.2915)	
Train Epoch: [246][0/8]	Loss 0.2915 (0.2915)	LossFusion 0.2915 (0.2915)	
Train Epoch: [246][0/8]	Loss 0.2915 (0.2915)	LossFusion 0.2915 (0.2915)	
Train Epoch: [246][7/8]	Loss 0.1401 (0.1665)	LossFusion 0.1401 (0.1665)	
Train Epoch: [246][7/8]	Loss 0.1401 (0.1665)	LossFusion 0.1401 (0.1665)	
Train Epoch: [246][7/8]	Loss 0.1401 (0.1665)	LossFusion 0.1401 (0.1665)	
Train Epoch: [246][7/8]	Loss 0.1401 (0.1665)	LossFusion 0.1401 (0.1665)	
Train Epoch: [246][7/8]	Loss 0.1401 (0.1665)	LossFusion 0.1401 (0.1665)	
Train Epoch: [246][7/8]	Loss 0.1401 (0.1665)	LossFusion 0.1401 (0.1665)	
Train Epoch: [246][7/8]	Loss 0.1401 (0.1665)	LossFusion 0.1401 (0.1665)	
Train Epoch: [246][7/8]	Loss 0.1401 (0.1665)	LossFusion 0.1401 (0.1665)	
R@10:  53.71947884559631     R@50:  80.23850321769714
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.23850321769714
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.23850321769714
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.23850321769714
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.23850321769714
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.23850321769714
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.23850321769714
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  80.23850321769714
Mean Now:  66.97899103164673  Best Mean Before:  69.44918 --------------------
Train Epoch: [247][0/8]	Loss 0.2584 (0.2584)	LossFusion 0.2584 (0.2584)	
Train Epoch: [247][0/8]	Loss 0.2584 (0.2584)	LossFusion 0.2584 (0.2584)	
Train Epoch: [247][0/8]	Loss 0.2584 (0.2584)	LossFusion 0.2584 (0.2584)	
Train Epoch: [247][0/8]	Loss 0.2584 (0.2584)	LossFusion 0.2584 (0.2584)	
Train Epoch: [247][0/8]	Loss 0.2584 (0.2584)	LossFusion 0.2584 (0.2584)	
Train Epoch: [247][0/8]	Loss 0.2584 (0.2584)	LossFusion 0.2584 (0.2584)	
Train Epoch: [247][0/8]	Loss 0.2584 (0.2584)	LossFusion 0.2584 (0.2584)	
Train Epoch: [247][0/8]	Loss 0.2584 (0.2584)	LossFusion 0.2584 (0.2584)	
Train Epoch: [247][7/8]	Loss 0.1297 (0.1537)	LossFusion 0.1297 (0.1537)	
Train Epoch: [247][7/8]	Loss 0.1297 (0.1537)	LossFusion 0.1297 (0.1537)	
Train Epoch: [247][7/8]	Loss 0.1297 (0.1537)	LossFusion 0.1297 (0.1537)	
Train Epoch: [247][7/8]	Loss 0.1297 (0.1537)	LossFusion 0.1297 (0.1537)	
Train Epoch: [247][7/8]	Loss 0.1297 (0.1537)	LossFusion 0.1297 (0.1537)	
Train Epoch: [247][7/8]	Loss 0.1297 (0.1537)	LossFusion 0.1297 (0.1537)	
Train Epoch: [247][7/8]	Loss 0.1297 (0.1537)	LossFusion 0.1297 (0.1537)	
Train Epoch: [247][7/8]	Loss 0.1297 (0.1537)	LossFusion 0.1297 (0.1537)	
R@10:  53.49233150482178     R@50:  80.01135587692261
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.01135587692261
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.01135587692261
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.01135587692261
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.01135587692261
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.01135587692261
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.01135587692261
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.01135587692261
Mean Now:  66.75184369087219  Best Mean Before:  69.44918 --------------------
Train Epoch: [248][0/8]	Loss 0.2759 (0.2759)	LossFusion 0.2759 (0.2759)	
Train Epoch: [248][0/8]	Loss 0.2759 (0.2759)	LossFusion 0.2759 (0.2759)	
Train Epoch: [248][0/8]	Loss 0.2759 (0.2759)	LossFusion 0.2759 (0.2759)	
Train Epoch: [248][0/8]	Loss 0.2759 (0.2759)	LossFusion 0.2759 (0.2759)	
Train Epoch: [248][0/8]	Loss 0.2759 (0.2759)	LossFusion 0.2759 (0.2759)	
Train Epoch: [248][0/8]	Loss 0.2759 (0.2759)	LossFusion 0.2759 (0.2759)	
Train Epoch: [248][0/8]	Loss 0.2759 (0.2759)	LossFusion 0.2759 (0.2759)	
Train Epoch: [248][0/8]	Loss 0.2759 (0.2759)	LossFusion 0.2759 (0.2759)	
Train Epoch: [248][7/8]	Loss 0.1307 (0.1617)	LossFusion 0.1307 (0.1617)	
Train Epoch: [248][7/8]	Loss 0.1307 (0.1617)	LossFusion 0.1307 (0.1617)	
Train Epoch: [248][7/8]	Loss 0.1307 (0.1617)	LossFusion 0.1307 (0.1617)	
Train Epoch: [248][7/8]	Loss 0.1307 (0.1617)	LossFusion 0.1307 (0.1617)	
Train Epoch: [248][7/8]	Loss 0.1307 (0.1617)	LossFusion 0.1307 (0.1617)	
Train Epoch: [248][7/8]	Loss 0.1307 (0.1617)	LossFusion 0.1307 (0.1617)	
Train Epoch: [248][7/8]	Loss 0.1307 (0.1617)	LossFusion 0.1307 (0.1617)	
Train Epoch: [248][7/8]	Loss 0.1307 (0.1617)	LossFusion 0.1307 (0.1617)	
R@10:  53.83304953575134     R@50:  80.29528856277466
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.29528856277466
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.29528856277466
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.29528856277466
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.29528856277466
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.29528856277466
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.29528856277466
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.29528856277466
Mean Now:  67.064169049263  Best Mean Before:  69.44918 --------------------
Train Epoch: [249][0/8]	Loss 0.2571 (0.2571)	LossFusion 0.2571 (0.2571)	
Train Epoch: [249][0/8]	Loss 0.2571 (0.2571)	LossFusion 0.2571 (0.2571)	
Train Epoch: [249][0/8]	Loss 0.2571 (0.2571)	LossFusion 0.2571 (0.2571)	
Train Epoch: [249][0/8]	Loss 0.2571 (0.2571)	LossFusion 0.2571 (0.2571)	
Train Epoch: [249][0/8]	Loss 0.2571 (0.2571)	LossFusion 0.2571 (0.2571)	
Train Epoch: [249][0/8]	Loss 0.2571 (0.2571)	LossFusion 0.2571 (0.2571)	
Train Epoch: [249][0/8]	Loss 0.2571 (0.2571)	LossFusion 0.2571 (0.2571)	
Train Epoch: [249][0/8]	Loss 0.2571 (0.2571)	LossFusion 0.2571 (0.2571)	
Train Epoch: [249][7/8]	Loss 0.1182 (0.1496)	LossFusion 0.1182 (0.1496)	
Train Epoch: [249][7/8]	Loss 0.1182 (0.1496)	LossFusion 0.1182 (0.1496)	
Train Epoch: [249][7/8]	Loss 0.1182 (0.1496)	LossFusion 0.1182 (0.1496)	
Train Epoch: [249][7/8]	Loss 0.1182 (0.1496)	LossFusion 0.1182 (0.1496)	
Train Epoch: [249][7/8]	Loss 0.1182 (0.1496)	LossFusion 0.1182 (0.1496)	
Train Epoch: [249][7/8]	Loss 0.1182 (0.1496)	LossFusion 0.1182 (0.1496)	
Train Epoch: [249][7/8]	Loss 0.1182 (0.1496)	LossFusion 0.1182 (0.1496)	
Train Epoch: [249][7/8]	Loss 0.1182 (0.1496)	LossFusion 0.1182 (0.1496)	
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  80.18171787261963
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
Train Epoch: [250][0/8]	Loss 0.2530 (0.2530)	LossFusion 0.2530 (0.2530)	
Train Epoch: [250][0/8]	Loss 0.2530 (0.2530)	LossFusion 0.2530 (0.2530)	
Train Epoch: [250][0/8]	Loss 0.2530 (0.2530)	LossFusion 0.2530 (0.2530)	
Train Epoch: [250][0/8]	Loss 0.2530 (0.2530)	LossFusion 0.2530 (0.2530)	
Train Epoch: [250][0/8]	Loss 0.2530 (0.2530)	LossFusion 0.2530 (0.2530)	
Train Epoch: [250][0/8]	Loss 0.2530 (0.2530)	LossFusion 0.2530 (0.2530)	
Train Epoch: [250][0/8]	Loss 0.2530 (0.2530)	LossFusion 0.2530 (0.2530)	
Train Epoch: [250][0/8]	Loss 0.2530 (0.2530)	LossFusion 0.2530 (0.2530)	
Train Epoch: [250][7/8]	Loss 0.1316 (0.1547)	LossFusion 0.1316 (0.1547)	
Train Epoch: [250][7/8]	Loss 0.1316 (0.1547)	LossFusion 0.1316 (0.1547)	
Train Epoch: [250][7/8]	Loss 0.1316 (0.1547)	LossFusion 0.1316 (0.1547)	
Train Epoch: [250][7/8]	Loss 0.1316 (0.1547)	LossFusion 0.1316 (0.1547)	
Train Epoch: [250][7/8]	Loss 0.1316 (0.1547)	LossFusion 0.1316 (0.1547)	
Train Epoch: [250][7/8]	Loss 0.1316 (0.1547)	LossFusion 0.1316 (0.1547)	
Train Epoch: [250][7/8]	Loss 0.1316 (0.1547)	LossFusion 0.1316 (0.1547)	
Train Epoch: [250][7/8]	Loss 0.1316 (0.1547)	LossFusion 0.1316 (0.1547)	
R@10:  53.83304953575134     R@50:  80.01135587692261
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.01135587692261
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.01135587692261
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.01135587692261
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.01135587692261
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.01135587692261
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.01135587692261
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  80.01135587692261
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
Train Epoch: [251][0/8]	Loss 0.2583 (0.2583)	LossFusion 0.2583 (0.2583)	
Train Epoch: [251][0/8]	Loss 0.2583 (0.2583)	LossFusion 0.2583 (0.2583)	
Train Epoch: [251][0/8]	Loss 0.2583 (0.2583)	LossFusion 0.2583 (0.2583)	
Train Epoch: [251][0/8]	Loss 0.2583 (0.2583)	LossFusion 0.2583 (0.2583)	
Train Epoch: [251][0/8]	Loss 0.2583 (0.2583)	LossFusion 0.2583 (0.2583)	
Train Epoch: [251][0/8]	Loss 0.2583 (0.2583)	LossFusion 0.2583 (0.2583)	
Train Epoch: [251][0/8]	Loss 0.2583 (0.2583)	LossFusion 0.2583 (0.2583)	
Train Epoch: [251][0/8]	Loss 0.2583 (0.2583)	LossFusion 0.2583 (0.2583)	
Train Epoch: [251][7/8]	Loss 0.1558 (0.1590)	LossFusion 0.1558 (0.1590)	
Train Epoch: [251][7/8]	Loss 0.1558 (0.1590)	LossFusion 0.1558 (0.1590)	
Train Epoch: [251][7/8]	Loss 0.1558 (0.1590)	LossFusion 0.1558 (0.1590)	
Train Epoch: [251][7/8]	Loss 0.1558 (0.1590)	LossFusion 0.1558 (0.1590)	
Train Epoch: [251][7/8]	Loss 0.1558 (0.1590)	LossFusion 0.1558 (0.1590)	
Train Epoch: [251][7/8]	Loss 0.1558 (0.1590)	LossFusion 0.1558 (0.1590)	
Train Epoch: [251][7/8]	Loss 0.1558 (0.1590)	LossFusion 0.1558 (0.1590)	
Train Epoch: [251][7/8]	Loss 0.1558 (0.1590)	LossFusion 0.1558 (0.1590)	
R@10:  53.32197546958923     R@50:  79.89778518676758
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  79.89778518676758
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  79.89778518676758
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  79.89778518676758
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  79.89778518676758
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  79.89778518676758
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  79.89778518676758
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.32197546958923     R@50:  79.89778518676758
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
Train Epoch: [252][0/8]	Loss 0.2606 (0.2606)	LossFusion 0.2606 (0.2606)	
Train Epoch: [252][0/8]	Loss 0.2606 (0.2606)	LossFusion 0.2606 (0.2606)	
Train Epoch: [252][0/8]	Loss 0.2606 (0.2606)	LossFusion 0.2606 (0.2606)	
Train Epoch: [252][0/8]	Loss 0.2606 (0.2606)	LossFusion 0.2606 (0.2606)	
Train Epoch: [252][0/8]	Loss 0.2606 (0.2606)	LossFusion 0.2606 (0.2606)	
Train Epoch: [252][0/8]	Loss 0.2606 (0.2606)	LossFusion 0.2606 (0.2606)	
Train Epoch: [252][0/8]	Loss 0.2606 (0.2606)	LossFusion 0.2606 (0.2606)	
Train Epoch: [252][0/8]	Loss 0.2606 (0.2606)	LossFusion 0.2606 (0.2606)	
Train Epoch: [252][7/8]	Loss 0.1319 (0.1560)	LossFusion 0.1319 (0.1560)	
Train Epoch: [252][7/8]	Loss 0.1319 (0.1560)	LossFusion 0.1319 (0.1560)	
Train Epoch: [252][7/8]	Loss 0.1319 (0.1560)	LossFusion 0.1319 (0.1560)	
Train Epoch: [252][7/8]	Loss 0.1319 (0.1560)	LossFusion 0.1319 (0.1560)	
Train Epoch: [252][7/8]	Loss 0.1319 (0.1560)	LossFusion 0.1319 (0.1560)	
Train Epoch: [252][7/8]	Loss 0.1319 (0.1560)	LossFusion 0.1319 (0.1560)	
Train Epoch: [252][7/8]	Loss 0.1319 (0.1560)	LossFusion 0.1319 (0.1560)	
Train Epoch: [252][7/8]	Loss 0.1319 (0.1560)	LossFusion 0.1319 (0.1560)	
R@10:  53.49233150482178     R@50:  79.89778518676758
Mean Now:  66.69505834579468  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  79.89778518676758
Mean Now:  66.69505834579468  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  79.89778518676758
Mean Now:  66.69505834579468  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  79.89778518676758
Mean Now:  66.69505834579468  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  79.89778518676758
Mean Now:  66.69505834579468  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  79.89778518676758
Mean Now:  66.69505834579468  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  79.89778518676758
Mean Now:  66.69505834579468  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  79.89778518676758
Mean Now:  66.69505834579468  Best Mean Before:  69.44918 --------------------
Train Epoch: [253][0/8]	Loss 0.2454 (0.2454)	LossFusion 0.2454 (0.2454)	
Train Epoch: [253][0/8]	Loss 0.2454 (0.2454)	LossFusion 0.2454 (0.2454)	
Train Epoch: [253][0/8]	Loss 0.2454 (0.2454)	LossFusion 0.2454 (0.2454)	
Train Epoch: [253][0/8]	Loss 0.2454 (0.2454)	LossFusion 0.2454 (0.2454)	
Train Epoch: [253][0/8]	Loss 0.2454 (0.2454)	LossFusion 0.2454 (0.2454)	
Train Epoch: [253][0/8]	Loss 0.2454 (0.2454)	LossFusion 0.2454 (0.2454)	
Train Epoch: [253][0/8]	Loss 0.2454 (0.2454)	LossFusion 0.2454 (0.2454)	
Train Epoch: [253][0/8]	Loss 0.2454 (0.2454)	LossFusion 0.2454 (0.2454)	
Train Epoch: [253][7/8]	Loss 0.1169 (0.1482)	LossFusion 0.1169 (0.1482)	
Train Epoch: [253][7/8]	Loss 0.1169 (0.1482)	LossFusion 0.1169 (0.1482)	
Train Epoch: [253][7/8]	Loss 0.1169 (0.1482)	LossFusion 0.1169 (0.1482)	
Train Epoch: [253][7/8]	Loss 0.1169 (0.1482)	LossFusion 0.1169 (0.1482)	
Train Epoch: [253][7/8]	Loss 0.1169 (0.1482)	LossFusion 0.1169 (0.1482)	
Train Epoch: [253][7/8]	Loss 0.1169 (0.1482)	LossFusion 0.1169 (0.1482)	
Train Epoch: [253][7/8]	Loss 0.1169 (0.1482)	LossFusion 0.1169 (0.1482)	
Train Epoch: [253][7/8]	Loss 0.1169 (0.1482)	LossFusion 0.1169 (0.1482)	
R@10:  53.43554615974426     R@50:  80.01135587692261
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.01135587692261
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.01135587692261
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.01135587692261
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.01135587692261
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.01135587692261
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.01135587692261
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.01135587692261
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
Train Epoch: [254][0/8]	Loss 0.2475 (0.2475)	LossFusion 0.2475 (0.2475)	
Train Epoch: [254][0/8]	Loss 0.2475 (0.2475)	LossFusion 0.2475 (0.2475)	
Train Epoch: [254][0/8]	Loss 0.2475 (0.2475)	LossFusion 0.2475 (0.2475)	
Train Epoch: [254][0/8]	Loss 0.2475 (0.2475)	LossFusion 0.2475 (0.2475)	
Train Epoch: [254][0/8]	Loss 0.2475 (0.2475)	LossFusion 0.2475 (0.2475)	
Train Epoch: [254][0/8]	Loss 0.2475 (0.2475)	LossFusion 0.2475 (0.2475)	
Train Epoch: [254][0/8]	Loss 0.2475 (0.2475)	LossFusion 0.2475 (0.2475)	
Train Epoch: [254][0/8]	Loss 0.2475 (0.2475)	LossFusion 0.2475 (0.2475)	
Train Epoch: [254][7/8]	Loss 0.1379 (0.1528)	LossFusion 0.1379 (0.1528)	
Train Epoch: [254][7/8]	Loss 0.1379 (0.1528)	LossFusion 0.1379 (0.1528)	
Train Epoch: [254][7/8]	Loss 0.1379 (0.1528)	LossFusion 0.1379 (0.1528)	
Train Epoch: [254][7/8]	Loss 0.1379 (0.1528)	LossFusion 0.1379 (0.1528)	
Train Epoch: [254][7/8]	Loss 0.1379 (0.1528)	LossFusion 0.1379 (0.1528)	
Train Epoch: [254][7/8]	Loss 0.1379 (0.1528)	LossFusion 0.1379 (0.1528)	
Train Epoch: [254][7/8]	Loss 0.1379 (0.1528)	LossFusion 0.1379 (0.1528)	
Train Epoch: [254][7/8]	Loss 0.1379 (0.1528)	LossFusion 0.1379 (0.1528)	
R@10:  53.54911684989929     R@50:  79.89778518676758
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.89778518676758
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.89778518676758
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.89778518676758
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.89778518676758
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.89778518676758
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.89778518676758
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.89778518676758
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
Train Epoch: [255][0/8]	Loss 0.2331 (0.2331)	LossFusion 0.2331 (0.2331)	
Train Epoch: [255][0/8]	Loss 0.2331 (0.2331)	LossFusion 0.2331 (0.2331)	
Train Epoch: [255][0/8]	Loss 0.2331 (0.2331)	LossFusion 0.2331 (0.2331)	
Train Epoch: [255][0/8]	Loss 0.2331 (0.2331)	LossFusion 0.2331 (0.2331)	
Train Epoch: [255][0/8]	Loss 0.2331 (0.2331)	LossFusion 0.2331 (0.2331)	
Train Epoch: [255][0/8]	Loss 0.2331 (0.2331)	LossFusion 0.2331 (0.2331)	
Train Epoch: [255][0/8]	Loss 0.2331 (0.2331)	LossFusion 0.2331 (0.2331)	
Train Epoch: [255][0/8]	Loss 0.2331 (0.2331)	LossFusion 0.2331 (0.2331)	
Train Epoch: [255][7/8]	Loss 0.1333 (0.1463)	LossFusion 0.1333 (0.1463)	
Train Epoch: [255][7/8]	Loss 0.1333 (0.1463)	LossFusion 0.1333 (0.1463)	
Train Epoch: [255][7/8]	Loss 0.1333 (0.1463)	LossFusion 0.1333 (0.1463)	
Train Epoch: [255][7/8]	Loss 0.1333 (0.1463)	LossFusion 0.1333 (0.1463)	
Train Epoch: [255][7/8]	Loss 0.1333 (0.1463)	LossFusion 0.1333 (0.1463)	
Train Epoch: [255][7/8]	Loss 0.1333 (0.1463)	LossFusion 0.1333 (0.1463)	
Train Epoch: [255][7/8]	Loss 0.1333 (0.1463)	LossFusion 0.1333 (0.1463)	
Train Epoch: [255][7/8]	Loss 0.1333 (0.1463)	LossFusion 0.1333 (0.1463)	
R@10:  53.49233150482178     R@50:  80.18171787261963
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.18171787261963
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.18171787261963
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.18171787261963
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.18171787261963
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.18171787261963
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.18171787261963
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.49233150482178     R@50:  80.18171787261963
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
Train Epoch: [256][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [256][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [256][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [256][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [256][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [256][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [256][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [256][0/8]	Loss 0.2660 (0.2660)	LossFusion 0.2660 (0.2660)	
Train Epoch: [256][7/8]	Loss 0.1468 (0.1556)	LossFusion 0.1468 (0.1556)	
Train Epoch: [256][7/8]	Loss 0.1468 (0.1556)	LossFusion 0.1468 (0.1556)	
Train Epoch: [256][7/8]	Loss 0.1468 (0.1556)	LossFusion 0.1468 (0.1556)	
Train Epoch: [256][7/8]	Loss 0.1468 (0.1556)	LossFusion 0.1468 (0.1556)	
Train Epoch: [256][7/8]	Loss 0.1468 (0.1556)	LossFusion 0.1468 (0.1556)	
Train Epoch: [256][7/8]	Loss 0.1468 (0.1556)	LossFusion 0.1468 (0.1556)	
Train Epoch: [256][7/8]	Loss 0.1468 (0.1556)	LossFusion 0.1468 (0.1556)	
Train Epoch: [256][7/8]	Loss 0.1468 (0.1556)	LossFusion 0.1468 (0.1556)	
R@10:  53.43554615974426     R@50:  80.18171787261963
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.18171787261963
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.18171787261963
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.18171787261963
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.18171787261963
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.18171787261963
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.18171787261963
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  80.18171787261963
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
Train Epoch: [257][0/8]	Loss 0.2516 (0.2516)	LossFusion 0.2516 (0.2516)	
Train Epoch: [257][0/8]	Loss 0.2516 (0.2516)	LossFusion 0.2516 (0.2516)	
Train Epoch: [257][0/8]	Loss 0.2516 (0.2516)	LossFusion 0.2516 (0.2516)	
Train Epoch: [257][0/8]	Loss 0.2516 (0.2516)	LossFusion 0.2516 (0.2516)	
Train Epoch: [257][0/8]	Loss 0.2516 (0.2516)	LossFusion 0.2516 (0.2516)	
Train Epoch: [257][0/8]	Loss 0.2516 (0.2516)	LossFusion 0.2516 (0.2516)	
Train Epoch: [257][0/8]	Loss 0.2516 (0.2516)	LossFusion 0.2516 (0.2516)	
Train Epoch: [257][0/8]	Loss 0.2516 (0.2516)	LossFusion 0.2516 (0.2516)	
Train Epoch: [257][7/8]	Loss 0.1464 (0.1508)	LossFusion 0.1464 (0.1508)	
Train Epoch: [257][7/8]	Loss 0.1464 (0.1508)	LossFusion 0.1464 (0.1508)	
Train Epoch: [257][7/8]	Loss 0.1464 (0.1508)	LossFusion 0.1464 (0.1508)	
Train Epoch: [257][7/8]	Loss 0.1464 (0.1508)	LossFusion 0.1464 (0.1508)	
Train Epoch: [257][7/8]	Loss 0.1464 (0.1508)	LossFusion 0.1464 (0.1508)	
Train Epoch: [257][7/8]	Loss 0.1464 (0.1508)	LossFusion 0.1464 (0.1508)	
Train Epoch: [257][7/8]	Loss 0.1464 (0.1508)	LossFusion 0.1464 (0.1508)	
Train Epoch: [257][7/8]	Loss 0.1464 (0.1508)	LossFusion 0.1464 (0.1508)	
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
Train Epoch: [258][0/8]	Loss 0.2296 (0.2296)	LossFusion 0.2296 (0.2296)	
Train Epoch: [258][0/8]	Loss 0.2296 (0.2296)	LossFusion 0.2296 (0.2296)	
Train Epoch: [258][0/8]	Loss 0.2296 (0.2296)	LossFusion 0.2296 (0.2296)	
Train Epoch: [258][0/8]	Loss 0.2296 (0.2296)	LossFusion 0.2296 (0.2296)	
Train Epoch: [258][0/8]	Loss 0.2296 (0.2296)	LossFusion 0.2296 (0.2296)	
Train Epoch: [258][0/8]	Loss 0.2296 (0.2296)	LossFusion 0.2296 (0.2296)	
Train Epoch: [258][0/8]	Loss 0.2296 (0.2296)	LossFusion 0.2296 (0.2296)	
Train Epoch: [258][0/8]	Loss 0.2296 (0.2296)	LossFusion 0.2296 (0.2296)	
Train Epoch: [258][7/8]	Loss 0.1386 (0.1492)	LossFusion 0.1386 (0.1492)	
Train Epoch: [258][7/8]	Loss 0.1386 (0.1492)	LossFusion 0.1386 (0.1492)	
Train Epoch: [258][7/8]	Loss 0.1386 (0.1492)	LossFusion 0.1386 (0.1492)	
Train Epoch: [258][7/8]	Loss 0.1386 (0.1492)	LossFusion 0.1386 (0.1492)	
Train Epoch: [258][7/8]	Loss 0.1386 (0.1492)	LossFusion 0.1386 (0.1492)	
Train Epoch: [258][7/8]	Loss 0.1386 (0.1492)	LossFusion 0.1386 (0.1492)	
Train Epoch: [258][7/8]	Loss 0.1386 (0.1492)	LossFusion 0.1386 (0.1492)	
Train Epoch: [258][7/8]	Loss 0.1386 (0.1492)	LossFusion 0.1386 (0.1492)	
R@10:  53.71947884559631     R@50:  79.95457053184509
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.95457053184509
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.95457053184509
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.95457053184509
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.95457053184509
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.95457053184509
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.95457053184509
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.95457053184509
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
Train Epoch: [259][0/8]	Loss 0.2477 (0.2477)	LossFusion 0.2477 (0.2477)	
Train Epoch: [259][0/8]	Loss 0.2477 (0.2477)	LossFusion 0.2477 (0.2477)	
Train Epoch: [259][0/8]	Loss 0.2477 (0.2477)	LossFusion 0.2477 (0.2477)	Train Epoch: [259][0/8]	Loss 0.2477 (0.2477)	LossFusion 0.2477 (0.2477)	

Train Epoch: [259][0/8]	Loss 0.2477 (0.2477)	LossFusion 0.2477 (0.2477)	
Train Epoch: [259][0/8]	Loss 0.2477 (0.2477)	LossFusion 0.2477 (0.2477)	
Train Epoch: [259][0/8]	Loss 0.2477 (0.2477)	LossFusion 0.2477 (0.2477)	
Train Epoch: [259][0/8]	Loss 0.2477 (0.2477)	LossFusion 0.2477 (0.2477)	
Train Epoch: [259][7/8]	Loss 0.1296 (0.1455)	LossFusion 0.1296 (0.1455)	
Train Epoch: [259][7/8]	Loss 0.1296 (0.1455)	LossFusion 0.1296 (0.1455)	
Train Epoch: [259][7/8]	Loss 0.1296 (0.1455)	LossFusion 0.1296 (0.1455)	
Train Epoch: [259][7/8]	Loss 0.1296 (0.1455)	LossFusion 0.1296 (0.1455)	
Train Epoch: [259][7/8]	Loss 0.1296 (0.1455)	LossFusion 0.1296 (0.1455)	
Train Epoch: [259][7/8]	Loss 0.1296 (0.1455)	LossFusion 0.1296 (0.1455)	
Train Epoch: [259][7/8]	Loss 0.1296 (0.1455)	LossFusion 0.1296 (0.1455)	
Train Epoch: [259][7/8]	Loss 0.1296 (0.1455)	LossFusion 0.1296 (0.1455)	
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
Train Epoch: [260][0/8]	Loss 0.2597 (0.2597)	LossFusion 0.2597 (0.2597)	
Train Epoch: [260][0/8]	Loss 0.2597 (0.2597)	LossFusion 0.2597 (0.2597)	
Train Epoch: [260][0/8]	Loss 0.2597 (0.2597)	LossFusion 0.2597 (0.2597)	
Train Epoch: [260][0/8]	Loss 0.2597 (0.2597)	LossFusion 0.2597 (0.2597)	
Train Epoch: [260][0/8]	Loss 0.2597 (0.2597)	LossFusion 0.2597 (0.2597)	
Train Epoch: [260][0/8]	Loss 0.2597 (0.2597)	LossFusion 0.2597 (0.2597)	
Train Epoch: [260][0/8]	Loss 0.2597 (0.2597)	LossFusion 0.2597 (0.2597)	
Train Epoch: [260][0/8]	Loss 0.2597 (0.2597)	LossFusion 0.2597 (0.2597)	
Train Epoch: [260][7/8]	Loss 0.1433 (0.1523)	LossFusion 0.1433 (0.1523)	
Train Epoch: [260][7/8]	Loss 0.1433 (0.1523)	LossFusion 0.1433 (0.1523)	
Train Epoch: [260][7/8]	Loss 0.1433 (0.1523)	LossFusion 0.1433 (0.1523)	
Train Epoch: [260][7/8]	Loss 0.1433 (0.1523)	LossFusion 0.1433 (0.1523)	
Train Epoch: [260][7/8]	Loss 0.1433 (0.1523)	LossFusion 0.1433 (0.1523)	
Train Epoch: [260][7/8]	Loss 0.1433 (0.1523)	LossFusion 0.1433 (0.1523)	
Train Epoch: [260][7/8]	Loss 0.1433 (0.1523)	LossFusion 0.1433 (0.1523)	
Train Epoch: [260][7/8]	Loss 0.1433 (0.1523)	LossFusion 0.1433 (0.1523)	
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.78421449661255
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
Train Epoch: [261][0/8]	Loss 0.2310 (0.2310)	LossFusion 0.2310 (0.2310)	
Train Epoch: [261][0/8]	Loss 0.2310 (0.2310)	LossFusion 0.2310 (0.2310)	
Train Epoch: [261][0/8]	Loss 0.2310 (0.2310)	LossFusion 0.2310 (0.2310)	
Train Epoch: [261][0/8]	Loss 0.2310 (0.2310)	LossFusion 0.2310 (0.2310)	
Train Epoch: [261][0/8]	Loss 0.2310 (0.2310)	LossFusion 0.2310 (0.2310)	
Train Epoch: [261][0/8]	Loss 0.2310 (0.2310)	LossFusion 0.2310 (0.2310)	
Train Epoch: [261][0/8]	Loss 0.2310 (0.2310)	LossFusion 0.2310 (0.2310)	
Train Epoch: [261][0/8]	Loss 0.2310 (0.2310)	LossFusion 0.2310 (0.2310)	
Train Epoch: [261][7/8]	Loss 0.1381 (0.1468)	LossFusion 0.1381 (0.1468)	
Train Epoch: [261][7/8]	Loss 0.1381 (0.1468)	LossFusion 0.1381 (0.1468)	
Train Epoch: [261][7/8]	Loss 0.1381 (0.1468)	LossFusion 0.1381 (0.1468)	
Train Epoch: [261][7/8]	Loss 0.1381 (0.1468)	LossFusion 0.1381 (0.1468)	
Train Epoch: [261][7/8]	Loss 0.1381 (0.1468)	LossFusion 0.1381 (0.1468)	
Train Epoch: [261][7/8]	Loss 0.1381 (0.1468)	LossFusion 0.1381 (0.1468)	
Train Epoch: [261][7/8]	Loss 0.1381 (0.1468)	LossFusion 0.1381 (0.1468)	
Train Epoch: [261][7/8]	Loss 0.1381 (0.1468)	LossFusion 0.1381 (0.1468)	
R@10:  53.37876081466675     R@50:  79.61385846138
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  79.61385846138
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  79.61385846138
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  79.61385846138
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  79.61385846138
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  79.61385846138
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  79.61385846138
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
R@10:  53.37876081466675     R@50:  79.61385846138
Mean Now:  66.49630963802338  Best Mean Before:  69.44918 --------------------
Train Epoch: [262][0/8]	Loss 0.2790 (0.2790)	LossFusion 0.2790 (0.2790)	
Train Epoch: [262][0/8]	Loss 0.2790 (0.2790)	LossFusion 0.2790 (0.2790)	
Train Epoch: [262][0/8]	Loss 0.2790 (0.2790)	LossFusion 0.2790 (0.2790)	
Train Epoch: [262][0/8]	Loss 0.2790 (0.2790)	LossFusion 0.2790 (0.2790)	
Train Epoch: [262][0/8]	Loss 0.2790 (0.2790)	LossFusion 0.2790 (0.2790)	
Train Epoch: [262][0/8]	Loss 0.2790 (0.2790)	LossFusion 0.2790 (0.2790)	
Train Epoch: [262][0/8]	Loss 0.2790 (0.2790)	LossFusion 0.2790 (0.2790)	
Train Epoch: [262][0/8]	Loss 0.2790 (0.2790)	LossFusion 0.2790 (0.2790)	
Train Epoch: [262][7/8]	Loss 0.1272 (0.1515)	LossFusion 0.1272 (0.1515)	
Train Epoch: [262][7/8]	Loss 0.1272 (0.1515)	LossFusion 0.1272 (0.1515)	
Train Epoch: [262][7/8]	Loss 0.1272 (0.1515)	LossFusion 0.1272 (0.1515)	
Train Epoch: [262][7/8]	Loss 0.1272 (0.1515)	LossFusion 0.1272 (0.1515)	
Train Epoch: [262][7/8]	Loss 0.1272 (0.1515)	LossFusion 0.1272 (0.1515)	
Train Epoch: [262][7/8]	Loss 0.1272 (0.1515)	LossFusion 0.1272 (0.1515)	
Train Epoch: [262][7/8]	Loss 0.1272 (0.1515)	LossFusion 0.1272 (0.1515)	
Train Epoch: [262][7/8]	Loss 0.1272 (0.1515)	LossFusion 0.1272 (0.1515)	
R@10:  53.71947884559631     R@50:  79.78421449661255
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.78421449661255
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.78421449661255
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.78421449661255
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.78421449661255
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.78421449661255
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.78421449661255
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.78421449661255
Mean Now:  66.75184667110443  Best Mean Before:  69.44918 --------------------
Train Epoch: [263][0/8]	Loss 0.2505 (0.2505)	LossFusion 0.2505 (0.2505)	
Train Epoch: [263][0/8]	Loss 0.2505 (0.2505)	LossFusion 0.2505 (0.2505)	
Train Epoch: [263][0/8]	Loss 0.2505 (0.2505)	LossFusion 0.2505 (0.2505)	
Train Epoch: [263][0/8]	Loss 0.2505 (0.2505)	LossFusion 0.2505 (0.2505)	
Train Epoch: [263][0/8]	Loss 0.2505 (0.2505)	LossFusion 0.2505 (0.2505)	
Train Epoch: [263][0/8]	Loss 0.2505 (0.2505)	LossFusion 0.2505 (0.2505)	
Train Epoch: [263][0/8]	Loss 0.2505 (0.2505)	LossFusion 0.2505 (0.2505)	
Train Epoch: [263][0/8]	Loss 0.2505 (0.2505)	LossFusion 0.2505 (0.2505)	
Train Epoch: [263][7/8]	Loss 0.1321 (0.1505)	LossFusion 0.1321 (0.1505)	
Train Epoch: [263][7/8]	Loss 0.1321 (0.1505)	LossFusion 0.1321 (0.1505)	
Train Epoch: [263][7/8]	Loss 0.1321 (0.1505)	LossFusion 0.1321 (0.1505)	
Train Epoch: [263][7/8]	Loss 0.1321 (0.1505)	LossFusion 0.1321 (0.1505)	
Train Epoch: [263][7/8]	Loss 0.1321 (0.1505)	LossFusion 0.1321 (0.1505)	
Train Epoch: [263][7/8]	Loss 0.1321 (0.1505)	LossFusion 0.1321 (0.1505)	
Train Epoch: [263][7/8]	Loss 0.1321 (0.1505)	LossFusion 0.1321 (0.1505)	
Train Epoch: [263][7/8]	Loss 0.1321 (0.1505)	LossFusion 0.1321 (0.1505)	
R@10:  53.43554615974426     R@50:  79.55706715583801
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.55706715583801
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.55706715583801
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.55706715583801
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.55706715583801
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.55706715583801
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.55706715583801
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.43554615974426     R@50:  79.55706715583801
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
Train Epoch: [264][0/8]	Loss 0.2551 (0.2551)	LossFusion 0.2551 (0.2551)	
Train Epoch: [264][0/8]	Loss 0.2551 (0.2551)	LossFusion 0.2551 (0.2551)	
Train Epoch: [264][0/8]	Loss 0.2551 (0.2551)	LossFusion 0.2551 (0.2551)	
Train Epoch: [264][0/8]	Loss 0.2551 (0.2551)	LossFusion 0.2551 (0.2551)	
Train Epoch: [264][0/8]	Loss 0.2551 (0.2551)	LossFusion 0.2551 (0.2551)	
Train Epoch: [264][0/8]	Loss 0.2551 (0.2551)	LossFusion 0.2551 (0.2551)	
Train Epoch: [264][0/8]	Loss 0.2551 (0.2551)	LossFusion 0.2551 (0.2551)	
Train Epoch: [264][0/8]	Loss 0.2551 (0.2551)	LossFusion 0.2551 (0.2551)	
Train Epoch: [264][7/8]	Loss 0.1400 (0.1498)	LossFusion 0.1400 (0.1498)	
Train Epoch: [264][7/8]	Loss 0.1400 (0.1498)	LossFusion 0.1400 (0.1498)	
Train Epoch: [264][7/8]	Loss 0.1400 (0.1498)	LossFusion 0.1400 (0.1498)	
Train Epoch: [264][7/8]	Loss 0.1400 (0.1498)	LossFusion 0.1400 (0.1498)	
Train Epoch: [264][7/8]	Loss 0.1400 (0.1498)	LossFusion 0.1400 (0.1498)	
Train Epoch: [264][7/8]	Loss 0.1400 (0.1498)	LossFusion 0.1400 (0.1498)	
Train Epoch: [264][7/8]	Loss 0.1400 (0.1498)	LossFusion 0.1400 (0.1498)	
Train Epoch: [264][7/8]	Loss 0.1400 (0.1498)	LossFusion 0.1400 (0.1498)	
R@10:  53.54911684989929     R@50:  79.67064380645752
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.67064380645752
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.67064380645752
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.67064380645752
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.67064380645752
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.67064380645752
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.67064380645752
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.67064380645752
Mean Now:  66.6098803281784  Best Mean Before:  69.44918 --------------------
Train Epoch: [265][0/8]	Loss 0.2262 (0.2262)	LossFusion 0.2262 (0.2262)	
Train Epoch: [265][0/8]	Loss 0.2262 (0.2262)	LossFusion 0.2262 (0.2262)	
Train Epoch: [265][0/8]	Loss 0.2262 (0.2262)	LossFusion 0.2262 (0.2262)	
Train Epoch: [265][0/8]	Loss 0.2262 (0.2262)	LossFusion 0.2262 (0.2262)	
Train Epoch: [265][0/8]	Loss 0.2262 (0.2262)	LossFusion 0.2262 (0.2262)	
Train Epoch: [265][0/8]	Loss 0.2262 (0.2262)	LossFusion 0.2262 (0.2262)	
Train Epoch: [265][0/8]	Loss 0.2262 (0.2262)	LossFusion 0.2262 (0.2262)	
Train Epoch: [265][0/8]	Loss 0.2262 (0.2262)	LossFusion 0.2262 (0.2262)	
Train Epoch: [265][7/8]	Loss 0.1475 (0.1444)	LossFusion 0.1475 (0.1444)	
Train Epoch: [265][7/8]	Loss 0.1475 (0.1444)	LossFusion 0.1475 (0.1444)	
Train Epoch: [265][7/8]	Loss 0.1475 (0.1444)	LossFusion 0.1475 (0.1444)	
Train Epoch: [265][7/8]	Loss 0.1475 (0.1444)	LossFusion 0.1475 (0.1444)	
Train Epoch: [265][7/8]	Loss 0.1475 (0.1444)	LossFusion 0.1475 (0.1444)	
Train Epoch: [265][7/8]	Loss 0.1475 (0.1444)	LossFusion 0.1475 (0.1444)	
Train Epoch: [265][7/8]	Loss 0.1475 (0.1444)	LossFusion 0.1475 (0.1444)	
Train Epoch: [265][7/8]	Loss 0.1475 (0.1444)	LossFusion 0.1475 (0.1444)	
R@10:  53.88983488082886     R@50:  79.44349646568298
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.44349646568298
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.44349646568298
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.44349646568298
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.44349646568298
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.44349646568298
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.44349646568298
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.44349646568298
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
Train Epoch: [266][0/8]	Loss 0.2334 (0.2334)	LossFusion 0.2334 (0.2334)	
Train Epoch: [266][0/8]	Loss 0.2334 (0.2334)	LossFusion 0.2334 (0.2334)	
Train Epoch: [266][0/8]	Loss 0.2334 (0.2334)	LossFusion 0.2334 (0.2334)	
Train Epoch: [266][0/8]	Loss 0.2334 (0.2334)	LossFusion 0.2334 (0.2334)	
Train Epoch: [266][0/8]	Loss 0.2334 (0.2334)	LossFusion 0.2334 (0.2334)	
Train Epoch: [266][0/8]	Loss 0.2334 (0.2334)	LossFusion 0.2334 (0.2334)	
Train Epoch: [266][0/8]	Loss 0.2334 (0.2334)	LossFusion 0.2334 (0.2334)	
Train Epoch: [266][0/8]	Loss 0.2334 (0.2334)	LossFusion 0.2334 (0.2334)	
Train Epoch: [266][7/8]	Loss 0.1173 (0.1416)	LossFusion 0.1173 (0.1416)	
Train Epoch: [266][7/8]	Loss 0.1173 (0.1416)	LossFusion 0.1173 (0.1416)	
Train Epoch: [266][7/8]	Loss 0.1173 (0.1416)	LossFusion 0.1173 (0.1416)	
Train Epoch: [266][7/8]	Loss 0.1173 (0.1416)	LossFusion 0.1173 (0.1416)	
Train Epoch: [266][7/8]	Loss 0.1173 (0.1416)	LossFusion 0.1173 (0.1416)	
Train Epoch: [266][7/8]	Loss 0.1173 (0.1416)	LossFusion 0.1173 (0.1416)	
Train Epoch: [266][7/8]	Loss 0.1173 (0.1416)	LossFusion 0.1173 (0.1416)	
Train Epoch: [266][7/8]	Loss 0.1173 (0.1416)	LossFusion 0.1173 (0.1416)	
R@10:  53.54911684989929     R@50:  79.38671112060547
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.38671112060547
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.38671112060547
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.38671112060547
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.38671112060547
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.38671112060547
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.38671112060547
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.38671112060547
Mean Now:  66.46791398525238  Best Mean Before:  69.44918 --------------------
Train Epoch: [267][0/8]	Loss 0.2473 (0.2473)	LossFusion 0.2473 (0.2473)	
Train Epoch: [267][0/8]	Loss 0.2473 (0.2473)	LossFusion 0.2473 (0.2473)	
Train Epoch: [267][0/8]	Loss 0.2473 (0.2473)	LossFusion 0.2473 (0.2473)	
Train Epoch: [267][0/8]	Loss 0.2473 (0.2473)	LossFusion 0.2473 (0.2473)	
Train Epoch: [267][0/8]	Loss 0.2473 (0.2473)	LossFusion 0.2473 (0.2473)	
Train Epoch: [267][0/8]	Loss 0.2473 (0.2473)	LossFusion 0.2473 (0.2473)	
Train Epoch: [267][0/8]	Loss 0.2473 (0.2473)	LossFusion 0.2473 (0.2473)	
Train Epoch: [267][0/8]	Loss 0.2473 (0.2473)	LossFusion 0.2473 (0.2473)	
Train Epoch: [267][7/8]	Loss 0.1186 (0.1440)	LossFusion 0.1186 (0.1440)	
Train Epoch: [267][7/8]	Loss 0.1186 (0.1440)	LossFusion 0.1186 (0.1440)	
Train Epoch: [267][7/8]	Loss 0.1186 (0.1440)	LossFusion 0.1186 (0.1440)	
Train Epoch: [267][7/8]	Loss 0.1186 (0.1440)	LossFusion 0.1186 (0.1440)	
Train Epoch: [267][7/8]	Loss 0.1186 (0.1440)	LossFusion 0.1186 (0.1440)	
Train Epoch: [267][7/8]	Loss 0.1186 (0.1440)	LossFusion 0.1186 (0.1440)	
Train Epoch: [267][7/8]	Loss 0.1186 (0.1440)	LossFusion 0.1186 (0.1440)	
Train Epoch: [267][7/8]	Loss 0.1186 (0.1440)	LossFusion 0.1186 (0.1440)	
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
Train Epoch: [268][0/8]	Loss 0.2294 (0.2294)	LossFusion 0.2294 (0.2294)	
Train Epoch: [268][0/8]	Loss 0.2294 (0.2294)	LossFusion 0.2294 (0.2294)	
Train Epoch: [268][0/8]	Loss 0.2294 (0.2294)	LossFusion 0.2294 (0.2294)	Train Epoch: [268][0/8]	Loss 0.2294 (0.2294)	LossFusion 0.2294 (0.2294)	

Train Epoch: [268][0/8]	Loss 0.2294 (0.2294)	LossFusion 0.2294 (0.2294)	
Train Epoch: [268][0/8]	Loss 0.2294 (0.2294)	LossFusion 0.2294 (0.2294)	
Train Epoch: [268][0/8]	Loss 0.2294 (0.2294)	LossFusion 0.2294 (0.2294)	
Train Epoch: [268][0/8]	Loss 0.2294 (0.2294)	LossFusion 0.2294 (0.2294)	
Train Epoch: [268][7/8]	Loss 0.1203 (0.1430)	LossFusion 0.1203 (0.1430)	
Train Epoch: [268][7/8]	Loss 0.1203 (0.1430)	LossFusion 0.1203 (0.1430)	
Train Epoch: [268][7/8]	Loss 0.1203 (0.1430)	LossFusion 0.1203 (0.1430)	
Train Epoch: [268][7/8]	Loss 0.1203 (0.1430)	LossFusion 0.1203 (0.1430)	
Train Epoch: [268][7/8]	Loss 0.1203 (0.1430)	LossFusion 0.1203 (0.1430)	
Train Epoch: [268][7/8]	Loss 0.1203 (0.1430)	LossFusion 0.1203 (0.1430)	
Train Epoch: [268][7/8]	Loss 0.1203 (0.1430)	LossFusion 0.1203 (0.1430)	
Train Epoch: [268][7/8]	Loss 0.1203 (0.1430)	LossFusion 0.1203 (0.1430)	
R@10:  54.116976261138916     R@50:  79.84099984169006
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.84099984169006
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.84099984169006
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.84099984169006
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.84099984169006
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.84099984169006
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.84099984169006
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.84099984169006
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
Train Epoch: [269][0/8]	Loss 0.2320 (0.2320)	LossFusion 0.2320 (0.2320)	
Train Epoch: [269][0/8]	Loss 0.2320 (0.2320)	LossFusion 0.2320 (0.2320)	
Train Epoch: [269][0/8]	Loss 0.2320 (0.2320)	LossFusion 0.2320 (0.2320)	
Train Epoch: [269][0/8]	Loss 0.2320 (0.2320)	LossFusion 0.2320 (0.2320)	
Train Epoch: [269][0/8]	Loss 0.2320 (0.2320)	LossFusion 0.2320 (0.2320)	
Train Epoch: [269][0/8]	Loss 0.2320 (0.2320)	LossFusion 0.2320 (0.2320)	
Train Epoch: [269][0/8]	Loss 0.2320 (0.2320)	LossFusion 0.2320 (0.2320)	
Train Epoch: [269][0/8]	Loss 0.2320 (0.2320)	LossFusion 0.2320 (0.2320)	
Train Epoch: [269][7/8]	Loss 0.1213 (0.1449)	LossFusion 0.1213 (0.1449)	
Train Epoch: [269][7/8]	Loss 0.1213 (0.1449)	LossFusion 0.1213 (0.1449)	
Train Epoch: [269][7/8]	Loss 0.1213 (0.1449)	LossFusion 0.1213 (0.1449)	
Train Epoch: [269][7/8]	Loss 0.1213 (0.1449)	LossFusion 0.1213 (0.1449)	
Train Epoch: [269][7/8]	Loss 0.1213 (0.1449)	LossFusion 0.1213 (0.1449)	
Train Epoch: [269][7/8]	Loss 0.1213 (0.1449)	LossFusion 0.1213 (0.1449)	
Train Epoch: [269][7/8]	Loss 0.1213 (0.1449)	LossFusion 0.1213 (0.1449)	
Train Epoch: [269][7/8]	Loss 0.1213 (0.1449)	LossFusion 0.1213 (0.1449)	
R@10:  53.77626419067383     R@50:  79.89778518676758
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.89778518676758
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.89778518676758
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.89778518676758
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.89778518676758
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.89778518676758
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.89778518676758
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.89778518676758
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
Train Epoch: [270][0/8]	Loss 0.2398 (0.2398)	LossFusion 0.2398 (0.2398)	
Train Epoch: [270][0/8]	Loss 0.2398 (0.2398)	LossFusion 0.2398 (0.2398)	
Train Epoch: [270][0/8]	Loss 0.2398 (0.2398)	LossFusion 0.2398 (0.2398)	
Train Epoch: [270][0/8]	Loss 0.2398 (0.2398)	LossFusion 0.2398 (0.2398)	
Train Epoch: [270][0/8]	Loss 0.2398 (0.2398)	LossFusion 0.2398 (0.2398)	
Train Epoch: [270][0/8]	Loss 0.2398 (0.2398)	LossFusion 0.2398 (0.2398)	
Train Epoch: [270][0/8]	Loss 0.2398 (0.2398)	LossFusion 0.2398 (0.2398)	
Train Epoch: [270][0/8]	Loss 0.2398 (0.2398)	LossFusion 0.2398 (0.2398)	
Train Epoch: [270][7/8]	Loss 0.1254 (0.1462)	LossFusion 0.1254 (0.1462)	
Train Epoch: [270][7/8]	Loss 0.1254 (0.1462)	LossFusion 0.1254 (0.1462)	
Train Epoch: [270][7/8]	Loss 0.1254 (0.1462)	LossFusion 0.1254 (0.1462)	
Train Epoch: [270][7/8]	Loss 0.1254 (0.1462)	LossFusion 0.1254 (0.1462)	
Train Epoch: [270][7/8]	Loss 0.1254 (0.1462)	LossFusion 0.1254 (0.1462)	
Train Epoch: [270][7/8]	Loss 0.1254 (0.1462)	LossFusion 0.1254 (0.1462)	
Train Epoch: [270][7/8]	Loss 0.1254 (0.1462)	LossFusion 0.1254 (0.1462)	
Train Epoch: [270][7/8]	Loss 0.1254 (0.1462)	LossFusion 0.1254 (0.1462)	
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.67064380645752
Mean Now:  66.66666865348816  Best Mean Before:  69.44918 --------------------
Train Epoch: [271][0/8]	Loss 0.2397 (0.2397)	LossFusion 0.2397 (0.2397)	
Train Epoch: [271][0/8]	Loss 0.2397 (0.2397)	LossFusion 0.2397 (0.2397)	
Train Epoch: [271][0/8]	Loss 0.2397 (0.2397)	LossFusion 0.2397 (0.2397)	
Train Epoch: [271][0/8]	Loss 0.2397 (0.2397)	LossFusion 0.2397 (0.2397)	
Train Epoch: [271][0/8]	Loss 0.2397 (0.2397)	LossFusion 0.2397 (0.2397)	
Train Epoch: [271][0/8]	Loss 0.2397 (0.2397)	LossFusion 0.2397 (0.2397)	
Train Epoch: [271][0/8]	Loss 0.2397 (0.2397)	LossFusion 0.2397 (0.2397)	
Train Epoch: [271][0/8]	Loss 0.2397 (0.2397)	LossFusion 0.2397 (0.2397)	
Train Epoch: [271][7/8]	Loss 0.1206 (0.1459)	LossFusion 0.1206 (0.1459)	
Train Epoch: [271][7/8]	Loss 0.1206 (0.1459)	LossFusion 0.1206 (0.1459)	
Train Epoch: [271][7/8]	Loss 0.1206 (0.1459)	LossFusion 0.1206 (0.1459)	
Train Epoch: [271][7/8]	Loss 0.1206 (0.1459)	LossFusion 0.1206 (0.1459)	
Train Epoch: [271][7/8]	Loss 0.1206 (0.1459)	LossFusion 0.1206 (0.1459)	
Train Epoch: [271][7/8]	Loss 0.1206 (0.1459)	LossFusion 0.1206 (0.1459)	
Train Epoch: [271][7/8]	Loss 0.1206 (0.1459)	LossFusion 0.1206 (0.1459)	
Train Epoch: [271][7/8]	Loss 0.1206 (0.1459)	LossFusion 0.1206 (0.1459)	
R@10:  53.77626419067383     R@50:  79.55706715583801
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.55706715583801
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.55706715583801
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.55706715583801
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.55706715583801
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.55706715583801
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.55706715583801
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.77626419067383     R@50:  79.55706715583801
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
Train Epoch: [272][0/8]	Loss 0.2683 (0.2683)	LossFusion 0.2683 (0.2683)	
Train Epoch: [272][0/8]	Loss 0.2683 (0.2683)	LossFusion 0.2683 (0.2683)	
Train Epoch: [272][0/8]	Loss 0.2683 (0.2683)	LossFusion 0.2683 (0.2683)	
Train Epoch: [272][0/8]	Loss 0.2683 (0.2683)	LossFusion 0.2683 (0.2683)	
Train Epoch: [272][0/8]	Loss 0.2683 (0.2683)	LossFusion 0.2683 (0.2683)	
Train Epoch: [272][0/8]	Loss 0.2683 (0.2683)	LossFusion 0.2683 (0.2683)	
Train Epoch: [272][0/8]	Loss 0.2683 (0.2683)	LossFusion 0.2683 (0.2683)	
Train Epoch: [272][0/8]	Loss 0.2683 (0.2683)	LossFusion 0.2683 (0.2683)	
Train Epoch: [272][7/8]	Loss 0.1419 (0.1443)	LossFusion 0.1419 (0.1443)	
Train Epoch: [272][7/8]	Loss 0.1419 (0.1443)	LossFusion 0.1419 (0.1443)	
Train Epoch: [272][7/8]	Loss 0.1419 (0.1443)	LossFusion 0.1419 (0.1443)	
Train Epoch: [272][7/8]	Loss 0.1419 (0.1443)	LossFusion 0.1419 (0.1443)	
Train Epoch: [272][7/8]	Loss 0.1419 (0.1443)	LossFusion 0.1419 (0.1443)	
Train Epoch: [272][7/8]	Loss 0.1419 (0.1443)	LossFusion 0.1419 (0.1443)	
Train Epoch: [272][7/8]	Loss 0.1419 (0.1443)	LossFusion 0.1419 (0.1443)	
Train Epoch: [272][7/8]	Loss 0.1419 (0.1443)	LossFusion 0.1419 (0.1443)	
R@10:  53.54911684989929     R@50:  79.44349646568298
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.44349646568298
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.44349646568298
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.44349646568298
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.44349646568298
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.44349646568298
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.44349646568298
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
R@10:  53.54911684989929     R@50:  79.44349646568298
Mean Now:  66.49630665779114  Best Mean Before:  69.44918 --------------------
Train Epoch: [273][0/8]	Loss 0.2332 (0.2332)	LossFusion 0.2332 (0.2332)	Train Epoch: [273][0/8]	Loss 0.2332 (0.2332)	LossFusion 0.2332 (0.2332)	

Train Epoch: [273][0/8]	Loss 0.2332 (0.2332)	LossFusion 0.2332 (0.2332)	
Train Epoch: [273][0/8]	Loss 0.2332 (0.2332)	LossFusion 0.2332 (0.2332)	
Train Epoch: [273][0/8]	Loss 0.2332 (0.2332)	LossFusion 0.2332 (0.2332)	
Train Epoch: [273][0/8]	Loss 0.2332 (0.2332)	LossFusion 0.2332 (0.2332)	
Train Epoch: [273][0/8]	Loss 0.2332 (0.2332)	LossFusion 0.2332 (0.2332)	
Train Epoch: [273][0/8]	Loss 0.2332 (0.2332)	LossFusion 0.2332 (0.2332)	
Train Epoch: [273][7/8]	Loss 0.1118 (0.1353)	LossFusion 0.1118 (0.1353)	
Train Epoch: [273][7/8]	Loss 0.1118 (0.1353)	LossFusion 0.1118 (0.1353)	
Train Epoch: [273][7/8]	Loss 0.1118 (0.1353)	LossFusion 0.1118 (0.1353)	
Train Epoch: [273][7/8]	Loss 0.1118 (0.1353)	LossFusion 0.1118 (0.1353)	
Train Epoch: [273][7/8]	Loss 0.1118 (0.1353)	LossFusion 0.1118 (0.1353)	
Train Epoch: [273][7/8]	Loss 0.1118 (0.1353)	LossFusion 0.1118 (0.1353)	
Train Epoch: [273][7/8]	Loss 0.1118 (0.1353)	LossFusion 0.1118 (0.1353)	
Train Epoch: [273][7/8]	Loss 0.1118 (0.1353)	LossFusion 0.1118 (0.1353)	
R@10:  53.83304953575134     R@50:  79.44349646568298
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.44349646568298
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.44349646568298
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.44349646568298
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.44349646568298
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.44349646568298
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.44349646568298
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.44349646568298
Mean Now:  66.63827300071716  Best Mean Before:  69.44918 --------------------
Train Epoch: [274][0/8]	Loss 0.2309 (0.2309)	LossFusion 0.2309 (0.2309)	
Train Epoch: [274][0/8]	Loss 0.2309 (0.2309)	LossFusion 0.2309 (0.2309)	
Train Epoch: [274][0/8]	Loss 0.2309 (0.2309)	LossFusion 0.2309 (0.2309)	
Train Epoch: [274][0/8]	Loss 0.2309 (0.2309)	LossFusion 0.2309 (0.2309)	
Train Epoch: [274][0/8]	Loss 0.2309 (0.2309)	LossFusion 0.2309 (0.2309)	
Train Epoch: [274][0/8]	Loss 0.2309 (0.2309)	LossFusion 0.2309 (0.2309)	
Train Epoch: [274][0/8]	Loss 0.2309 (0.2309)	LossFusion 0.2309 (0.2309)	
Train Epoch: [274][0/8]	Loss 0.2309 (0.2309)	LossFusion 0.2309 (0.2309)	
Train Epoch: [274][7/8]	Loss 0.1237 (0.1465)	LossFusion 0.1237 (0.1465)	
Train Epoch: [274][7/8]	Loss 0.1237 (0.1465)	LossFusion 0.1237 (0.1465)	
Train Epoch: [274][7/8]	Loss 0.1237 (0.1465)	LossFusion 0.1237 (0.1465)	
Train Epoch: [274][7/8]	Loss 0.1237 (0.1465)	LossFusion 0.1237 (0.1465)	
Train Epoch: [274][7/8]	Loss 0.1237 (0.1465)	LossFusion 0.1237 (0.1465)	
Train Epoch: [274][7/8]	Loss 0.1237 (0.1465)	LossFusion 0.1237 (0.1465)	
Train Epoch: [274][7/8]	Loss 0.1237 (0.1465)	LossFusion 0.1237 (0.1465)	
Train Epoch: [274][7/8]	Loss 0.1237 (0.1465)	LossFusion 0.1237 (0.1465)	
R@10:  53.88983488082886     R@50:  79.55706715583801
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.55706715583801
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.55706715583801
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.55706715583801
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.55706715583801
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.55706715583801
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.55706715583801
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.55706715583801
Mean Now:  66.72345101833344  Best Mean Before:  69.44918 --------------------
Train Epoch: [275][0/8]	Loss 0.2482 (0.2482)	LossFusion 0.2482 (0.2482)	
Train Epoch: [275][0/8]	Loss 0.2482 (0.2482)	LossFusion 0.2482 (0.2482)	
Train Epoch: [275][0/8]	Loss 0.2482 (0.2482)	LossFusion 0.2482 (0.2482)	
Train Epoch: [275][0/8]	Loss 0.2482 (0.2482)	LossFusion 0.2482 (0.2482)	
Train Epoch: [275][0/8]	Loss 0.2482 (0.2482)	LossFusion 0.2482 (0.2482)	
Train Epoch: [275][0/8]	Loss 0.2482 (0.2482)	LossFusion 0.2482 (0.2482)	
Train Epoch: [275][0/8]	Loss 0.2482 (0.2482)	LossFusion 0.2482 (0.2482)	
Train Epoch: [275][0/8]	Loss 0.2482 (0.2482)	LossFusion 0.2482 (0.2482)	
Train Epoch: [275][7/8]	Loss 0.1306 (0.1488)	LossFusion 0.1306 (0.1488)	
Train Epoch: [275][7/8]	Loss 0.1306 (0.1488)	LossFusion 0.1306 (0.1488)	
Train Epoch: [275][7/8]	Loss 0.1306 (0.1488)	LossFusion 0.1306 (0.1488)	
Train Epoch: [275][7/8]	Loss 0.1306 (0.1488)	LossFusion 0.1306 (0.1488)	
Train Epoch: [275][7/8]	Loss 0.1306 (0.1488)	LossFusion 0.1306 (0.1488)	
Train Epoch: [275][7/8]	Loss 0.1306 (0.1488)	LossFusion 0.1306 (0.1488)	
Train Epoch: [275][7/8]	Loss 0.1306 (0.1488)	LossFusion 0.1306 (0.1488)	
Train Epoch: [275][7/8]	Loss 0.1306 (0.1488)	LossFusion 0.1306 (0.1488)	
R@10:  53.83304953575134     R@50:  79.5002818107605
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.5002818107605
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.5002818107605
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.5002818107605
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.5002818107605
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.5002818107605
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.5002818107605
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.5002818107605
Mean Now:  66.66666567325592  Best Mean Before:  69.44918 --------------------
Train Epoch: [276][0/8]	Loss 0.2417 (0.2417)	LossFusion 0.2417 (0.2417)	
Train Epoch: [276][0/8]	Loss 0.2417 (0.2417)	LossFusion 0.2417 (0.2417)	
Train Epoch: [276][0/8]	Loss 0.2417 (0.2417)	LossFusion 0.2417 (0.2417)	
Train Epoch: [276][0/8]	Loss 0.2417 (0.2417)	LossFusion 0.2417 (0.2417)	
Train Epoch: [276][0/8]	Loss 0.2417 (0.2417)	LossFusion 0.2417 (0.2417)	
Train Epoch: [276][0/8]	Loss 0.2417 (0.2417)	LossFusion 0.2417 (0.2417)	
Train Epoch: [276][0/8]	Loss 0.2417 (0.2417)	LossFusion 0.2417 (0.2417)	
Train Epoch: [276][0/8]	Loss 0.2417 (0.2417)	LossFusion 0.2417 (0.2417)	
Train Epoch: [276][7/8]	Loss 0.1432 (0.1437)	LossFusion 0.1432 (0.1437)	
Train Epoch: [276][7/8]	Loss 0.1432 (0.1437)	LossFusion 0.1432 (0.1437)	
Train Epoch: [276][7/8]	Loss 0.1432 (0.1437)	LossFusion 0.1432 (0.1437)	
Train Epoch: [276][7/8]	Loss 0.1432 (0.1437)	LossFusion 0.1432 (0.1437)	
Train Epoch: [276][7/8]	Loss 0.1432 (0.1437)	LossFusion 0.1432 (0.1437)	
Train Epoch: [276][7/8]	Loss 0.1432 (0.1437)	LossFusion 0.1432 (0.1437)	
Train Epoch: [276][7/8]	Loss 0.1432 (0.1437)	LossFusion 0.1432 (0.1437)	
Train Epoch: [276][7/8]	Loss 0.1432 (0.1437)	LossFusion 0.1432 (0.1437)	
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
Train Epoch: [277][0/8]	Loss 0.2497 (0.2497)	LossFusion 0.2497 (0.2497)	
Train Epoch: [277][0/8]	Loss 0.2497 (0.2497)	LossFusion 0.2497 (0.2497)	
Train Epoch: [277][0/8]	Loss 0.2497 (0.2497)	LossFusion 0.2497 (0.2497)	
Train Epoch: [277][0/8]	Loss 0.2497 (0.2497)	LossFusion 0.2497 (0.2497)	
Train Epoch: [277][0/8]	Loss 0.2497 (0.2497)	LossFusion 0.2497 (0.2497)	
Train Epoch: [277][0/8]	Loss 0.2497 (0.2497)	LossFusion 0.2497 (0.2497)	
Train Epoch: [277][0/8]	Loss 0.2497 (0.2497)	LossFusion 0.2497 (0.2497)	
Train Epoch: [277][0/8]	Loss 0.2497 (0.2497)	LossFusion 0.2497 (0.2497)	
Train Epoch: [277][7/8]	Loss 0.1285 (0.1419)	LossFusion 0.1285 (0.1419)	
Train Epoch: [277][7/8]	Loss 0.1285 (0.1419)	LossFusion 0.1285 (0.1419)	
Train Epoch: [277][7/8]	Loss 0.1285 (0.1419)	LossFusion 0.1285 (0.1419)	
Train Epoch: [277][7/8]	Loss 0.1285 (0.1419)	LossFusion 0.1285 (0.1419)	
Train Epoch: [277][7/8]	Loss 0.1285 (0.1419)	LossFusion 0.1285 (0.1419)	
Train Epoch: [277][7/8]	Loss 0.1285 (0.1419)	LossFusion 0.1285 (0.1419)	
Train Epoch: [277][7/8]	Loss 0.1285 (0.1419)	LossFusion 0.1285 (0.1419)	
Train Epoch: [277][7/8]	Loss 0.1285 (0.1419)	LossFusion 0.1285 (0.1419)	
R@10:  53.6626935005188     R@50:  79.78421449661255
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.78421449661255
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.78421449661255
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.78421449661255
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.78421449661255
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.78421449661255
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.78421449661255
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.6626935005188     R@50:  79.78421449661255
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
Train Epoch: [278][0/8]	Loss 0.2019 (0.2019)	LossFusion 0.2019 (0.2019)	
Train Epoch: [278][0/8]	Loss 0.2019 (0.2019)	LossFusion 0.2019 (0.2019)	
Train Epoch: [278][0/8]	Loss 0.2019 (0.2019)	LossFusion 0.2019 (0.2019)	
Train Epoch: [278][0/8]	Loss 0.2019 (0.2019)	LossFusion 0.2019 (0.2019)	
Train Epoch: [278][0/8]	Loss 0.2019 (0.2019)	LossFusion 0.2019 (0.2019)	
Train Epoch: [278][0/8]	Loss 0.2019 (0.2019)	LossFusion 0.2019 (0.2019)	
Train Epoch: [278][0/8]	Loss 0.2019 (0.2019)	LossFusion 0.2019 (0.2019)	
Train Epoch: [278][0/8]	Loss 0.2019 (0.2019)	LossFusion 0.2019 (0.2019)	
Train Epoch: [278][7/8]	Loss 0.1379 (0.1423)	LossFusion 0.1379 (0.1423)	
Train Epoch: [278][7/8]	Loss 0.1379 (0.1423)	LossFusion 0.1379 (0.1423)	
Train Epoch: [278][7/8]	Loss 0.1379 (0.1423)	LossFusion 0.1379 (0.1423)	
Train Epoch: [278][7/8]	Loss 0.1379 (0.1423)	LossFusion 0.1379 (0.1423)	
Train Epoch: [278][7/8]	Loss 0.1379 (0.1423)	LossFusion 0.1379 (0.1423)	
Train Epoch: [278][7/8]	Loss 0.1379 (0.1423)	LossFusion 0.1379 (0.1423)	
Train Epoch: [278][7/8]	Loss 0.1379 (0.1423)	LossFusion 0.1379 (0.1423)	
Train Epoch: [278][7/8]	Loss 0.1379 (0.1423)	LossFusion 0.1379 (0.1423)	
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.78421449661255
Mean Now:  66.8370246887207  Best Mean Before:  69.44918 --------------------
Train Epoch: [279][0/8]	Loss 0.2449 (0.2449)	LossFusion 0.2449 (0.2449)	
Train Epoch: [279][0/8]	Loss 0.2449 (0.2449)	LossFusion 0.2449 (0.2449)	
Train Epoch: [279][0/8]	Loss 0.2449 (0.2449)	LossFusion 0.2449 (0.2449)	
Train Epoch: [279][0/8]	Loss 0.2449 (0.2449)	LossFusion 0.2449 (0.2449)	
Train Epoch: [279][0/8]	Loss 0.2449 (0.2449)	LossFusion 0.2449 (0.2449)	
Train Epoch: [279][0/8]	Loss 0.2449 (0.2449)	LossFusion 0.2449 (0.2449)	
Train Epoch: [279][0/8]	Loss 0.2449 (0.2449)	LossFusion 0.2449 (0.2449)	
Train Epoch: [279][0/8]	Loss 0.2449 (0.2449)	LossFusion 0.2449 (0.2449)	
Train Epoch: [279][7/8]	Loss 0.1124 (0.1366)	LossFusion 0.1124 (0.1366)	
Train Epoch: [279][7/8]	Loss 0.1124 (0.1366)	LossFusion 0.1124 (0.1366)	
Train Epoch: [279][7/8]	Loss 0.1124 (0.1366)	LossFusion 0.1124 (0.1366)	
Train Epoch: [279][7/8]	Loss 0.1124 (0.1366)	LossFusion 0.1124 (0.1366)	
Train Epoch: [279][7/8]	Loss 0.1124 (0.1366)	LossFusion 0.1124 (0.1366)	
Train Epoch: [279][7/8]	Loss 0.1124 (0.1366)	LossFusion 0.1124 (0.1366)	
Train Epoch: [279][7/8]	Loss 0.1124 (0.1366)	LossFusion 0.1124 (0.1366)	
Train Epoch: [279][7/8]	Loss 0.1124 (0.1366)	LossFusion 0.1124 (0.1366)	
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.72742915153503
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
Train Epoch: [280][0/8]	Loss 0.2409 (0.2409)	LossFusion 0.2409 (0.2409)	
Train Epoch: [280][0/8]	Loss 0.2409 (0.2409)	LossFusion 0.2409 (0.2409)	Train Epoch: [280][0/8]	Loss 0.2409 (0.2409)	LossFusion 0.2409 (0.2409)	

Train Epoch: [280][0/8]	Loss 0.2409 (0.2409)	LossFusion 0.2409 (0.2409)	
Train Epoch: [280][0/8]	Loss 0.2409 (0.2409)	LossFusion 0.2409 (0.2409)	
Train Epoch: [280][0/8]	Loss 0.2409 (0.2409)	LossFusion 0.2409 (0.2409)	
Train Epoch: [280][0/8]	Loss 0.2409 (0.2409)	LossFusion 0.2409 (0.2409)	
Train Epoch: [280][0/8]	Loss 0.2409 (0.2409)	LossFusion 0.2409 (0.2409)	
Train Epoch: [280][7/8]	Loss 0.1382 (0.1415)	LossFusion 0.1382 (0.1415)	
Train Epoch: [280][7/8]	Loss 0.1382 (0.1415)	LossFusion 0.1382 (0.1415)	
Train Epoch: [280][7/8]	Loss 0.1382 (0.1415)	LossFusion 0.1382 (0.1415)	
Train Epoch: [280][7/8]	Loss 0.1382 (0.1415)	LossFusion 0.1382 (0.1415)	
Train Epoch: [280][7/8]	Loss 0.1382 (0.1415)	LossFusion 0.1382 (0.1415)	
Train Epoch: [280][7/8]	Loss 0.1382 (0.1415)	LossFusion 0.1382 (0.1415)	
Train Epoch: [280][7/8]	Loss 0.1382 (0.1415)	LossFusion 0.1382 (0.1415)	
Train Epoch: [280][7/8]	Loss 0.1382 (0.1415)	LossFusion 0.1382 (0.1415)	
R@10:  53.83304953575134     R@50:  79.72742915153503
Mean Now:  66.78023934364319  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.72742915153503
Mean Now:  66.78023934364319  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.72742915153503
Mean Now:  66.78023934364319  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.72742915153503
Mean Now:  66.78023934364319  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.72742915153503
Mean Now:  66.78023934364319  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.72742915153503
Mean Now:  66.78023934364319  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.72742915153503
Mean Now:  66.78023934364319  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.72742915153503
Mean Now:  66.78023934364319  Best Mean Before:  69.44918 --------------------
Train Epoch: [281][0/8]	Loss 0.2290 (0.2290)	LossFusion 0.2290 (0.2290)	
Train Epoch: [281][0/8]	Loss 0.2290 (0.2290)	LossFusion 0.2290 (0.2290)	
Train Epoch: [281][0/8]	Loss 0.2290 (0.2290)	LossFusion 0.2290 (0.2290)	
Train Epoch: [281][0/8]	Loss 0.2290 (0.2290)	LossFusion 0.2290 (0.2290)	
Train Epoch: [281][0/8]	Loss 0.2290 (0.2290)	LossFusion 0.2290 (0.2290)	
Train Epoch: [281][0/8]	Loss 0.2290 (0.2290)	LossFusion 0.2290 (0.2290)	
Train Epoch: [281][0/8]	Loss 0.2290 (0.2290)	LossFusion 0.2290 (0.2290)	
Train Epoch: [281][0/8]	Loss 0.2290 (0.2290)	LossFusion 0.2290 (0.2290)	
Train Epoch: [281][7/8]	Loss 0.1381 (0.1423)	LossFusion 0.1381 (0.1423)	
Train Epoch: [281][7/8]	Loss 0.1381 (0.1423)	LossFusion 0.1381 (0.1423)	
Train Epoch: [281][7/8]	Loss 0.1381 (0.1423)	LossFusion 0.1381 (0.1423)	
Train Epoch: [281][7/8]	Loss 0.1381 (0.1423)	LossFusion 0.1381 (0.1423)	
Train Epoch: [281][7/8]	Loss 0.1381 (0.1423)	LossFusion 0.1381 (0.1423)	
Train Epoch: [281][7/8]	Loss 0.1381 (0.1423)	LossFusion 0.1381 (0.1423)	
Train Epoch: [281][7/8]	Loss 0.1381 (0.1423)	LossFusion 0.1381 (0.1423)	Train Epoch: [281][7/8]	Loss 0.1381 (0.1423)	LossFusion 0.1381 (0.1423)	

R@10:  53.71947884559631     R@50:  79.72742915153503
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.72742915153503
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.72742915153503
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.72742915153503
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.72742915153503
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.72742915153503
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.72742915153503
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
R@10:  53.71947884559631     R@50:  79.72742915153503
Mean Now:  66.72345399856567  Best Mean Before:  69.44918 --------------------
Train Epoch: [282][0/8]	Loss 0.2546 (0.2546)	LossFusion 0.2546 (0.2546)	
Train Epoch: [282][0/8]	Loss 0.2546 (0.2546)	LossFusion 0.2546 (0.2546)	
Train Epoch: [282][0/8]	Loss 0.2546 (0.2546)	LossFusion 0.2546 (0.2546)	
Train Epoch: [282][0/8]	Loss 0.2546 (0.2546)	LossFusion 0.2546 (0.2546)	
Train Epoch: [282][0/8]	Loss 0.2546 (0.2546)	LossFusion 0.2546 (0.2546)	
Train Epoch: [282][0/8]	Loss 0.2546 (0.2546)	LossFusion 0.2546 (0.2546)	
Train Epoch: [282][0/8]	Loss 0.2546 (0.2546)	LossFusion 0.2546 (0.2546)	
Train Epoch: [282][0/8]	Loss 0.2546 (0.2546)	LossFusion 0.2546 (0.2546)	
Train Epoch: [282][7/8]	Loss 0.1310 (0.1472)	LossFusion 0.1310 (0.1472)	
Train Epoch: [282][7/8]	Loss 0.1310 (0.1472)	LossFusion 0.1310 (0.1472)	
Train Epoch: [282][7/8]	Loss 0.1310 (0.1472)	LossFusion 0.1310 (0.1472)	
Train Epoch: [282][7/8]	Loss 0.1310 (0.1472)	LossFusion 0.1310 (0.1472)	
Train Epoch: [282][7/8]	Loss 0.1310 (0.1472)	LossFusion 0.1310 (0.1472)	
Train Epoch: [282][7/8]	Loss 0.1310 (0.1472)	LossFusion 0.1310 (0.1472)	
Train Epoch: [282][7/8]	Loss 0.1310 (0.1472)	LossFusion 0.1310 (0.1472)	
Train Epoch: [282][7/8]	Loss 0.1310 (0.1472)	LossFusion 0.1310 (0.1472)	
R@10:  53.83304953575134     R@50:  79.78421449661255
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.78421449661255
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.78421449661255
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.78421449661255
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.78421449661255
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.78421449661255
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.78421449661255
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.78421449661255
Mean Now:  66.80863201618195  Best Mean Before:  69.44918 --------------------
Train Epoch: [283][0/8]	Loss 0.2263 (0.2263)	LossFusion 0.2263 (0.2263)	
Train Epoch: [283][0/8]	Loss 0.2263 (0.2263)	LossFusion 0.2263 (0.2263)	
Train Epoch: [283][0/8]	Loss 0.2263 (0.2263)	LossFusion 0.2263 (0.2263)	
Train Epoch: [283][0/8]	Loss 0.2263 (0.2263)	LossFusion 0.2263 (0.2263)	
Train Epoch: [283][0/8]	Loss 0.2263 (0.2263)	LossFusion 0.2263 (0.2263)	
Train Epoch: [283][0/8]	Loss 0.2263 (0.2263)	LossFusion 0.2263 (0.2263)	
Train Epoch: [283][0/8]	Loss 0.2263 (0.2263)	LossFusion 0.2263 (0.2263)	
Train Epoch: [283][0/8]	Loss 0.2263 (0.2263)	LossFusion 0.2263 (0.2263)	
Train Epoch: [283][7/8]	Loss 0.1372 (0.1389)	LossFusion 0.1372 (0.1389)	
Train Epoch: [283][7/8]	Loss 0.1372 (0.1389)	LossFusion 0.1372 (0.1389)	
Train Epoch: [283][7/8]	Loss 0.1372 (0.1389)	LossFusion 0.1372 (0.1389)	
Train Epoch: [283][7/8]	Loss 0.1372 (0.1389)	LossFusion 0.1372 (0.1389)	
Train Epoch: [283][7/8]	Loss 0.1372 (0.1389)	LossFusion 0.1372 (0.1389)	
Train Epoch: [283][7/8]	Loss 0.1372 (0.1389)	LossFusion 0.1372 (0.1389)	
Train Epoch: [283][7/8]	Loss 0.1372 (0.1389)	LossFusion 0.1372 (0.1389)	
Train Epoch: [283][7/8]	Loss 0.1372 (0.1389)	LossFusion 0.1372 (0.1389)	
R@10:  54.00340557098389     R@50:  79.84099984169006
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.84099984169006
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.84099984169006
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.84099984169006
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.84099984169006
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.84099984169006
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.84099984169006
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.84099984169006
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
Train Epoch: [284][0/8]	Loss 0.2210 (0.2210)	LossFusion 0.2210 (0.2210)	
Train Epoch: [284][0/8]	Loss 0.2210 (0.2210)	LossFusion 0.2210 (0.2210)	
Train Epoch: [284][0/8]	Loss 0.2210 (0.2210)	LossFusion 0.2210 (0.2210)	
Train Epoch: [284][0/8]	Loss 0.2210 (0.2210)	LossFusion 0.2210 (0.2210)	
Train Epoch: [284][0/8]	Loss 0.2210 (0.2210)	LossFusion 0.2210 (0.2210)	
Train Epoch: [284][0/8]	Loss 0.2210 (0.2210)	LossFusion 0.2210 (0.2210)	
Train Epoch: [284][0/8]	Loss 0.2210 (0.2210)	LossFusion 0.2210 (0.2210)	
Train Epoch: [284][0/8]	Loss 0.2210 (0.2210)	LossFusion 0.2210 (0.2210)	
Train Epoch: [284][7/8]	Loss 0.1168 (0.1342)	LossFusion 0.1168 (0.1342)	
Train Epoch: [284][7/8]	Loss 0.1168 (0.1342)	LossFusion 0.1168 (0.1342)	
Train Epoch: [284][7/8]	Loss 0.1168 (0.1342)	LossFusion 0.1168 (0.1342)	
Train Epoch: [284][7/8]	Loss 0.1168 (0.1342)	LossFusion 0.1168 (0.1342)	
Train Epoch: [284][7/8]	Loss 0.1168 (0.1342)	LossFusion 0.1168 (0.1342)	
Train Epoch: [284][7/8]	Loss 0.1168 (0.1342)	LossFusion 0.1168 (0.1342)	
Train Epoch: [284][7/8]	Loss 0.1168 (0.1342)	LossFusion 0.1168 (0.1342)	
Train Epoch: [284][7/8]	Loss 0.1168 (0.1342)	LossFusion 0.1168 (0.1342)	
R@10:  53.94662022590637     R@50:  79.95457053184509
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.95457053184509
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.95457053184509
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.95457053184509
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.95457053184509
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.95457053184509
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.95457053184509
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.95457053184509
Mean Now:  66.95059537887573  Best Mean Before:  69.44918 --------------------
Train Epoch: [285][0/8]	Loss 0.2371 (0.2371)	LossFusion 0.2371 (0.2371)	
Train Epoch: [285][0/8]	Loss 0.2371 (0.2371)	LossFusion 0.2371 (0.2371)	
Train Epoch: [285][0/8]	Loss 0.2371 (0.2371)	LossFusion 0.2371 (0.2371)	
Train Epoch: [285][0/8]	Loss 0.2371 (0.2371)	LossFusion 0.2371 (0.2371)	
Train Epoch: [285][0/8]	Loss 0.2371 (0.2371)	LossFusion 0.2371 (0.2371)	
Train Epoch: [285][0/8]	Loss 0.2371 (0.2371)	LossFusion 0.2371 (0.2371)	
Train Epoch: [285][0/8]	Loss 0.2371 (0.2371)	LossFusion 0.2371 (0.2371)	
Train Epoch: [285][0/8]	Loss 0.2371 (0.2371)	LossFusion 0.2371 (0.2371)	
Train Epoch: [285][7/8]	Loss 0.1200 (0.1381)	LossFusion 0.1200 (0.1381)	
Train Epoch: [285][7/8]	Loss 0.1200 (0.1381)	LossFusion 0.1200 (0.1381)	
Train Epoch: [285][7/8]	Loss 0.1200 (0.1381)	LossFusion 0.1200 (0.1381)	
Train Epoch: [285][7/8]	Loss 0.1200 (0.1381)	LossFusion 0.1200 (0.1381)	
Train Epoch: [285][7/8]	Loss 0.1200 (0.1381)	LossFusion 0.1200 (0.1381)	
Train Epoch: [285][7/8]	Loss 0.1200 (0.1381)	LossFusion 0.1200 (0.1381)	
Train Epoch: [285][7/8]	Loss 0.1200 (0.1381)	LossFusion 0.1200 (0.1381)	
Train Epoch: [285][7/8]	Loss 0.1200 (0.1381)	LossFusion 0.1200 (0.1381)	
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
Train Epoch: [286][0/8]	Loss 0.2308 (0.2308)	LossFusion 0.2308 (0.2308)	
Train Epoch: [286][0/8]	Loss 0.2308 (0.2308)	LossFusion 0.2308 (0.2308)	
Train Epoch: [286][0/8]	Loss 0.2308 (0.2308)	LossFusion 0.2308 (0.2308)	
Train Epoch: [286][0/8]	Loss 0.2308 (0.2308)	LossFusion 0.2308 (0.2308)	
Train Epoch: [286][0/8]	Loss 0.2308 (0.2308)	LossFusion 0.2308 (0.2308)	
Train Epoch: [286][0/8]	Loss 0.2308 (0.2308)	LossFusion 0.2308 (0.2308)	
Train Epoch: [286][0/8]	Loss 0.2308 (0.2308)	LossFusion 0.2308 (0.2308)	
Train Epoch: [286][0/8]	Loss 0.2308 (0.2308)	LossFusion 0.2308 (0.2308)	
Train Epoch: [286][7/8]	Loss 0.1261 (0.1418)	LossFusion 0.1261 (0.1418)	
Train Epoch: [286][7/8]	Loss 0.1261 (0.1418)	LossFusion 0.1261 (0.1418)	Train Epoch: [286][7/8]	Loss 0.1261 (0.1418)	LossFusion 0.1261 (0.1418)	

Train Epoch: [286][7/8]	Loss 0.1261 (0.1418)	LossFusion 0.1261 (0.1418)	
Train Epoch: [286][7/8]	Loss 0.1261 (0.1418)	LossFusion 0.1261 (0.1418)	
Train Epoch: [286][7/8]	Loss 0.1261 (0.1418)	LossFusion 0.1261 (0.1418)	
Train Epoch: [286][7/8]	Loss 0.1261 (0.1418)	LossFusion 0.1261 (0.1418)	
Train Epoch: [286][7/8]	Loss 0.1261 (0.1418)	LossFusion 0.1261 (0.1418)	
R@10:  53.88983488082886     R@50:  79.84099984169006
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.84099984169006
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.84099984169006
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.84099984169006
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.84099984169006
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.84099984169006
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.84099984169006
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.84099984169006
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
Train Epoch: [287][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [287][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [287][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [287][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [287][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [287][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [287][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [287][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [287][7/8]	Loss 0.1269 (0.1364)	LossFusion 0.1269 (0.1364)	
Train Epoch: [287][7/8]	Loss 0.1269 (0.1364)	LossFusion 0.1269 (0.1364)	
Train Epoch: [287][7/8]	Loss 0.1269 (0.1364)	LossFusion 0.1269 (0.1364)	
Train Epoch: [287][7/8]	Loss 0.1269 (0.1364)	LossFusion 0.1269 (0.1364)	
Train Epoch: [287][7/8]	Loss 0.1269 (0.1364)	LossFusion 0.1269 (0.1364)	
Train Epoch: [287][7/8]	Loss 0.1269 (0.1364)	LossFusion 0.1269 (0.1364)	
Train Epoch: [287][7/8]	Loss 0.1269 (0.1364)	LossFusion 0.1269 (0.1364)	
Train Epoch: [287][7/8]	Loss 0.1269 (0.1364)	LossFusion 0.1269 (0.1364)	
R@10:  54.0601909160614     R@50:  79.95457053184509
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  79.95457053184509
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  79.95457053184509
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  79.95457053184509
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  79.95457053184509
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  79.95457053184509
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  79.95457053184509
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.0601909160614     R@50:  79.95457053184509
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
Train Epoch: [288][0/8]	Loss 0.2375 (0.2375)	LossFusion 0.2375 (0.2375)	
Train Epoch: [288][0/8]	Loss 0.2375 (0.2375)	LossFusion 0.2375 (0.2375)	
Train Epoch: [288][0/8]	Loss 0.2375 (0.2375)	LossFusion 0.2375 (0.2375)	
Train Epoch: [288][0/8]	Loss 0.2375 (0.2375)	LossFusion 0.2375 (0.2375)	
Train Epoch: [288][0/8]	Loss 0.2375 (0.2375)	LossFusion 0.2375 (0.2375)	
Train Epoch: [288][0/8]	Loss 0.2375 (0.2375)	LossFusion 0.2375 (0.2375)	
Train Epoch: [288][0/8]	Loss 0.2375 (0.2375)	LossFusion 0.2375 (0.2375)	
Train Epoch: [288][0/8]	Loss 0.2375 (0.2375)	LossFusion 0.2375 (0.2375)	
Train Epoch: [288][7/8]	Loss 0.1277 (0.1352)	LossFusion 0.1277 (0.1352)	
Train Epoch: [288][7/8]	Loss 0.1277 (0.1352)	LossFusion 0.1277 (0.1352)	
Train Epoch: [288][7/8]	Loss 0.1277 (0.1352)	LossFusion 0.1277 (0.1352)	
Train Epoch: [288][7/8]	Loss 0.1277 (0.1352)	LossFusion 0.1277 (0.1352)	
Train Epoch: [288][7/8]	Loss 0.1277 (0.1352)	LossFusion 0.1277 (0.1352)	
Train Epoch: [288][7/8]	Loss 0.1277 (0.1352)	LossFusion 0.1277 (0.1352)	
Train Epoch: [288][7/8]	Loss 0.1277 (0.1352)	LossFusion 0.1277 (0.1352)	
Train Epoch: [288][7/8]	Loss 0.1277 (0.1352)	LossFusion 0.1277 (0.1352)	
R@10:  54.116976261138916     R@50:  79.89778518676758
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.89778518676758
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.89778518676758
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.89778518676758
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.89778518676758
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.89778518676758
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.89778518676758
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
R@10:  54.116976261138916     R@50:  79.89778518676758
Mean Now:  67.00738072395325  Best Mean Before:  69.44918 --------------------
Train Epoch: [289][0/8]	Loss 0.2430 (0.2430)	LossFusion 0.2430 (0.2430)	
Train Epoch: [289][0/8]	Loss 0.2430 (0.2430)	LossFusion 0.2430 (0.2430)	
Train Epoch: [289][0/8]	Loss 0.2430 (0.2430)	LossFusion 0.2430 (0.2430)	
Train Epoch: [289][0/8]	Loss 0.2430 (0.2430)	LossFusion 0.2430 (0.2430)	
Train Epoch: [289][0/8]	Loss 0.2430 (0.2430)	LossFusion 0.2430 (0.2430)	
Train Epoch: [289][0/8]	Loss 0.2430 (0.2430)	LossFusion 0.2430 (0.2430)	
Train Epoch: [289][0/8]	Loss 0.2430 (0.2430)	LossFusion 0.2430 (0.2430)	
Train Epoch: [289][0/8]	Loss 0.2430 (0.2430)	LossFusion 0.2430 (0.2430)	
Train Epoch: [289][7/8]	Loss 0.1141 (0.1398)	LossFusion 0.1141 (0.1398)	
Train Epoch: [289][7/8]	Loss 0.1141 (0.1398)	LossFusion 0.1141 (0.1398)	
Train Epoch: [289][7/8]	Loss 0.1141 (0.1398)	LossFusion 0.1141 (0.1398)	
Train Epoch: [289][7/8]	Loss 0.1141 (0.1398)	LossFusion 0.1141 (0.1398)	
Train Epoch: [289][7/8]	Loss 0.1141 (0.1398)	LossFusion 0.1141 (0.1398)	
Train Epoch: [289][7/8]	Loss 0.1141 (0.1398)	LossFusion 0.1141 (0.1398)	Train Epoch: [289][7/8]	Loss 0.1141 (0.1398)	LossFusion 0.1141 (0.1398)	

Train Epoch: [289][7/8]	Loss 0.1141 (0.1398)	LossFusion 0.1141 (0.1398)	
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
Train Epoch: [290][0/8]	Loss 0.2149 (0.2149)	LossFusion 0.2149 (0.2149)	
Train Epoch: [290][0/8]	Loss 0.2149 (0.2149)	LossFusion 0.2149 (0.2149)	
Train Epoch: [290][0/8]	Loss 0.2149 (0.2149)	LossFusion 0.2149 (0.2149)	
Train Epoch: [290][0/8]	Loss 0.2149 (0.2149)	LossFusion 0.2149 (0.2149)	
Train Epoch: [290][0/8]	Loss 0.2149 (0.2149)	LossFusion 0.2149 (0.2149)	
Train Epoch: [290][0/8]	Loss 0.2149 (0.2149)	LossFusion 0.2149 (0.2149)	
Train Epoch: [290][0/8]	Loss 0.2149 (0.2149)	LossFusion 0.2149 (0.2149)	
Train Epoch: [290][0/8]	Loss 0.2149 (0.2149)	LossFusion 0.2149 (0.2149)	
Train Epoch: [290][7/8]	Loss 0.1181 (0.1339)	LossFusion 0.1181 (0.1339)	
Train Epoch: [290][7/8]	Loss 0.1181 (0.1339)	LossFusion 0.1181 (0.1339)	
Train Epoch: [290][7/8]	Loss 0.1181 (0.1339)	LossFusion 0.1181 (0.1339)	
Train Epoch: [290][7/8]	Loss 0.1181 (0.1339)	LossFusion 0.1181 (0.1339)	
Train Epoch: [290][7/8]	Loss 0.1181 (0.1339)	LossFusion 0.1181 (0.1339)	
Train Epoch: [290][7/8]	Loss 0.1181 (0.1339)	LossFusion 0.1181 (0.1339)	
Train Epoch: [290][7/8]	Loss 0.1181 (0.1339)	LossFusion 0.1181 (0.1339)	
Train Epoch: [290][7/8]	Loss 0.1181 (0.1339)	LossFusion 0.1181 (0.1339)	
R@10:  54.00340557098389     R@50:  79.95457053184509
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.95457053184509
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.95457053184509
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.95457053184509
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.95457053184509
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.95457053184509
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.95457053184509
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
R@10:  54.00340557098389     R@50:  79.95457053184509
Mean Now:  66.97898805141449  Best Mean Before:  69.44918 --------------------
Train Epoch: [291][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [291][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [291][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [291][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [291][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [291][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [291][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [291][0/8]	Loss 0.2484 (0.2484)	LossFusion 0.2484 (0.2484)	
Train Epoch: [291][7/8]	Loss 0.1305 (0.1414)	LossFusion 0.1305 (0.1414)	
Train Epoch: [291][7/8]	Loss 0.1305 (0.1414)	LossFusion 0.1305 (0.1414)	
Train Epoch: [291][7/8]	Loss 0.1305 (0.1414)	LossFusion 0.1305 (0.1414)	
Train Epoch: [291][7/8]	Loss 0.1305 (0.1414)	LossFusion 0.1305 (0.1414)	
Train Epoch: [291][7/8]	Loss 0.1305 (0.1414)	LossFusion 0.1305 (0.1414)	
Train Epoch: [291][7/8]	Loss 0.1305 (0.1414)	LossFusion 0.1305 (0.1414)	
Train Epoch: [291][7/8]	Loss 0.1305 (0.1414)	LossFusion 0.1305 (0.1414)	
Train Epoch: [291][7/8]	Loss 0.1305 (0.1414)	LossFusion 0.1305 (0.1414)	
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
Train Epoch: [292][0/8]	Loss 0.2507 (0.2507)	LossFusion 0.2507 (0.2507)	
Train Epoch: [292][0/8]	Loss 0.2507 (0.2507)	LossFusion 0.2507 (0.2507)	
Train Epoch: [292][0/8]	Loss 0.2507 (0.2507)	LossFusion 0.2507 (0.2507)	
Train Epoch: [292][0/8]	Loss 0.2507 (0.2507)	LossFusion 0.2507 (0.2507)	
Train Epoch: [292][0/8]	Loss 0.2507 (0.2507)	LossFusion 0.2507 (0.2507)	
Train Epoch: [292][0/8]	Loss 0.2507 (0.2507)	LossFusion 0.2507 (0.2507)	
Train Epoch: [292][0/8]	Loss 0.2507 (0.2507)	LossFusion 0.2507 (0.2507)	
Train Epoch: [292][0/8]	Loss 0.2507 (0.2507)	LossFusion 0.2507 (0.2507)	
Train Epoch: [292][7/8]	Loss 0.1251 (0.1399)	LossFusion 0.1251 (0.1399)	
Train Epoch: [292][7/8]	Loss 0.1251 (0.1399)	LossFusion 0.1251 (0.1399)	
Train Epoch: [292][7/8]	Loss 0.1251 (0.1399)	LossFusion 0.1251 (0.1399)	
Train Epoch: [292][7/8]	Loss 0.1251 (0.1399)	LossFusion 0.1251 (0.1399)	
Train Epoch: [292][7/8]	Loss 0.1251 (0.1399)	LossFusion 0.1251 (0.1399)	
Train Epoch: [292][7/8]	Loss 0.1251 (0.1399)	LossFusion 0.1251 (0.1399)	
Train Epoch: [292][7/8]	Loss 0.1251 (0.1399)	LossFusion 0.1251 (0.1399)	
Train Epoch: [292][7/8]	Loss 0.1251 (0.1399)	LossFusion 0.1251 (0.1399)	
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
Train Epoch: [293][0/8]	Loss 0.2292 (0.2292)	LossFusion 0.2292 (0.2292)	
Train Epoch: [293][0/8]	Loss 0.2292 (0.2292)	LossFusion 0.2292 (0.2292)	
Train Epoch: [293][0/8]	Loss 0.2292 (0.2292)	LossFusion 0.2292 (0.2292)	
Train Epoch: [293][0/8]	Loss 0.2292 (0.2292)	LossFusion 0.2292 (0.2292)	
Train Epoch: [293][0/8]	Loss 0.2292 (0.2292)	LossFusion 0.2292 (0.2292)	
Train Epoch: [293][0/8]	Loss 0.2292 (0.2292)	LossFusion 0.2292 (0.2292)	
Train Epoch: [293][0/8]	Loss 0.2292 (0.2292)	LossFusion 0.2292 (0.2292)	
Train Epoch: [293][0/8]	Loss 0.2292 (0.2292)	LossFusion 0.2292 (0.2292)	
Train Epoch: [293][7/8]	Loss 0.1075 (0.1353)	LossFusion 0.1075 (0.1353)	
Train Epoch: [293][7/8]	Loss 0.1075 (0.1353)	LossFusion 0.1075 (0.1353)	
Train Epoch: [293][7/8]	Loss 0.1075 (0.1353)	LossFusion 0.1075 (0.1353)	
Train Epoch: [293][7/8]	Loss 0.1075 (0.1353)	LossFusion 0.1075 (0.1353)	
Train Epoch: [293][7/8]	Loss 0.1075 (0.1353)	LossFusion 0.1075 (0.1353)	
Train Epoch: [293][7/8]	Loss 0.1075 (0.1353)	LossFusion 0.1075 (0.1353)	
Train Epoch: [293][7/8]	Loss 0.1075 (0.1353)	LossFusion 0.1075 (0.1353)	
Train Epoch: [293][7/8]	Loss 0.1075 (0.1353)	LossFusion 0.1075 (0.1353)	
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
R@10:  53.94662022590637     R@50:  79.89778518676758
Mean Now:  66.92220270633698  Best Mean Before:  69.44918 --------------------
Train Epoch: [294][0/8]	Loss 0.2400 (0.2400)	LossFusion 0.2400 (0.2400)	
Train Epoch: [294][0/8]	Loss 0.2400 (0.2400)	LossFusion 0.2400 (0.2400)	
Train Epoch: [294][0/8]	Loss 0.2400 (0.2400)	LossFusion 0.2400 (0.2400)	
Train Epoch: [294][0/8]	Loss 0.2400 (0.2400)	LossFusion 0.2400 (0.2400)	
Train Epoch: [294][0/8]	Loss 0.2400 (0.2400)	LossFusion 0.2400 (0.2400)	
Train Epoch: [294][0/8]	Loss 0.2400 (0.2400)	LossFusion 0.2400 (0.2400)	
Train Epoch: [294][0/8]	Loss 0.2400 (0.2400)	LossFusion 0.2400 (0.2400)	
Train Epoch: [294][0/8]	Loss 0.2400 (0.2400)	LossFusion 0.2400 (0.2400)	
Train Epoch: [294][7/8]	Loss 0.1367 (0.1376)	LossFusion 0.1367 (0.1376)	
Train Epoch: [294][7/8]	Loss 0.1367 (0.1376)	LossFusion 0.1367 (0.1376)	
Train Epoch: [294][7/8]	Loss 0.1367 (0.1376)	LossFusion 0.1367 (0.1376)	
Train Epoch: [294][7/8]	Loss 0.1367 (0.1376)	LossFusion 0.1367 (0.1376)	
Train Epoch: [294][7/8]	Loss 0.1367 (0.1376)	LossFusion 0.1367 (0.1376)	
Train Epoch: [294][7/8]	Loss 0.1367 (0.1376)	LossFusion 0.1367 (0.1376)	
Train Epoch: [294][7/8]	Loss 0.1367 (0.1376)	LossFusion 0.1367 (0.1376)	
Train Epoch: [294][7/8]	Loss 0.1367 (0.1376)	LossFusion 0.1367 (0.1376)	
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
Train Epoch: [295][0/8]	Loss 0.2327 (0.2327)	LossFusion 0.2327 (0.2327)	
Train Epoch: [295][0/8]	Loss 0.2327 (0.2327)	LossFusion 0.2327 (0.2327)	
Train Epoch: [295][0/8]	Loss 0.2327 (0.2327)	LossFusion 0.2327 (0.2327)	
Train Epoch: [295][0/8]	Loss 0.2327 (0.2327)	LossFusion 0.2327 (0.2327)	
Train Epoch: [295][0/8]	Loss 0.2327 (0.2327)	LossFusion 0.2327 (0.2327)	
Train Epoch: [295][0/8]	Loss 0.2327 (0.2327)	LossFusion 0.2327 (0.2327)	
Train Epoch: [295][0/8]	Loss 0.2327 (0.2327)	LossFusion 0.2327 (0.2327)	
Train Epoch: [295][0/8]	Loss 0.2327 (0.2327)	LossFusion 0.2327 (0.2327)	
Train Epoch: [295][7/8]	Loss 0.1275 (0.1368)	LossFusion 0.1275 (0.1368)	
Train Epoch: [295][7/8]	Loss 0.1275 (0.1368)	LossFusion 0.1275 (0.1368)	
Train Epoch: [295][7/8]	Loss 0.1275 (0.1368)	LossFusion 0.1275 (0.1368)	
Train Epoch: [295][7/8]	Loss 0.1275 (0.1368)	LossFusion 0.1275 (0.1368)	
Train Epoch: [295][7/8]	Loss 0.1275 (0.1368)	LossFusion 0.1275 (0.1368)	
Train Epoch: [295][7/8]	Loss 0.1275 (0.1368)	LossFusion 0.1275 (0.1368)	
Train Epoch: [295][7/8]	Loss 0.1275 (0.1368)	LossFusion 0.1275 (0.1368)	
Train Epoch: [295][7/8]	Loss 0.1275 (0.1368)	LossFusion 0.1275 (0.1368)	
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
Train Epoch: [296][0/8]	Loss 0.2448 (0.2448)	LossFusion 0.2448 (0.2448)	
Train Epoch: [296][0/8]	Loss 0.2448 (0.2448)	LossFusion 0.2448 (0.2448)	
Train Epoch: [296][0/8]	Loss 0.2448 (0.2448)	LossFusion 0.2448 (0.2448)	
Train Epoch: [296][0/8]	Loss 0.2448 (0.2448)	LossFusion 0.2448 (0.2448)	
Train Epoch: [296][0/8]	Loss 0.2448 (0.2448)	LossFusion 0.2448 (0.2448)	
Train Epoch: [296][0/8]	Loss 0.2448 (0.2448)	LossFusion 0.2448 (0.2448)	
Train Epoch: [296][0/8]	Loss 0.2448 (0.2448)	LossFusion 0.2448 (0.2448)	
Train Epoch: [296][0/8]	Loss 0.2448 (0.2448)	LossFusion 0.2448 (0.2448)	
Train Epoch: [296][7/8]	Loss 0.1222 (0.1427)	LossFusion 0.1222 (0.1427)	
Train Epoch: [296][7/8]	Loss 0.1222 (0.1427)	LossFusion 0.1222 (0.1427)	
Train Epoch: [296][7/8]	Loss 0.1222 (0.1427)	LossFusion 0.1222 (0.1427)	Train Epoch: [296][7/8]	Loss 0.1222 (0.1427)	LossFusion 0.1222 (0.1427)	

Train Epoch: [296][7/8]	Loss 0.1222 (0.1427)	LossFusion 0.1222 (0.1427)	
Train Epoch: [296][7/8]	Loss 0.1222 (0.1427)	LossFusion 0.1222 (0.1427)	
Train Epoch: [296][7/8]	Loss 0.1222 (0.1427)	LossFusion 0.1222 (0.1427)	
Train Epoch: [296][7/8]	Loss 0.1222 (0.1427)	LossFusion 0.1222 (0.1427)	
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
Train Epoch: [297][0/8]	Loss 0.2732 (0.2732)	LossFusion 0.2732 (0.2732)	
Train Epoch: [297][0/8]	Loss 0.2732 (0.2732)	LossFusion 0.2732 (0.2732)	
Train Epoch: [297][0/8]	Loss 0.2732 (0.2732)	LossFusion 0.2732 (0.2732)	
Train Epoch: [297][0/8]	Loss 0.2732 (0.2732)	LossFusion 0.2732 (0.2732)	
Train Epoch: [297][0/8]	Loss 0.2732 (0.2732)	LossFusion 0.2732 (0.2732)	
Train Epoch: [297][0/8]	Loss 0.2732 (0.2732)	LossFusion 0.2732 (0.2732)	
Train Epoch: [297][0/8]	Loss 0.2732 (0.2732)	LossFusion 0.2732 (0.2732)	
Train Epoch: [297][0/8]	Loss 0.2732 (0.2732)	LossFusion 0.2732 (0.2732)	
Train Epoch: [297][7/8]	Loss 0.1225 (0.1401)	LossFusion 0.1225 (0.1401)	
Train Epoch: [297][7/8]	Loss 0.1225 (0.1401)	LossFusion 0.1225 (0.1401)	
Train Epoch: [297][7/8]	Loss 0.1225 (0.1401)	LossFusion 0.1225 (0.1401)	
Train Epoch: [297][7/8]	Loss 0.1225 (0.1401)	LossFusion 0.1225 (0.1401)	
Train Epoch: [297][7/8]	Loss 0.1225 (0.1401)	LossFusion 0.1225 (0.1401)	
Train Epoch: [297][7/8]	Loss 0.1225 (0.1401)	LossFusion 0.1225 (0.1401)	
Train Epoch: [297][7/8]	Loss 0.1225 (0.1401)	LossFusion 0.1225 (0.1401)	
Train Epoch: [297][7/8]	Loss 0.1225 (0.1401)	LossFusion 0.1225 (0.1401)	
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
Train Epoch: [298][0/8]	Loss 0.2380 (0.2380)	LossFusion 0.2380 (0.2380)	
Train Epoch: [298][0/8]	Loss 0.2380 (0.2380)	LossFusion 0.2380 (0.2380)	
Train Epoch: [298][0/8]	Loss 0.2380 (0.2380)	LossFusion 0.2380 (0.2380)	
Train Epoch: [298][0/8]	Loss 0.2380 (0.2380)	LossFusion 0.2380 (0.2380)	
Train Epoch: [298][0/8]	Loss 0.2380 (0.2380)	LossFusion 0.2380 (0.2380)	
Train Epoch: [298][0/8]	Loss 0.2380 (0.2380)	LossFusion 0.2380 (0.2380)	
Train Epoch: [298][0/8]	Loss 0.2380 (0.2380)	LossFusion 0.2380 (0.2380)	
Train Epoch: [298][0/8]	Loss 0.2380 (0.2380)	LossFusion 0.2380 (0.2380)	
Train Epoch: [298][7/8]	Loss 0.1251 (0.1388)	LossFusion 0.1251 (0.1388)	
Train Epoch: [298][7/8]	Loss 0.1251 (0.1388)	LossFusion 0.1251 (0.1388)	
Train Epoch: [298][7/8]	Loss 0.1251 (0.1388)	LossFusion 0.1251 (0.1388)	
Train Epoch: [298][7/8]	Loss 0.1251 (0.1388)	LossFusion 0.1251 (0.1388)	
Train Epoch: [298][7/8]	Loss 0.1251 (0.1388)	LossFusion 0.1251 (0.1388)	
Train Epoch: [298][7/8]	Loss 0.1251 (0.1388)	LossFusion 0.1251 (0.1388)	
Train Epoch: [298][7/8]	Loss 0.1251 (0.1388)	LossFusion 0.1251 (0.1388)	
Train Epoch: [298][7/8]	Loss 0.1251 (0.1388)	LossFusion 0.1251 (0.1388)	
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
R@10:  53.83304953575134     R@50:  79.89778518676758
Mean Now:  66.86541736125946  Best Mean Before:  69.44918 --------------------
Train Epoch: [299][0/8]	Loss 0.2486 (0.2486)	LossFusion 0.2486 (0.2486)	
Train Epoch: [299][0/8]	Loss 0.2486 (0.2486)	LossFusion 0.2486 (0.2486)	
Train Epoch: [299][0/8]	Loss 0.2486 (0.2486)	LossFusion 0.2486 (0.2486)	
Train Epoch: [299][0/8]	Loss 0.2486 (0.2486)	LossFusion 0.2486 (0.2486)	
Train Epoch: [299][0/8]	Loss 0.2486 (0.2486)	LossFusion 0.2486 (0.2486)	
Train Epoch: [299][0/8]	Loss 0.2486 (0.2486)	LossFusion 0.2486 (0.2486)	
Train Epoch: [299][0/8]	Loss 0.2486 (0.2486)	LossFusion 0.2486 (0.2486)	
Train Epoch: [299][0/8]	Loss 0.2486 (0.2486)	LossFusion 0.2486 (0.2486)	
Train Epoch: [299][7/8]	Loss 0.1288 (0.1426)	LossFusion 0.1288 (0.1426)	
Train Epoch: [299][7/8]	Loss 0.1288 (0.1426)	LossFusion 0.1288 (0.1426)	
Train Epoch: [299][7/8]	Loss 0.1288 (0.1426)	LossFusion 0.1288 (0.1426)	
Train Epoch: [299][7/8]	Loss 0.1288 (0.1426)	LossFusion 0.1288 (0.1426)	
Train Epoch: [299][7/8]	Loss 0.1288 (0.1426)	LossFusion 0.1288 (0.1426)	
Train Epoch: [299][7/8]	Loss 0.1288 (0.1426)	LossFusion 0.1288 (0.1426)	
Train Epoch: [299][7/8]	Loss 0.1288 (0.1426)	LossFusion 0.1288 (0.1426)	
Train Epoch: [299][7/8]	Loss 0.1288 (0.1426)	LossFusion 0.1288 (0.1426)	
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
R@10:  53.88983488082886     R@50:  79.89778518676758
Mean Now:  66.89381003379822  Best Mean Before:  69.44918 --------------------
